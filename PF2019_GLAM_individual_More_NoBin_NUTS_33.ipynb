{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Individual GLAM estimation and out of sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1734.284</td>\n",
       "      <td>110</td>\n",
       "      <td>131</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6555.370</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.240370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3174.566</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2877.579</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>0.608409</td>\n",
       "      <td>0.391591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1806.310</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.522849</td>\n",
       "      <td>0.477151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice        rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        1      0       1  1734.284           110           131  0.669090   \n",
       "1        1      1       0  6555.370            47            50  0.759630   \n",
       "2        1      2       0  3174.566            50            44  0.549371   \n",
       "3        1      3       1  2877.579            57            50  0.608409   \n",
       "4        1      4       1  1806.310            42            50  0.522849   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.330910  \n",
       "1  0.240370  \n",
       "2  0.450629  \n",
       "3  0.391591  \n",
       "4  0.477151  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_individual_More_NoBin_Gamma-11_NUTS_33'\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataPF2019_More_NoBin_33.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1920 trials) and test (1920 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1734.284</td>\n",
       "      <td>110</td>\n",
       "      <td>131</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3174.566</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1806.310</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.522849</td>\n",
       "      <td>0.477151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3650.266</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>0.317966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1259.268</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>0.508019</td>\n",
       "      <td>0.491981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5698.027</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>0.582089</td>\n",
       "      <td>0.417911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2626.168</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>0.666353</td>\n",
       "      <td>0.333647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1671.149</td>\n",
       "      <td>110</td>\n",
       "      <td>124</td>\n",
       "      <td>0.508035</td>\n",
       "      <td>0.491965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1527.826</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.473512</td>\n",
       "      <td>0.526488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2267.665</td>\n",
       "      <td>101</td>\n",
       "      <td>110</td>\n",
       "      <td>0.553242</td>\n",
       "      <td>0.446758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5571.061</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>0.575306</td>\n",
       "      <td>0.424694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1402.112</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>0.435523</td>\n",
       "      <td>0.564477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2065.604</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>0.528335</td>\n",
       "      <td>0.471665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1613.454</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>0.485035</td>\n",
       "      <td>0.514965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4895.517</td>\n",
       "      <td>133</td>\n",
       "      <td>110</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.301621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.688</td>\n",
       "      <td>126</td>\n",
       "      <td>110</td>\n",
       "      <td>0.511292</td>\n",
       "      <td>0.488708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2050.497</td>\n",
       "      <td>110</td>\n",
       "      <td>126</td>\n",
       "      <td>0.522393</td>\n",
       "      <td>0.477607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1635.473</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.477739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>4443.018</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>0.567061</td>\n",
       "      <td>0.432939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.903</td>\n",
       "      <td>124</td>\n",
       "      <td>110</td>\n",
       "      <td>0.558840</td>\n",
       "      <td>0.441160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1686.530</td>\n",
       "      <td>128</td>\n",
       "      <td>110</td>\n",
       "      <td>0.657603</td>\n",
       "      <td>0.342397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2244.929</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>0.702233</td>\n",
       "      <td>0.297767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1361.319</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "      <td>0.482747</td>\n",
       "      <td>0.517253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2850.121</td>\n",
       "      <td>96</td>\n",
       "      <td>80</td>\n",
       "      <td>0.698865</td>\n",
       "      <td>0.301135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1391.672</td>\n",
       "      <td>110</td>\n",
       "      <td>128</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.547368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1582.340</td>\n",
       "      <td>110</td>\n",
       "      <td>119</td>\n",
       "      <td>0.559501</td>\n",
       "      <td>0.440499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2184.782</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>0.581910</td>\n",
       "      <td>0.418090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2890.742</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "      <td>0.530453</td>\n",
       "      <td>0.469547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1901.984</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>0.418559</td>\n",
       "      <td>0.581441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2545.418</td>\n",
       "      <td>94</td>\n",
       "      <td>110</td>\n",
       "      <td>0.576064</td>\n",
       "      <td>0.423936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4251.426</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0.503628</td>\n",
       "      <td>0.496372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4601.336</td>\n",
       "      <td>89</td>\n",
       "      <td>110</td>\n",
       "      <td>0.477015</td>\n",
       "      <td>0.522985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3649.435</td>\n",
       "      <td>110</td>\n",
       "      <td>98</td>\n",
       "      <td>0.416827</td>\n",
       "      <td>0.583173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3708.628</td>\n",
       "      <td>110</td>\n",
       "      <td>94</td>\n",
       "      <td>0.451137</td>\n",
       "      <td>0.548863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>5089.783</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.624277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>6969.709</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>0.424717</td>\n",
       "      <td>0.575283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>33</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1858.269</td>\n",
       "      <td>87</td>\n",
       "      <td>110</td>\n",
       "      <td>0.469035</td>\n",
       "      <td>0.530965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>3910.930</td>\n",
       "      <td>80</td>\n",
       "      <td>96</td>\n",
       "      <td>0.460076</td>\n",
       "      <td>0.539924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2087.100</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>0.532287</td>\n",
       "      <td>0.467713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>33</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>4085.180</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>0.425232</td>\n",
       "      <td>0.574768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6549.821</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>0.568922</td>\n",
       "      <td>0.431078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>4550.765</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>0.449738</td>\n",
       "      <td>0.550262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>33</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>5756.064</td>\n",
       "      <td>103</td>\n",
       "      <td>110</td>\n",
       "      <td>0.479955</td>\n",
       "      <td>0.520045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>33</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4035.357</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>0.477174</td>\n",
       "      <td>0.522826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1844.621</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.497924</td>\n",
       "      <td>0.502076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>33</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3936.449</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.477459</td>\n",
       "      <td>0.522541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>33</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>11964.377</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>0.484599</td>\n",
       "      <td>0.515401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>33</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2743.440</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>0.529970</td>\n",
       "      <td>0.470030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>2532.466</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>0.539153</td>\n",
       "      <td>0.460847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>6412.806</td>\n",
       "      <td>110</td>\n",
       "      <td>96</td>\n",
       "      <td>0.513330</td>\n",
       "      <td>0.486670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4007.788</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.442161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>33</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>3685.316</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>0.582175</td>\n",
       "      <td>0.417825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>33</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.182</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>0.399461</td>\n",
       "      <td>0.600539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>33</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>4300.777</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>0.492486</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>7640.657</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>0.593629</td>\n",
       "      <td>0.406371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>33</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>3341.929</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>0.476386</td>\n",
       "      <td>0.523614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>33</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2674.219</td>\n",
       "      <td>122</td>\n",
       "      <td>110</td>\n",
       "      <td>0.584644</td>\n",
       "      <td>0.415356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2848.448</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>0.552859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>33</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>2835.649</td>\n",
       "      <td>110</td>\n",
       "      <td>122</td>\n",
       "      <td>0.680958</td>\n",
       "      <td>0.319042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>33</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>3903.836</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "      <td>0.392389</td>\n",
       "      <td>0.607611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  trial  choice         rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0          1      0       1   1734.284           110           131  0.669090   \n",
       "2          1      2       0   3174.566            50            44  0.549371   \n",
       "4          1      4       1   1806.310            42            50  0.522849   \n",
       "6          1      6       1   3650.266            78            80  0.682034   \n",
       "8          1      8       1   1259.268            50            48  0.508019   \n",
       "10         1     10       1   5698.027            46            50  0.582089   \n",
       "12         1     12       1   2626.168            50            56  0.666353   \n",
       "14         1     14       1   1671.149           110           124  0.508035   \n",
       "16         1     16       1   1527.826            64            80  0.473512   \n",
       "18         1     18       1   2267.665           101           110  0.553242   \n",
       "20         1     20       0   5571.061            50            42  0.575306   \n",
       "22         1     22       1   1402.112            77            80  0.435523   \n",
       "24         1     24       1   2065.604            44            50  0.528335   \n",
       "26         1     26       1   1613.454            50            46  0.485035   \n",
       "28         1     28       0   4895.517           133           110  0.698379   \n",
       "30         1     30       1   2000.688           126           110  0.511292   \n",
       "32         1     32       1   2050.497           110           126  0.522393   \n",
       "34         1     34       1   1635.473            80            77  0.522261   \n",
       "36         1     36       0   4443.018            80            64  0.567061   \n",
       "38         1     38       1   1725.903           124           110  0.558840   \n",
       "40         1     40       0   1686.530           128           110  0.657603   \n",
       "42         1     42       0   2244.929            54            50  0.702233   \n",
       "44         1     44       1   1361.319           105           110  0.482747   \n",
       "46         1     46       0   2850.121            96            80  0.698865   \n",
       "48         1     48       1   1391.672           110           128  0.452632   \n",
       "50         1     50       1   1582.340           110           119  0.559501   \n",
       "52         1     52       0   2184.782            58            50  0.581910   \n",
       "54         1     54       1   2890.742            74            80  0.530453   \n",
       "56         1     56       1   1901.984            66            80  0.418559   \n",
       "58         1     58       1   2545.418            94           110  0.576064   \n",
       "..       ...    ...     ...        ...           ...           ...       ...   \n",
       "60        33     60       1   4251.426            75            80  0.503628   \n",
       "62        33     62       0   4601.336            89           110  0.477015   \n",
       "64        33     64       0   3649.435           110            98  0.416827   \n",
       "66        33     66       0   3708.628           110            94  0.451137   \n",
       "68        33     68       1   5089.783            50            54  0.375723   \n",
       "70        33     70       1   6969.709            50            52  0.424717   \n",
       "72        33     72       1   1858.269            87           110  0.469035   \n",
       "74        33     74       1   3910.930            80            96  0.460076   \n",
       "76        33     76       1   2087.100            50            55  0.532287   \n",
       "78        33     78       1   4085.180            45            50  0.425232   \n",
       "80        33     80       1   6549.821            50            53  0.568922   \n",
       "82        33     82       1   4550.765            80            88  0.449738   \n",
       "84        33     84       0   5756.064           103           110  0.479955   \n",
       "86        33     86       0   4035.357            80            72  0.477174   \n",
       "88        33     88       1   1844.621            80            90  0.497924   \n",
       "90        33     90       0   3936.449            80            70  0.477459   \n",
       "92        33     92       0  11964.377            82            80  0.484599   \n",
       "94        33     94       1   2743.440            96           110  0.529970   \n",
       "96        33     96       0   2532.466            60            50  0.539153   \n",
       "98        33     98       1   6412.806           110            96  0.513330   \n",
       "100       33    100       0   4007.788            49            50  0.557839   \n",
       "102       33    102       0   3685.316            51            50  0.582175   \n",
       "104       33    104       1   1988.182            40            50  0.399461   \n",
       "106       33    106       0   4300.777            85            80  0.492486   \n",
       "108       33    108       0   7640.657            50            43  0.593629   \n",
       "110       33    110       1   3341.929            50            60  0.476386   \n",
       "112       33    112       0   2674.219           122           110  0.584644   \n",
       "114       33    114       1   2848.448            80            67  0.447141   \n",
       "116       33    116       1   2835.649           110           122  0.680958   \n",
       "118       33    118       1   3903.836           110           112  0.392389   \n",
       "\n",
       "       gaze_1  \n",
       "0    0.330910  \n",
       "2    0.450629  \n",
       "4    0.477151  \n",
       "6    0.317966  \n",
       "8    0.491981  \n",
       "10   0.417911  \n",
       "12   0.333647  \n",
       "14   0.491965  \n",
       "16   0.526488  \n",
       "18   0.446758  \n",
       "20   0.424694  \n",
       "22   0.564477  \n",
       "24   0.471665  \n",
       "26   0.514965  \n",
       "28   0.301621  \n",
       "30   0.488708  \n",
       "32   0.477607  \n",
       "34   0.477739  \n",
       "36   0.432939  \n",
       "38   0.441160  \n",
       "40   0.342397  \n",
       "42   0.297767  \n",
       "44   0.517253  \n",
       "46   0.301135  \n",
       "48   0.547368  \n",
       "50   0.440499  \n",
       "52   0.418090  \n",
       "54   0.469547  \n",
       "56   0.581441  \n",
       "58   0.423936  \n",
       "..        ...  \n",
       "60   0.496372  \n",
       "62   0.522985  \n",
       "64   0.583173  \n",
       "66   0.548863  \n",
       "68   0.624277  \n",
       "70   0.575283  \n",
       "72   0.530965  \n",
       "74   0.539924  \n",
       "76   0.467713  \n",
       "78   0.574768  \n",
       "80   0.431078  \n",
       "82   0.550262  \n",
       "84   0.520045  \n",
       "86   0.522826  \n",
       "88   0.502076  \n",
       "90   0.522541  \n",
       "92   0.515401  \n",
       "94   0.470030  \n",
       "96   0.460847  \n",
       "98   0.486670  \n",
       "100  0.442161  \n",
       "102  0.417825  \n",
       "104  0.600539  \n",
       "106  0.507514  \n",
       "108  0.406371  \n",
       "110  0.523614  \n",
       "112  0.415356  \n",
       "114  0.552859  \n",
       "116  0.319042  \n",
       "118  0.607611  \n",
       "\n",
       "[1920 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM individually...\n",
      "Generating single subject models for 32 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 32 model(s) using NUTS...\n",
      "  Fitting model 1 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1210.81draws/s]\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 2 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:12<00:00, 951.08draws/s]\n",
      "There were 47 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 43 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 50 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 43 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 3 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1100.47draws/s]\n",
      "There were 123 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 185 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 138 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 147 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 4 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1137.85draws/s]\n",
      "There were 41 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 28 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 40 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 40 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 5 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1290.24draws/s]\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 6 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:11<00:00, 1079.16draws/s]\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8799485849873582, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 8 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8981774391494725, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 7 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:14<00:00, 828.96draws/s]\n",
      "There were 13 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 8 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1190.10draws/s]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 9 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1292.75draws/s]\n",
      "There were 35 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 37 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 24 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 32 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 10 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1171.29draws/s]\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6988306481239942, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 11 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1128.43draws/s]\n",
      "There were 158 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 138 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 131 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 136 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 12 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1330.82draws/s]\n",
      "The acceptance probability does not match the target. It is 0.8849509223576897, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.6966123193269532, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 13 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [10:24<00:00,  4.37draws/s]\n",
      "There were 38 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.652840423067064, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8799764671095479, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 26 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 14 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '5134' (I am process '4933')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.5.0-x86_64-i386-64bit-i386-3.7.2-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '5134' (I am process '4933')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.5.0-x86_64-i386-64bit-i386-3.7.2-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '5134' (I am process '4933')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/pradyumna/.theano/compiledir_Darwin-18.5.0-x86_64-i386-64bit-i386-3.7.2-64/lock_dir\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:08<00:00, 1461.32draws/s]\n",
      "There were 101 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 148 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 76 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 97 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 15 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:12<00:00, 976.05draws/s]\n",
      "There were 100 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 62 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 93 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 60 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 16 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:18<00:00, 636.68draws/s]\n",
      "There were 101 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9100193217790833, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 449 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.558953569611484, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 203 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.5587931752794926, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 111 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 17 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1272.12draws/s]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8794101178300339, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 8 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 18 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:07<00:00, 1673.81draws/s]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 19 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:22<00:00, 540.22draws/s]\n",
      "There were 94 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6525463358732884, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 18 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9356809315434799, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 62 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6896103745502107, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 20 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:15<00:00, 779.84draws/s]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 21 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:08<00:00, 1382.84draws/s]\n",
      "There were 12 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.896292655029272, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 51 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 22 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1155.88draws/s]\n",
      "There were 1243 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 1189 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 1098 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 1272 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 23 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1146.38draws/s]\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8871559125146787, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 24 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:13<00:00, 918.14draws/s]\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 21 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 14 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 12 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 25 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:10<00:00, 1194.69draws/s]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 8 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 13 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 26 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:12<00:00, 941.04draws/s]\n",
      "There were 10 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 8 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 10 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 12 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 27 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1302.26draws/s]\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9024634839476384, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8907039117862787, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 28 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [11:35<00:00,  6.36draws/s]\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9170981570841957, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 29 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:30<00:00, 395.59draws/s]\n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 30 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:11<00:00, 1002.12draws/s]\n",
      "There were 66 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 27 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 25 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 55 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 31 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:09<00:00, 1223.14draws/s]\n",
      "There were 8 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 93 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 13 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 15 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.4775538612458078, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting model 32 of 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, SNR, gamma, v]\n",
      "Sampling 4 chains: 100%|██████████| 12000/12000 [00:11<00:00, 1006.88draws/s]\n",
      "There were 65 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 48 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 54 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 103 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM individually...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full'+sufix+'.npy')):\n",
    "    glam_full.make_model('individual', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_full'+sufix+'.npy'), glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 4.1e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 1.2e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.1e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 2.2e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.1e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 4.3e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 2.5e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 5.2e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 9.5e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 4e-05, 'gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 2e-05, 'gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 6.1e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 1.9e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.8e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 2.3e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 4.6e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 1.7e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 2.7e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.9e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 2.7e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.9e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 4.4e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3e-05, 'gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 2e-05, 'gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 1.7e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.4e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.6e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 8.4e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 5.7e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 4.4e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 4.3e-05, 'gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'b': 1.0, 'p_error': 0.05, 'v': 3.2e-05, 'gam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   {'b': 1.0, 'p_error': 0.05, 'v': 4.1e-05, 'gam...\n",
       "1   {'b': 1.0, 'p_error': 0.05, 'v': 1.2e-05, 'gam...\n",
       "2   {'b': 1.0, 'p_error': 0.05, 'v': 3.1e-05, 'gam...\n",
       "3   {'b': 1.0, 'p_error': 0.05, 'v': 2.2e-05, 'gam...\n",
       "4   {'b': 1.0, 'p_error': 0.05, 'v': 3.1e-05, 'gam...\n",
       "5   {'b': 1.0, 'p_error': 0.05, 'v': 4.3e-05, 'gam...\n",
       "6   {'b': 1.0, 'p_error': 0.05, 'v': 2.5e-05, 'gam...\n",
       "7   {'b': 1.0, 'p_error': 0.05, 'v': 5.2e-05, 'gam...\n",
       "8   {'b': 1.0, 'p_error': 0.05, 'v': 9.5e-05, 'gam...\n",
       "9   {'b': 1.0, 'p_error': 0.05, 'v': 4e-05, 'gamma...\n",
       "10  {'b': 1.0, 'p_error': 0.05, 'v': 2e-05, 'gamma...\n",
       "11  {'b': 1.0, 'p_error': 0.05, 'v': 6.1e-05, 'gam...\n",
       "12  {'b': 1.0, 'p_error': 0.05, 'v': 1.9e-05, 'gam...\n",
       "13  {'b': 1.0, 'p_error': 0.05, 'v': 3.8e-05, 'gam...\n",
       "14  {'b': 1.0, 'p_error': 0.05, 'v': 2.3e-05, 'gam...\n",
       "15  {'b': 1.0, 'p_error': 0.05, 'v': 4.6e-05, 'gam...\n",
       "16  {'b': 1.0, 'p_error': 0.05, 'v': 1.7e-05, 'gam...\n",
       "17  {'b': 1.0, 'p_error': 0.05, 'v': 2.7e-05, 'gam...\n",
       "18  {'b': 1.0, 'p_error': 0.05, 'v': 3.9e-05, 'gam...\n",
       "19  {'b': 1.0, 'p_error': 0.05, 'v': 2.7e-05, 'gam...\n",
       "20  {'b': 1.0, 'p_error': 0.05, 'v': 3.9e-05, 'gam...\n",
       "21  {'b': 1.0, 'p_error': 0.05, 'v': 4.4e-05, 'gam...\n",
       "22  {'b': 1.0, 'p_error': 0.05, 'v': 3e-05, 'gamma...\n",
       "23  {'b': 1.0, 'p_error': 0.05, 'v': 2e-05, 'gamma...\n",
       "24  {'b': 1.0, 'p_error': 0.05, 'v': 1.7e-05, 'gam...\n",
       "25  {'b': 1.0, 'p_error': 0.05, 'v': 3.4e-05, 'gam...\n",
       "26  {'b': 1.0, 'p_error': 0.05, 'v': 3.6e-05, 'gam...\n",
       "27  {'b': 1.0, 'p_error': 0.05, 'v': 8.4e-05, 'gam...\n",
       "28  {'b': 1.0, 'p_error': 0.05, 'v': 5.7e-05, 'gam...\n",
       "29  {'b': 1.0, 'p_error': 0.05, 'v': 4.4e-05, 'gam...\n",
       "30  {'b': 1.0, 'p_error': 0.05, 'v': 4.3e-05, 'gam...\n",
       "31  {'b': 1.0, 'p_error': 0.05, 'v': 3.2e-05, 'gam..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing WAIC scores for full model...\n",
      "  Found old DIC scores in \"results/waic\". Skipping WAIC computation...\n"
     ]
    }
   ],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04604884e+03, 0.00000000e+00, 1.72250244e+00, 1.00000000e+00],\n",
       "       [1.22067883e+03, 0.00000000e+00, 1.77895232e+00, 1.00000000e+00],\n",
       "       [1.08131950e+03, 0.00000000e+00, 4.57825376e+00, 1.00000000e+00],\n",
       "       [1.19129127e+03, 0.00000000e+00, 1.81216772e+00, 1.00000000e+00],\n",
       "       [1.09360688e+03, 0.00000000e+00, 2.09341500e+00, 1.00000000e+00],\n",
       "       [1.07141022e+03, 0.00000000e+00, 3.96698860e+00, 1.00000000e+00],\n",
       "       [1.16532728e+03, 0.00000000e+00, 1.59540281e+00, 1.00000000e+00],\n",
       "       [1.04997833e+03, 0.00000000e+00, 2.34431071e+00, 1.00000000e+00],\n",
       "       [9.92213429e+02, 0.00000000e+00, 2.57769666e+00, 1.00000000e+00],\n",
       "       [1.03406225e+03, 0.00000000e+00, 2.59437231e+00, 1.00000000e+00],\n",
       "       [1.20205192e+03, 0.00000000e+00, 3.10274965e+00, 1.00000000e+00],\n",
       "       [1.00093682e+03, 0.00000000e+00, 2.61991370e+00, 1.00000000e+00],\n",
       "       [1.05702793e+03, 0.00000000e+00, 1.21914822e+01, 1.00000000e+00],\n",
       "       [1.07529609e+03, 0.00000000e+00, 3.57531961e+00, 1.00000000e+00],\n",
       "       [1.14818307e+03, 0.00000000e+00, 2.59812852e+00, 1.00000000e+00],\n",
       "       [1.01134051e+03, 0.00000000e+00, 4.59129769e+00, 1.00000000e+00],\n",
       "       [1.17904935e+03, 0.00000000e+00, 2.61328657e+00, 1.00000000e+00],\n",
       "       [1.08212759e+03, 0.00000000e+00, 2.91359478e+00, 1.00000000e+00],\n",
       "       [1.03912684e+03, 0.00000000e+00, 2.98513902e+00, 1.00000000e+00],\n",
       "       [1.12281397e+03, 0.00000000e+00, 1.58847943e+00, 1.00000000e+00],\n",
       "       [1.08328029e+03, 0.00000000e+00, 5.13211283e+00, 1.00000000e+00],\n",
       "       [1.04048361e+03, 0.00000000e+00, 2.37669404e+00, 1.00000000e+00],\n",
       "       [1.10951177e+03, 0.00000000e+00, 3.77999267e+00, 1.00000000e+00],\n",
       "       [1.17166441e+03, 0.00000000e+00, 3.14235474e+00, 1.00000000e+00],\n",
       "       [1.14466468e+03, 0.00000000e+00, 1.24185550e+00, 1.00000000e+00],\n",
       "       [1.10702344e+03, 0.00000000e+00, 4.35968602e+00, 1.00000000e+00],\n",
       "       [1.11839910e+03, 0.00000000e+00, 3.38129679e+00, 1.00000000e+00],\n",
       "       [9.84718636e+02, 0.00000000e+00, 1.72399392e+00, 1.00000000e+00],\n",
       "       [9.37096894e+02, 0.00000000e+00, 3.91369881e+00, 1.00000000e+00],\n",
       "       [1.07135325e+03, 0.00000000e+00, 3.29260029e+00, 1.00000000e+00],\n",
       "       [1.07397668e+03, 0.00000000e+00, 6.75135179e+00, 1.00000000e+00],\n",
       "       [1.11923509e+03, 0.00000000e+00, 5.32397127e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'nchains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f3d14e55e290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute LOO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/loo/glam_PF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msufix\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pymc3/stats.py\u001b[0m in \u001b[0;36mloo\u001b[0;34m(trace, model, pointwise, reff, progressbar)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreff\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnchains\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mreff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'nchains'"
     ]
    }
   ],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test set data using full GLAM...\n",
      "Replaced attached data (1920 trials) with new data (1920 trials)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Domain error in arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-013032d2772f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/predictions/glam_PF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msufix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/predictions/glam_PF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msufix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, n_repeats, boundary, error_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                                                   \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboundary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                                                   \u001b[0merror_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                                                                   error_range=error_range)\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/simulation.py\u001b[0m in \u001b[0;36msimulate_subject\u001b[0;34m(parameters, values, gaze, n_repeats, subject, boundary, error_weight, error_range)\u001b[0m\n\u001b[1;32m     22\u001b[0m                                         \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboundary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                         \u001b[0merror_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                         error_range=error_range)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mrts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrunning_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/simulation.py\u001b[0m in \u001b[0;36msimulate_trial\u001b[0;34m(parameters, values, gaze, boundary, error_weight, error_range)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboundary\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdrifts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboundary\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mFPTs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvgauss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFPTs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Domain error in arguments.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Domain error in arguments."
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM individually...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close Figure to continue...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GLAM' object has no attribute 'prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45350e456e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Close Figure to continue...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLAM' object has no attribute 'prediction'"
     ]
    }
   ],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.1e-05,\n",
       "  'gamma': -0.77,\n",
       "  'SNR': 125.41,\n",
       "  's': 0.0081,\n",
       "  'tau': 0.01,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 1.6e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 290.78,\n",
       "  's': 0.006238,\n",
       "  'tau': 0.05,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.5e-05,\n",
       "  'gamma': -0.11,\n",
       "  'SNR': 230.96,\n",
       "  's': 0.008048,\n",
       "  'tau': 0.11,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.1e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 434.59,\n",
       "  's': 0.009583,\n",
       "  'tau': 0.1,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.2e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 165.04,\n",
       "  's': 0.005638,\n",
       "  'tau': 0.06,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.7e-05,\n",
       "  'gamma': -0.71,\n",
       "  'SNR': 83.7,\n",
       "  's': 0.005543,\n",
       "  'tau': 0.09,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 232.79,\n",
       "  's': 0.008216,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.1e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 99.14,\n",
       "  's': 0.005566,\n",
       "  'tau': 0.09,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 0.00011,\n",
       "  'gamma': -0.86,\n",
       "  'SNR': 49.13,\n",
       "  's': 0.005373,\n",
       "  'tau': 0.0,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 165.72,\n",
       "  's': 0.008702,\n",
       "  'tau': 0.06,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.8e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 326.55,\n",
       "  's': 0.008587,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 9e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 54.42,\n",
       "  's': 0.004899,\n",
       "  'tau': 0.02,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.4e-05,\n",
       "  'gamma': -0.56,\n",
       "  'SNR': 86.39,\n",
       "  's': 0.002529,\n",
       "  'tau': 0.0,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4e-05,\n",
       "  'gamma': -0.87,\n",
       "  'SNR': 232.26,\n",
       "  's': 0.00942,\n",
       "  'tau': 0.25,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 154.16,\n",
       "  's': 0.006544,\n",
       "  'tau': 0.04,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.6e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 127.67,\n",
       "  's': 0.007116,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 1.9e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 476.5,\n",
       "  's': 0.008507,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.8e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 177.22,\n",
       "  's': 0.005505,\n",
       "  'tau': 0.05,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.2e-05,\n",
       "  'gamma': -0.87,\n",
       "  'SNR': 340.23,\n",
       "  's': 0.008569,\n",
       "  'tau': 0.04,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.5e-05,\n",
       "  'gamma': -0.98,\n",
       "  'SNR': 228.98,\n",
       "  's': 0.008275,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.2e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 213.49,\n",
       "  's': 0.006526,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.6e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 288.26,\n",
       "  's': 0.009493,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 232.13,\n",
       "  's': 0.007639,\n",
       "  'tau': 0.07,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 133.67,\n",
       "  's': 0.006737,\n",
       "  'tau': 0.04,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 1.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 336.19,\n",
       "  's': 0.007432,\n",
       "  'tau': 0.02,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.9e-05,\n",
       "  'gamma': -0.71,\n",
       "  'SNR': 145.41,\n",
       "  's': 0.006367,\n",
       "  'tau': 0.06,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.9e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 141.85,\n",
       "  's': 0.004457,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.6e-05,\n",
       "  'gamma': -0.98,\n",
       "  'SNR': 259.96,\n",
       "  's': 0.010083,\n",
       "  'tau': 0.18,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 6.8e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 62.69,\n",
       "  's': 0.004352,\n",
       "  'tau': 0.11,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.7e-05,\n",
       "  'gamma': -0.98,\n",
       "  'SNR': 115.24,\n",
       "  's': 0.008492,\n",
       "  'tau': 0.05,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 7.2e-05,\n",
       "  'gamma': 0.27,\n",
       "  'SNR': 106.53,\n",
       "  's': 0.008452,\n",
       "  'tau': 0.01,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.6e-05,\n",
       "  'gamma': -0.94,\n",
       "  'SNR': 145.61,\n",
       "  's': 0.006249,\n",
       "  'tau': 0.01,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.4e-05,\n",
       "  'gamma': -0.94,\n",
       "  'SNR': 156.31,\n",
       "  's': 0.007018,\n",
       "  'tau': 0.0,\n",
       "  't0': array([0.])}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-24a3f3602e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams_participant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparams_participant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
