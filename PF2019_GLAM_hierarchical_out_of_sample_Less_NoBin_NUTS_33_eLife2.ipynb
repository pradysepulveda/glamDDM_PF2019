{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import arviz as az\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical GLAM estimation and out of sample prediction\n",
    "## eLife reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.735</td>\n",
       "      <td>110</td>\n",
       "      <td>131</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3559.258</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>0.490772</td>\n",
       "      <td>0.509228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3754.464</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>0.490893</td>\n",
       "      <td>0.509107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2431.751</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>0.639125</td>\n",
       "      <td>0.360875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2199.342</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.702232</td>\n",
       "      <td>0.297768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice        rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        1      0       0  4261.735           110           131  0.603448   \n",
       "1        1      1       1  3559.258            47            50  0.490772   \n",
       "2        1      2       1  3754.464            50            44  0.490893   \n",
       "3        1      3       0  2431.751            57            50  0.639125   \n",
       "4        1      4       0  2199.342            42            50  0.702232   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.396552  \n",
       "1  0.509228  \n",
       "2  0.509107  \n",
       "3  0.360875  \n",
       "4  0.297768  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_hierarchical_Less_NoBin_Gamma-11_NUTS_33_eLife2'\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataPF2019_Less_NoBin_33.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down the measures\n",
    "data['item_value_0'] = data['item_value_0']/10\n",
    "data['item_value_1'] = data['item_value_1']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[ (data['subject'] != 1) & (data['subject'] != 13) & (data['subject'] != 16) & (data['subject'] != 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1680 trials) and test (1680 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 17, 18, 19, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 17, 18, 19, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we renumber subject data for proper sequence\n",
    "train_data2 = train_data.replace(train_data.subject.unique(), list(range(len(train_data.subject.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2.subject.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM hierarchically...\n",
      "Generating hierarchical model for 28 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 model(s) using NUTS...\n",
      "  Fitting model 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, tau_sd, tau_mu, SNR, SNR_sd, SNR_mu, gamma, gamma_sd, gamma_mu, v, v_sd, v_mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 22:03<00:00 Sampling 4 chains, 636 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 1325 seconds.\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 450 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7006987313077647, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 120 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 63 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM hierarchically...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data2)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_full.make_model('hierarchical', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>p_error</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>gamma_mu</th>\n",
       "      <th>gamma_sd</th>\n",
       "      <th>gamma</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>SNR</th>\n",
       "      <th>s</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>tau</th>\n",
       "      <th>t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>272.06</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>135.48</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>320.59</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>172.93</td>\n",
       "      <td>0.005582</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>100.59</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>193.39</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>152.67</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>73.48</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>138.15</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>312.20</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>94.12</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>210.56</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>144.62</td>\n",
       "      <td>0.007511</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>413.98</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>176.54</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>143.37</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>197.89</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>225.05</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>228.68</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>169.69</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>328.54</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>158.43</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>138.97</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>157.97</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>65.96</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>121.93</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>150.78</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>187.96</td>\n",
       "      <td>82.15</td>\n",
       "      <td>212.67</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b  p_error      v_mu      v_sd         v  gamma_mu  gamma_sd  gamma  \\\n",
       "0   1.0     0.05  0.000044  0.000018  0.000019     -0.99       0.0  -0.99   \n",
       "1   1.0     0.05  0.000044  0.000018  0.000042     -0.99       0.0  -0.99   \n",
       "2   1.0     0.05  0.000044  0.000018  0.000028     -0.99       0.0  -0.99   \n",
       "3   1.0     0.05  0.000044  0.000018  0.000032     -0.99       0.0  -0.99   \n",
       "4   1.0     0.05  0.000044  0.000018  0.000060     -0.99       0.0  -0.99   \n",
       "5   1.0     0.05  0.000044  0.000018  0.000033     -0.99       0.0  -0.99   \n",
       "6   1.0     0.05  0.000044  0.000018  0.000052     -0.99       0.0  -0.99   \n",
       "7   1.0     0.05  0.000044  0.000018  0.000104     -0.99       0.0  -0.99   \n",
       "8   1.0     0.05  0.000044  0.000018  0.000059     -0.99       0.0  -0.99   \n",
       "9   1.0     0.05  0.000044  0.000018  0.000030     -0.99       0.0  -0.99   \n",
       "10  1.0     0.05  0.000044  0.000018  0.000072     -0.99       0.0  -0.99   \n",
       "11  1.0     0.05  0.000044  0.000018  0.000047     -0.99       0.0  -0.99   \n",
       "12  1.0     0.05  0.000044  0.000018  0.000045     -0.99       0.0  -0.99   \n",
       "13  1.0     0.05  0.000044  0.000018  0.000023     -0.99       0.0  -0.99   \n",
       "14  1.0     0.05  0.000044  0.000018  0.000029     -0.99       0.0  -0.99   \n",
       "15  1.0     0.05  0.000044  0.000018  0.000043     -0.99       0.0  -0.99   \n",
       "16  1.0     0.05  0.000044  0.000018  0.000034     -0.99       0.0  -0.99   \n",
       "17  1.0     0.05  0.000044  0.000018  0.000039     -0.99       0.0  -0.99   \n",
       "18  1.0     0.05  0.000044  0.000018  0.000033     -0.99       0.0  -0.99   \n",
       "19  1.0     0.05  0.000044  0.000018  0.000039     -0.99       0.0  -0.99   \n",
       "20  1.0     0.05  0.000044  0.000018  0.000020     -0.99       0.0  -0.99   \n",
       "21  1.0     0.05  0.000044  0.000018  0.000041     -0.99       0.0  -0.99   \n",
       "22  1.0     0.05  0.000044  0.000018  0.000029     -0.99       0.0  -0.99   \n",
       "23  1.0     0.05  0.000044  0.000018  0.000053     -0.99       0.0  -0.99   \n",
       "24  1.0     0.05  0.000044  0.000018  0.000070     -0.99       0.0  -0.99   \n",
       "25  1.0     0.05  0.000044  0.000018  0.000059     -0.99       0.0  -0.99   \n",
       "26  1.0     0.05  0.000044  0.000018  0.000041     -0.99       0.0  -0.99   \n",
       "27  1.0     0.05  0.000044  0.000018  0.000045     -0.99       0.0  -0.99   \n",
       "\n",
       "    SNR_mu  SNR_sd     SNR         s  tau_mu  tau_sd   tau   t0  \n",
       "0   187.96   82.15  272.06  0.005314    0.79    0.33  0.61  0.0  \n",
       "1   187.96   82.15  135.48  0.006133    0.79    0.33  0.98  0.0  \n",
       "2   187.96   82.15  320.59  0.009237    0.79    0.33  0.95  0.0  \n",
       "3   187.96   82.15  172.93  0.005582    0.79    0.33  0.79  0.0  \n",
       "4   187.96   82.15  100.59  0.006212    0.79    0.33  1.04  0.0  \n",
       "5   187.96   82.15  193.39  0.007307    0.79    0.33  0.75  0.0  \n",
       "6   187.96   82.15  152.67  0.007362    0.79    0.33  1.05  0.0  \n",
       "7   187.96   82.15   73.48  0.006938    0.79    0.33  0.07  0.0  \n",
       "8   187.96   82.15  138.15  0.008888    0.79    0.33  0.71  0.0  \n",
       "9   187.96   82.15  312.20  0.008169    0.79    0.33  0.58  0.0  \n",
       "10  187.96   82.15   94.12  0.007501    0.79    0.33  0.33  0.0  \n",
       "11  187.96   82.15  210.56  0.010940    0.79    0.33  1.07  0.0  \n",
       "12  187.96   82.15  144.62  0.007511    0.79    0.33  0.89  0.0  \n",
       "13  187.96   82.15  413.98  0.009114    0.79    0.33  0.56  0.0  \n",
       "14  187.96   82.15  176.54  0.005787    0.79    0.33  0.69  0.0  \n",
       "15  187.96   82.15  143.37  0.008045    0.79    0.33  0.44  0.0  \n",
       "16  187.96   82.15  197.89  0.006405    0.79    0.33  0.67  0.0  \n",
       "17  187.96   82.15  225.05  0.009331    0.79    0.33  0.53  0.0  \n",
       "18  187.96   82.15  228.68  0.007504    0.79    0.33  0.70  0.0  \n",
       "19  187.96   82.15  169.69  0.006408    0.79    0.33  0.56  0.0  \n",
       "20  187.96   82.15  328.54  0.006552    0.79    0.33  0.25  0.0  \n",
       "21  187.96   82.15  158.43  0.006935    0.79    0.33  0.80  0.0  \n",
       "22  187.96   82.15  138.97  0.004235    0.79    0.33  0.38  0.0  \n",
       "23  187.96   82.15  157.97  0.008805    0.79    0.33  1.26  0.0  \n",
       "24  187.96   82.15   65.96  0.004467    0.79    0.33  1.34  0.0  \n",
       "25  187.96   82.15  121.93  0.008127    0.79    0.33  0.87  0.0  \n",
       "26  187.96   82.15  150.78  0.006191    0.79    0.33  0.38  0.0  \n",
       "27  187.96   82.15  212.67  0.006782    0.79    0.33  0.72  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate convergence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rhat parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.031246</td>\n",
       "      <td>1.023460</td>\n",
       "      <td>1.036745</td>\n",
       "      <td>1.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.024954</td>\n",
       "      <td>1.013227</td>\n",
       "      <td>1.003609</td>\n",
       "      <td>1.005671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.021241</td>\n",
       "      <td>1.012952</td>\n",
       "      <td>1.004673</td>\n",
       "      <td>1.005138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.024307</td>\n",
       "      <td>1.012361</td>\n",
       "      <td>1.014471</td>\n",
       "      <td>1.009292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.029046</td>\n",
       "      <td>1.013487</td>\n",
       "      <td>1.007661</td>\n",
       "      <td>1.010011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.028739</td>\n",
       "      <td>1.016366</td>\n",
       "      <td>1.014839</td>\n",
       "      <td>1.003189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.026743</td>\n",
       "      <td>1.011030</td>\n",
       "      <td>1.016567</td>\n",
       "      <td>1.014954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.029180</td>\n",
       "      <td>1.023068</td>\n",
       "      <td>1.005393</td>\n",
       "      <td>1.037748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.025737</td>\n",
       "      <td>1.009429</td>\n",
       "      <td>1.005676</td>\n",
       "      <td>1.007341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.029815</td>\n",
       "      <td>1.002947</td>\n",
       "      <td>1.003469</td>\n",
       "      <td>1.003449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.033168</td>\n",
       "      <td>1.028030</td>\n",
       "      <td>1.023446</td>\n",
       "      <td>1.008282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.033395</td>\n",
       "      <td>1.013760</td>\n",
       "      <td>1.009128</td>\n",
       "      <td>1.004895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.026925</td>\n",
       "      <td>1.009164</td>\n",
       "      <td>1.011217</td>\n",
       "      <td>1.005125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.026131</td>\n",
       "      <td>1.018273</td>\n",
       "      <td>1.014386</td>\n",
       "      <td>1.008593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.027320</td>\n",
       "      <td>1.021307</td>\n",
       "      <td>1.003228</td>\n",
       "      <td>1.004353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.025913</td>\n",
       "      <td>1.006197</td>\n",
       "      <td>1.012161</td>\n",
       "      <td>1.006646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.025292</td>\n",
       "      <td>1.005908</td>\n",
       "      <td>1.009811</td>\n",
       "      <td>1.010046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.021048</td>\n",
       "      <td>1.004109</td>\n",
       "      <td>1.006940</td>\n",
       "      <td>1.003598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.027666</td>\n",
       "      <td>1.012696</td>\n",
       "      <td>1.004551</td>\n",
       "      <td>1.015620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.030937</td>\n",
       "      <td>1.015515</td>\n",
       "      <td>1.015737</td>\n",
       "      <td>1.016003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.022585</td>\n",
       "      <td>1.009413</td>\n",
       "      <td>1.003943</td>\n",
       "      <td>1.006652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.028762</td>\n",
       "      <td>1.009074</td>\n",
       "      <td>1.004552</td>\n",
       "      <td>1.009864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.026400</td>\n",
       "      <td>1.003983</td>\n",
       "      <td>1.017670</td>\n",
       "      <td>1.010454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.029432</td>\n",
       "      <td>1.009890</td>\n",
       "      <td>1.017664</td>\n",
       "      <td>1.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.023833</td>\n",
       "      <td>1.011427</td>\n",
       "      <td>1.005251</td>\n",
       "      <td>1.008793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.031323</td>\n",
       "      <td>1.017633</td>\n",
       "      <td>1.001516</td>\n",
       "      <td>1.016847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.024370</td>\n",
       "      <td>1.010264</td>\n",
       "      <td>1.019284</td>\n",
       "      <td>1.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.029075</td>\n",
       "      <td>1.016467</td>\n",
       "      <td>1.014229</td>\n",
       "      <td>1.008930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         v       tau         s\n",
       "0   1.031246  1.023460  1.036745  1.003157\n",
       "1   1.024954  1.013227  1.003609  1.005671\n",
       "2   1.021241  1.012952  1.004673  1.005138\n",
       "3   1.024307  1.012361  1.014471  1.009292\n",
       "4   1.029046  1.013487  1.007661  1.010011\n",
       "5   1.028739  1.016366  1.014839  1.003189\n",
       "6   1.026743  1.011030  1.016567  1.014954\n",
       "7   1.029180  1.023068  1.005393  1.037748\n",
       "8   1.025737  1.009429  1.005676  1.007341\n",
       "9   1.029815  1.002947  1.003469  1.003449\n",
       "10  1.033168  1.028030  1.023446  1.008282\n",
       "11  1.033395  1.013760  1.009128  1.004895\n",
       "12  1.026925  1.009164  1.011217  1.005125\n",
       "13  1.026131  1.018273  1.014386  1.008593\n",
       "14  1.027320  1.021307  1.003228  1.004353\n",
       "15  1.025913  1.006197  1.012161  1.006646\n",
       "16  1.025292  1.005908  1.009811  1.010046\n",
       "17  1.021048  1.004109  1.006940  1.003598\n",
       "18  1.027666  1.012696  1.004551  1.015620\n",
       "19  1.030937  1.015515  1.015737  1.016003\n",
       "20  1.022585  1.009413  1.003943  1.006652\n",
       "21  1.028762  1.009074  1.004552  1.009864\n",
       "22  1.026400  1.003983  1.017670  1.010454\n",
       "23  1.029432  1.009890  1.017664  1.012633\n",
       "24  1.023833  1.011427  1.005251  1.008793\n",
       "25  1.031323  1.017633  1.001516  1.016847\n",
       "26  1.024370  1.010264  1.019284  1.001072\n",
       "27  1.029075  1.016467  1.014229  1.008930"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trace = glam_full.trace\n",
    "rhats_params = az.rhat(model_trace, method=\"folded\")\n",
    "\n",
    "rhats_params_df = pd.DataFrame()\n",
    "rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "rhats_params_df['v'] = rhats_params.v.values\n",
    "rhats_params_df['tau'] = rhats_params.tau.values\n",
    "rhats_params_df['s'] = rhats_params.s.values\n",
    "\n",
    "rhats_params_df  # if |rhat - 1 | < 0.05 (rhat: gelman-rubin statistic) the sampler converged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124.889399</td>\n",
       "      <td>238.234335</td>\n",
       "      <td>122.918111</td>\n",
       "      <td>513.877338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.725987</td>\n",
       "      <td>173.576365</td>\n",
       "      <td>165.521976</td>\n",
       "      <td>1214.664307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161.402191</td>\n",
       "      <td>637.501307</td>\n",
       "      <td>809.553823</td>\n",
       "      <td>453.210749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.304718</td>\n",
       "      <td>892.482689</td>\n",
       "      <td>198.508083</td>\n",
       "      <td>354.982896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152.676212</td>\n",
       "      <td>753.945853</td>\n",
       "      <td>534.744386</td>\n",
       "      <td>299.524574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>163.421322</td>\n",
       "      <td>377.231281</td>\n",
       "      <td>363.086226</td>\n",
       "      <td>983.309828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>161.461194</td>\n",
       "      <td>698.538146</td>\n",
       "      <td>353.217286</td>\n",
       "      <td>948.376223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185.316480</td>\n",
       "      <td>83.243647</td>\n",
       "      <td>578.804603</td>\n",
       "      <td>39.982195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>136.835153</td>\n",
       "      <td>578.654604</td>\n",
       "      <td>910.332900</td>\n",
       "      <td>1033.183257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>157.801678</td>\n",
       "      <td>292.906756</td>\n",
       "      <td>967.722595</td>\n",
       "      <td>336.901829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>208.957725</td>\n",
       "      <td>221.515377</td>\n",
       "      <td>101.808894</td>\n",
       "      <td>610.941662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>178.530777</td>\n",
       "      <td>549.770444</td>\n",
       "      <td>652.919299</td>\n",
       "      <td>891.581614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>152.908255</td>\n",
       "      <td>521.597744</td>\n",
       "      <td>321.102324</td>\n",
       "      <td>508.438760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>144.002240</td>\n",
       "      <td>561.290173</td>\n",
       "      <td>1448.354522</td>\n",
       "      <td>697.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>188.162214</td>\n",
       "      <td>1192.709062</td>\n",
       "      <td>939.309532</td>\n",
       "      <td>506.446781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>127.340599</td>\n",
       "      <td>255.541131</td>\n",
       "      <td>210.753761</td>\n",
       "      <td>661.754485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>98.417320</td>\n",
       "      <td>144.103782</td>\n",
       "      <td>463.900010</td>\n",
       "      <td>602.195990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>132.013807</td>\n",
       "      <td>425.256465</td>\n",
       "      <td>1118.078735</td>\n",
       "      <td>1120.969884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>165.473421</td>\n",
       "      <td>385.343178</td>\n",
       "      <td>166.515504</td>\n",
       "      <td>1594.285875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>164.764565</td>\n",
       "      <td>731.957386</td>\n",
       "      <td>299.109636</td>\n",
       "      <td>683.344770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>160.675567</td>\n",
       "      <td>801.317041</td>\n",
       "      <td>588.468698</td>\n",
       "      <td>449.709541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>146.047019</td>\n",
       "      <td>245.937231</td>\n",
       "      <td>817.309641</td>\n",
       "      <td>151.339085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>175.989933</td>\n",
       "      <td>454.493477</td>\n",
       "      <td>580.884667</td>\n",
       "      <td>170.342370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>139.093779</td>\n",
       "      <td>828.848203</td>\n",
       "      <td>298.684876</td>\n",
       "      <td>177.325999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>184.614885</td>\n",
       "      <td>170.636385</td>\n",
       "      <td>291.498773</td>\n",
       "      <td>158.868702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>133.868608</td>\n",
       "      <td>114.543391</td>\n",
       "      <td>247.034641</td>\n",
       "      <td>210.105087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>150.052070</td>\n",
       "      <td>511.354006</td>\n",
       "      <td>711.224252</td>\n",
       "      <td>665.703768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>164.573736</td>\n",
       "      <td>295.616136</td>\n",
       "      <td>540.872391</td>\n",
       "      <td>223.350189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gamma            v          tau            s\n",
       "0   124.889399   238.234335   122.918111   513.877338\n",
       "1   136.725987   173.576365   165.521976  1214.664307\n",
       "2   161.402191   637.501307   809.553823   453.210749\n",
       "3    95.304718   892.482689   198.508083   354.982896\n",
       "4   152.676212   753.945853   534.744386   299.524574\n",
       "5   163.421322   377.231281   363.086226   983.309828\n",
       "6   161.461194   698.538146   353.217286   948.376223\n",
       "7   185.316480    83.243647   578.804603    39.982195\n",
       "8   136.835153   578.654604   910.332900  1033.183257\n",
       "9   157.801678   292.906756   967.722595   336.901829\n",
       "10  208.957725   221.515377   101.808894   610.941662\n",
       "11  178.530777   549.770444   652.919299   891.581614\n",
       "12  152.908255   521.597744   321.102324   508.438760\n",
       "13  144.002240   561.290173  1448.354522   697.006359\n",
       "14  188.162214  1192.709062   939.309532   506.446781\n",
       "15  127.340599   255.541131   210.753761   661.754485\n",
       "16   98.417320   144.103782   463.900010   602.195990\n",
       "17  132.013807   425.256465  1118.078735  1120.969884\n",
       "18  165.473421   385.343178   166.515504  1594.285875\n",
       "19  164.764565   731.957386   299.109636   683.344770\n",
       "20  160.675567   801.317041   588.468698   449.709541\n",
       "21  146.047019   245.937231   817.309641   151.339085\n",
       "22  175.989933   454.493477   580.884667   170.342370\n",
       "23  139.093779   828.848203   298.684876   177.325999\n",
       "24  184.614885   170.636385   291.498773   158.868702\n",
       "25  133.868608   114.543391   247.034641   210.105087\n",
       "26  150.052070   511.354006   711.224252   665.703768\n",
       "27  164.573736   295.616136   540.872391   223.350189"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_model = az.ess(model_trace, relative=False)\n",
    "\n",
    "ess_params_df = pd.DataFrame()\n",
    "ess_params_df['gamma'] = ess_model.gamma.values\n",
    "ess_params_df['v'] = ess_model.v.values\n",
    "ess_params_df['tau'] = ess_model.tau.values\n",
    "ess_params_df['s'] = ess_model.s.values\n",
    "\n",
    "ess_params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Percentage of divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Divergent 636\n",
      "Percentage of Divergent 31.8\n"
     ]
    }
   ],
   "source": [
    "# display the total number and percentage of divergent\n",
    "divergent = model_trace['diverging']\n",
    "print('Number of Divergent %d' % divergent.nonzero()[0].size)\n",
    "divperc = divergent.nonzero()[0].size / len(model_trace) * 100\n",
    "print('Percentage of Divergent %.1f' % divperc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_rhatsParams'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_essParams'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Waic scores (Less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "          Estimate       SE\n",
       "elpd_waic -15233.22     0.00\n",
       "p_waic       48.10        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.waic(model_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WAIC 15233.222461067375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    }
   ],
   "source": [
    "model_waic = pm.waic(model_trace,scale = 'negative_log')\n",
    "print ('Model WAIC',model_waic.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:683: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "         Estimate       SE\n",
       "elpd_loo -15224.73     0.00\n",
       "p_loo       39.61        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.loo(model_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), model_waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM hierarchically...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
