{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Hierarchical GLAM estimation and out of sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.568396</td>\n",
       "      <td>0.431604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3371.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.237668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7466.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.532352</td>\n",
       "      <td>0.467648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.529736</td>\n",
       "      <td>0.470264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice      rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0      0.0    0.0     0.0  2009.0         110.0         131.0  0.568396   \n",
       "1      0.0    1.0     0.0  3371.0          47.0          50.0  0.762332   \n",
       "2      0.0    2.0     1.0  1700.0          50.0          44.0  0.446809   \n",
       "3      0.0    3.0     1.0  7466.0          57.0          50.0  0.532352   \n",
       "4      0.0    4.0     1.0  1889.0          42.0          50.0  0.529736   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.431604  \n",
       "1  0.237668  \n",
       "2  0.553191  \n",
       "3  0.467648  \n",
       "4  0.470264  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = 'hierarchical_More_NoBin_Gamma-11_NUTS_33'\n",
    "#data = pd.read_csv('data/PF2019_data/GlamDataPF2019_More_NoBin_33.csv')\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataFF2018_Like_NoBin_TEST.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1920 trials) and test (1920 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5398.0\n",
       "2      10254.0\n",
       "4       3581.0\n",
       "6       2128.0\n",
       "8       2434.0\n",
       "10      3431.0\n",
       "12      2264.0\n",
       "14      4420.0\n",
       "16      2578.0\n",
       "18      4365.0\n",
       "20      5608.0\n",
       "22      4357.0\n",
       "24      3293.0\n",
       "26      2743.0\n",
       "28      2364.0\n",
       "30      4363.0\n",
       "32      5752.0\n",
       "34      2780.0\n",
       "36      6016.0\n",
       "38     13395.0\n",
       "40      2537.0\n",
       "42      1619.0\n",
       "44      1357.0\n",
       "46      1295.0\n",
       "48      1539.0\n",
       "50      1641.0\n",
       "52      1399.0\n",
       "54      2077.0\n",
       "56      2894.0\n",
       "58      2923.0\n",
       "60      1653.0\n",
       "62      1651.0\n",
       "64      1974.0\n",
       "66      2072.0\n",
       "68      2096.0\n",
       "70      1402.0\n",
       "72      1342.0\n",
       "74      1656.0\n",
       "76      1997.0\n",
       "78      1851.0\n",
       "80      5859.0\n",
       "82      2559.0\n",
       "84      2053.0\n",
       "86      1325.0\n",
       "88      2057.0\n",
       "90      1676.0\n",
       "92      1523.0\n",
       "94      3258.0\n",
       "96      1785.0\n",
       "98      1620.0\n",
       "100     2821.0\n",
       "102     2143.0\n",
       "104     1635.0\n",
       "106     1497.0\n",
       "108     1409.0\n",
       "110     2282.0\n",
       "112     1484.0\n",
       "114     1386.0\n",
       "116     1569.0\n",
       "118     2294.0\n",
       "Name: rt, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data1 = train_data.loc[(train_data['subject'] == 15) | (train_data['subject'] == 15)  ] \n",
    "train_data1.rt.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.767765</td>\n",
       "      <td>0.232235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10254.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.780964</td>\n",
       "      <td>0.219036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3581.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.347021</td>\n",
       "      <td>0.652979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.573778</td>\n",
       "      <td>0.426222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2434.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.682827</td>\n",
       "      <td>0.317173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3431.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.465171</td>\n",
       "      <td>0.534829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.508392</td>\n",
       "      <td>0.491608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4420.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.811765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2578.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.235066</td>\n",
       "      <td>0.764934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4365.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.473769</td>\n",
       "      <td>0.526231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5608.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.164408</td>\n",
       "      <td>0.835592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4357.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.488606</td>\n",
       "      <td>0.511394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3293.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.252050</td>\n",
       "      <td>0.747950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.279985</td>\n",
       "      <td>0.720015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.732657</td>\n",
       "      <td>0.267343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4363.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.682558</td>\n",
       "      <td>0.317442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5752.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.533901</td>\n",
       "      <td>0.466099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2780.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.626259</td>\n",
       "      <td>0.373741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6016.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.395597</td>\n",
       "      <td>0.604403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13395.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.409108</td>\n",
       "      <td>0.590892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2537.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.488372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.518839</td>\n",
       "      <td>0.481161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.678703</td>\n",
       "      <td>0.321297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.692664</td>\n",
       "      <td>0.307336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.741391</td>\n",
       "      <td>0.258609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.607676</td>\n",
       "      <td>0.392324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.530379</td>\n",
       "      <td>0.469621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.378430</td>\n",
       "      <td>0.621570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>15.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.788918</td>\n",
       "      <td>0.211082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>15.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.509266</td>\n",
       "      <td>0.490734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.457350</td>\n",
       "      <td>0.542650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>15.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.627498</td>\n",
       "      <td>0.372502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.337386</td>\n",
       "      <td>0.662614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>15.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2072.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>0.622587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.351145</td>\n",
       "      <td>0.648855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.659772</td>\n",
       "      <td>0.340228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.625931</td>\n",
       "      <td>0.374069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>15.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.733696</td>\n",
       "      <td>0.266304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>15.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.358538</td>\n",
       "      <td>0.641462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>15.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.418152</td>\n",
       "      <td>0.581848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5859.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.748265</td>\n",
       "      <td>0.251735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>15.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.787774</td>\n",
       "      <td>0.212226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>15.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.757915</td>\n",
       "      <td>0.242085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>15.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.631698</td>\n",
       "      <td>0.368302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>15.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.429752</td>\n",
       "      <td>0.570248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.484487</td>\n",
       "      <td>0.515513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>15.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.671701</td>\n",
       "      <td>0.328299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>15.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3258.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.223003</td>\n",
       "      <td>0.776997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>0.692997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>15.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>0.565432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.221274</td>\n",
       "      <td>0.778726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>15.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.790481</td>\n",
       "      <td>0.209519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>15.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.735780</td>\n",
       "      <td>0.264220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>15.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.692719</td>\n",
       "      <td>0.307281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>15.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.624556</td>\n",
       "      <td>0.375444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2282.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.400526</td>\n",
       "      <td>0.599474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>15.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.413747</td>\n",
       "      <td>0.586253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>15.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.564935</td>\n",
       "      <td>0.435065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>15.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.455067</td>\n",
       "      <td>0.544933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>15.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.517678</td>\n",
       "      <td>0.482322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  trial  choice       rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0       15.0    0.0     0.0   5398.0         110.0         131.0  0.767765   \n",
       "2       15.0    2.0     1.0  10254.0          50.0          44.0  0.780964   \n",
       "4       15.0    4.0     1.0   3581.0          42.0          50.0  0.347021   \n",
       "6       15.0    6.0     0.0   2128.0          78.0          80.0  0.573778   \n",
       "8       15.0    8.0     0.0   2434.0          50.0          48.0  0.682827   \n",
       "10      15.0   10.0     0.0   3431.0          46.0          50.0  0.465171   \n",
       "12      15.0   12.0     0.0   2264.0          50.0          56.0  0.508392   \n",
       "14      15.0   14.0     1.0   4420.0         110.0         124.0  0.188235   \n",
       "16      15.0   16.0     1.0   2578.0          64.0          80.0  0.235066   \n",
       "18      15.0   18.0     1.0   4365.0         101.0         110.0  0.473769   \n",
       "20      15.0   20.0     1.0   5608.0          50.0          42.0  0.164408   \n",
       "22      15.0   22.0     1.0   4357.0          77.0          80.0  0.488606   \n",
       "24      15.0   24.0     1.0   3293.0          44.0          50.0  0.252050   \n",
       "26      15.0   26.0     1.0   2743.0          50.0          46.0  0.279985   \n",
       "28      15.0   28.0     0.0   2364.0         133.0         110.0  0.732657   \n",
       "30      15.0   30.0     0.0   4363.0         126.0         110.0  0.682558   \n",
       "32      15.0   32.0     0.0   5752.0         110.0         126.0  0.533901   \n",
       "34      15.0   34.0     0.0   2780.0          80.0          77.0  0.626259   \n",
       "36      15.0   36.0     1.0   6016.0          80.0          64.0  0.395597   \n",
       "38      15.0   38.0     0.0  13395.0         124.0         110.0  0.409108   \n",
       "40      15.0   40.0     1.0   2537.0         128.0         110.0  0.511628   \n",
       "42      15.0   42.0     0.0   1619.0          54.0          50.0  0.518839   \n",
       "44      15.0   44.0     0.0   1357.0         105.0         110.0  0.678703   \n",
       "46      15.0   46.0     0.0   1295.0          96.0          80.0  0.692664   \n",
       "48      15.0   48.0     0.0   1539.0         110.0         128.0  0.741391   \n",
       "50      15.0   50.0     0.0   1641.0         110.0         119.0  0.607676   \n",
       "52      15.0   52.0     0.0   1399.0          58.0          50.0  0.530379   \n",
       "54      15.0   54.0     1.0   2077.0          74.0          80.0  0.378430   \n",
       "56      15.0   56.0     0.0   2894.0          66.0          80.0  0.788918   \n",
       "58      15.0   58.0     1.0   2923.0          94.0         110.0  0.509266   \n",
       "60      15.0   60.0     1.0   1653.0          75.0          80.0  0.457350   \n",
       "62      15.0   62.0     0.0   1651.0          89.0         110.0  0.627498   \n",
       "64      15.0   64.0     1.0   1974.0         110.0          98.0  0.337386   \n",
       "66      15.0   66.0     1.0   2072.0         110.0          94.0  0.377413   \n",
       "68      15.0   68.0     1.0   2096.0          50.0          54.0  0.351145   \n",
       "70      15.0   70.0     0.0   1402.0          50.0          52.0  0.659772   \n",
       "72      15.0   72.0     0.0   1342.0          87.0         110.0  0.625931   \n",
       "74      15.0   74.0     0.0   1656.0          80.0          96.0  0.733696   \n",
       "76      15.0   76.0     1.0   1997.0          50.0          55.0  0.358538   \n",
       "78      15.0   78.0     1.0   1851.0          45.0          50.0  0.418152   \n",
       "80      15.0   80.0     0.0   5859.0          50.0          53.0  0.748265   \n",
       "82      15.0   82.0     0.0   2559.0          80.0          88.0  0.787774   \n",
       "84      15.0   84.0     0.0   2053.0         103.0         110.0  0.757915   \n",
       "86      15.0   86.0     0.0   1325.0          80.0          72.0  0.631698   \n",
       "88      15.0   88.0     1.0   2057.0          80.0          90.0  0.429752   \n",
       "90      15.0   90.0     1.0   1676.0          80.0          70.0  0.484487   \n",
       "92      15.0   92.0     0.0   1523.0          82.0          80.0  0.671701   \n",
       "94      15.0   94.0     1.0   3258.0          96.0         110.0  0.223003   \n",
       "96      15.0   96.0     1.0   1785.0          60.0          50.0  0.307003   \n",
       "98      15.0   98.0     1.0   1620.0         110.0          96.0  0.434568   \n",
       "100     15.0  100.0     1.0   2821.0          49.0          50.0  0.221274   \n",
       "102     15.0  102.0     0.0   2143.0          51.0          50.0  0.790481   \n",
       "104     15.0  104.0     0.0   1635.0          40.0          50.0  0.735780   \n",
       "106     15.0  106.0     0.0   1497.0          85.0          80.0  0.692719   \n",
       "108     15.0  108.0     0.0   1409.0          50.0          43.0  0.624556   \n",
       "110     15.0  110.0     1.0   2282.0          50.0          60.0  0.400526   \n",
       "112     15.0  112.0     1.0   1484.0         122.0         110.0  0.413747   \n",
       "114     15.0  114.0     0.0   1386.0          80.0          67.0  0.564935   \n",
       "116     15.0  116.0     1.0   1569.0         110.0         122.0  0.455067   \n",
       "118     15.0  118.0     1.0   2294.0         110.0         112.0  0.517678   \n",
       "\n",
       "       gaze_1  \n",
       "0    0.232235  \n",
       "2    0.219036  \n",
       "4    0.652979  \n",
       "6    0.426222  \n",
       "8    0.317173  \n",
       "10   0.534829  \n",
       "12   0.491608  \n",
       "14   0.811765  \n",
       "16   0.764934  \n",
       "18   0.526231  \n",
       "20   0.835592  \n",
       "22   0.511394  \n",
       "24   0.747950  \n",
       "26   0.720015  \n",
       "28   0.267343  \n",
       "30   0.317442  \n",
       "32   0.466099  \n",
       "34   0.373741  \n",
       "36   0.604403  \n",
       "38   0.590892  \n",
       "40   0.488372  \n",
       "42   0.481161  \n",
       "44   0.321297  \n",
       "46   0.307336  \n",
       "48   0.258609  \n",
       "50   0.392324  \n",
       "52   0.469621  \n",
       "54   0.621570  \n",
       "56   0.211082  \n",
       "58   0.490734  \n",
       "60   0.542650  \n",
       "62   0.372502  \n",
       "64   0.662614  \n",
       "66   0.622587  \n",
       "68   0.648855  \n",
       "70   0.340228  \n",
       "72   0.374069  \n",
       "74   0.266304  \n",
       "76   0.641462  \n",
       "78   0.581848  \n",
       "80   0.251735  \n",
       "82   0.212226  \n",
       "84   0.242085  \n",
       "86   0.368302  \n",
       "88   0.570248  \n",
       "90   0.515513  \n",
       "92   0.328299  \n",
       "94   0.776997  \n",
       "96   0.692997  \n",
       "98   0.565432  \n",
       "100  0.778726  \n",
       "102  0.209519  \n",
       "104  0.264220  \n",
       "106  0.307281  \n",
       "108  0.375444  \n",
       "110  0.599474  \n",
       "112  0.586253  \n",
       "114  0.435065  \n",
       "116  0.544933  \n",
       "118  0.482322  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM hierarchically...\n",
      "Generating hierarchical model for 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-40411a0e342f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/estimates/glam_PF2019_full_hierarchical_cv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msufix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hierarchical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ADVI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_advi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(self, kind, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mmake_models\u001b[0;34m(df, kind, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m                                                      \u001b[0merror_lls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error_lls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                                                      \u001b[0msubject_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                                                      **kwargs)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhierarchical_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mmake_hierarchical_model\u001b[0;34m(rts, gaze, values, error_lls, subject_idx, v_val, gamma_val, s_val, tau_val, t0_val, zerotol, error_weight, boundary, gamma_bounds)\u001b[0m\n\u001b[1;32m    285\u001b[0m                                            \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                                            \u001b[0merror_lls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_lls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                                            zerotol=zerotol))\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mglam_hierarchical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pymc3/distributions/distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name needs to be a string but got: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36mVar\u001b[0;34m(self, name, dist, data, total_size)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 var = MultiObservedRV(name=name, data=data, distribution=dist,\n\u001b[0;32m--> 827\u001b[0;31m                                       total_size=total_size, model=self)\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserved_RVs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, data, distribution, total_size, model)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         self.missing_values = [datum.missing_values for datum in self.data.values()\n\u001b[1;32m   1373\u001b[0m                                if datum.missing_values is not None]\n\u001b[0;32m-> 1374\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp_elemwiset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m         \u001b[0;31m# The logp might need scaling in minibatches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \u001b[0;31m# This is done in `Factor`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mlda_logp\u001b[0;34m(rt, gaze, values, error_lls, zerotol)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;31m# compute drifts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             drift = glam.components.expdrift(v[subject_idx, None],\n\u001b[0m\u001b[1;32m    265\u001b[0m                                              \u001b[0mtau\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                                              \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/theano/tensor/var.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_subtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m                 \u001b[0mrequired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequired\u001b[0m  \u001b[0;31m# We provided all inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, out_)\u001b[0m\n\u001b[1;32m   2195\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0mcheck_advanced_indexing_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m         \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2198\u001b[0m         \u001b[0;31m# When there are no arrays, we are not actually doing advanced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m         \u001b[0;31m# indexing, so __getitem__ will not return a copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM hierarchically...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data1)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_full.make_model('hierarchical', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='ADVI', n_advi=200000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM hierarchically...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
