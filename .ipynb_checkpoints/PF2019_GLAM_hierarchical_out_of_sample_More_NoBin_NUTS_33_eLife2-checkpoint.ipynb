{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import arviz as az\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Hierarchical GLAM estimation and out of sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1734.284</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6555.370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.240370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3174.566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2877.579</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608409</td>\n",
       "      <td>0.391591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1806.310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522849</td>\n",
       "      <td>0.477151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice        rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        1      0       1  1734.284             6             7  0.669090   \n",
       "1        1      1       0  6555.370             0             0  0.759630   \n",
       "2        1      2       0  3174.566             0             0  0.549371   \n",
       "3        1      3       1  2877.579             2             0  0.608409   \n",
       "4        1      4       1  1806.310             0             0  0.522849   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.330910  \n",
       "1  0.240370  \n",
       "2  0.450629  \n",
       "3  0.391591  \n",
       "4  0.477151  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_hierarchical_More_Bin_Gamma-11_NUTS_33_eLife'\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataPF2019_More_Bin_33.csv')\n",
    "#data = pd.read_csv('data/PF2019_data/GlamDataFF2018_Like_NoBin_TEST.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.loc[data[\"subject\"] < 3 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1920 trials) and test (1920 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1734.284</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3174.566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1806.310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522849</td>\n",
       "      <td>0.477151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3650.266</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>0.317966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1259.268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508019</td>\n",
       "      <td>0.491981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5698.027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582089</td>\n",
       "      <td>0.417911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2626.168</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666353</td>\n",
       "      <td>0.333647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1671.149</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.508035</td>\n",
       "      <td>0.491965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1527.826</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.473512</td>\n",
       "      <td>0.526488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2267.665</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.553242</td>\n",
       "      <td>0.446758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5571.061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575306</td>\n",
       "      <td>0.424694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1402.112</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.435523</td>\n",
       "      <td>0.564477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2065.604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528335</td>\n",
       "      <td>0.471665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1613.454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485035</td>\n",
       "      <td>0.514965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4895.517</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.301621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.688</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.511292</td>\n",
       "      <td>0.488708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2050.497</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.522393</td>\n",
       "      <td>0.477607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1635.473</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.477739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>4443.018</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.567061</td>\n",
       "      <td>0.432939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.903</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.558840</td>\n",
       "      <td>0.441160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1686.530</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.657603</td>\n",
       "      <td>0.342397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2244.929</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702233</td>\n",
       "      <td>0.297767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1361.319</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.482747</td>\n",
       "      <td>0.517253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2850.121</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.698865</td>\n",
       "      <td>0.301135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1391.672</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.547368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1582.340</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559501</td>\n",
       "      <td>0.440499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2184.782</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581910</td>\n",
       "      <td>0.418090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2890.742</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530453</td>\n",
       "      <td>0.469547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1901.984</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.418559</td>\n",
       "      <td>0.581441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2545.418</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.576064</td>\n",
       "      <td>0.423936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4251.426</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.503628</td>\n",
       "      <td>0.496372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4601.336</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.477015</td>\n",
       "      <td>0.522985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3649.435</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.416827</td>\n",
       "      <td>0.583173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3708.628</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.451137</td>\n",
       "      <td>0.548863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>5089.783</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.624277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>6969.709</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.424717</td>\n",
       "      <td>0.575283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>33</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1858.269</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.469035</td>\n",
       "      <td>0.530965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>3910.930</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.460076</td>\n",
       "      <td>0.539924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2087.100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532287</td>\n",
       "      <td>0.467713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>33</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>4085.180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.425232</td>\n",
       "      <td>0.574768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6549.821</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.568922</td>\n",
       "      <td>0.431078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>4550.765</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.449738</td>\n",
       "      <td>0.550262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>33</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>5756.064</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.479955</td>\n",
       "      <td>0.520045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>33</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4035.357</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.477174</td>\n",
       "      <td>0.522826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1844.621</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.497924</td>\n",
       "      <td>0.502076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>33</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3936.449</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.477459</td>\n",
       "      <td>0.522541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>33</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>11964.377</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.484599</td>\n",
       "      <td>0.515401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>33</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2743.440</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.529970</td>\n",
       "      <td>0.470030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>2532.466</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539153</td>\n",
       "      <td>0.460847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>6412.806</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.513330</td>\n",
       "      <td>0.486670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4007.788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.442161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>33</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>3685.316</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582175</td>\n",
       "      <td>0.417825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>33</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399461</td>\n",
       "      <td>0.600539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>33</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>4300.777</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.492486</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>7640.657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.593629</td>\n",
       "      <td>0.406371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>33</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>3341.929</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.476386</td>\n",
       "      <td>0.523614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>33</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2674.219</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.584644</td>\n",
       "      <td>0.415356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2848.448</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>0.552859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>33</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>2835.649</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.680958</td>\n",
       "      <td>0.319042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>33</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>3903.836</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.392389</td>\n",
       "      <td>0.607611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  trial  choice         rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0          1      0       1   1734.284             6             7  0.669090   \n",
       "2          1      2       0   3174.566             0             0  0.549371   \n",
       "4          1      4       1   1806.310             0             0  0.522849   \n",
       "6          1      6       1   3650.266             3             3  0.682034   \n",
       "8          1      8       1   1259.268             0             0  0.508019   \n",
       "10         1     10       1   5698.027             0             0  0.582089   \n",
       "12         1     12       1   2626.168             0             2  0.666353   \n",
       "14         1     14       1   1671.149             6             7  0.508035   \n",
       "16         1     16       1   1527.826             2             3  0.473512   \n",
       "18         1     18       1   2267.665             5             6  0.553242   \n",
       "20         1     20       0   5571.061             0             0  0.575306   \n",
       "22         1     22       1   1402.112             3             3  0.435523   \n",
       "24         1     24       1   2065.604             0             0  0.528335   \n",
       "26         1     26       1   1613.454             0             0  0.485035   \n",
       "28         1     28       0   4895.517             7             6  0.698379   \n",
       "30         1     30       1   2000.688             7             6  0.511292   \n",
       "32         1     32       1   2050.497             6             7  0.522393   \n",
       "34         1     34       1   1635.473             3             3  0.522261   \n",
       "36         1     36       0   4443.018             3             2  0.567061   \n",
       "38         1     38       1   1725.903             7             6  0.558840   \n",
       "40         1     40       0   1686.530             7             6  0.657603   \n",
       "42         1     42       0   2244.929             2             0  0.702233   \n",
       "44         1     44       1   1361.319             5             6  0.482747   \n",
       "46         1     46       0   2850.121             5             3  0.698865   \n",
       "48         1     48       1   1391.672             6             7  0.452632   \n",
       "50         1     50       1   1582.340             6             7  0.559501   \n",
       "52         1     52       0   2184.782             2             0  0.581910   \n",
       "54         1     54       1   2890.742             3             3  0.530453   \n",
       "56         1     56       1   1901.984             2             3  0.418559   \n",
       "58         1     58       1   2545.418             5             6  0.576064   \n",
       "..       ...    ...     ...        ...           ...           ...       ...   \n",
       "60        33     60       1   4251.426             3             3  0.503628   \n",
       "62        33     62       0   4601.336             5             6  0.477015   \n",
       "64        33     64       0   3649.435             6             5  0.416827   \n",
       "66        33     66       0   3708.628             6             5  0.451137   \n",
       "68        33     68       1   5089.783             0             2  0.375723   \n",
       "70        33     70       1   6969.709             0             2  0.424717   \n",
       "72        33     72       1   1858.269             4             6  0.469035   \n",
       "74        33     74       1   3910.930             3             5  0.460076   \n",
       "76        33     76       1   2087.100             0             2  0.532287   \n",
       "78        33     78       1   4085.180             0             0  0.425232   \n",
       "80        33     80       1   6549.821             0             2  0.568922   \n",
       "82        33     82       1   4550.765             3             5  0.449738   \n",
       "84        33     84       0   5756.064             5             6  0.479955   \n",
       "86        33     86       0   4035.357             3             3  0.477174   \n",
       "88        33     88       1   1844.621             3             5  0.497924   \n",
       "90        33     90       0   3936.449             3             2  0.477459   \n",
       "92        33     92       0  11964.377             4             3  0.484599   \n",
       "94        33     94       1   2743.440             5             6  0.529970   \n",
       "96        33     96       0   2532.466             2             0  0.539153   \n",
       "98        33     98       1   6412.806             6             5  0.513330   \n",
       "100       33    100       0   4007.788             0             0  0.557839   \n",
       "102       33    102       0   3685.316             2             0  0.582175   \n",
       "104       33    104       1   1988.182             0             0  0.399461   \n",
       "106       33    106       0   4300.777             4             3  0.492486   \n",
       "108       33    108       0   7640.657             0             0  0.593629   \n",
       "110       33    110       1   3341.929             0             2  0.476386   \n",
       "112       33    112       0   2674.219             7             6  0.584644   \n",
       "114       33    114       1   2848.448             3             2  0.447141   \n",
       "116       33    116       1   2835.649             6             7  0.680958   \n",
       "118       33    118       1   3903.836             6             7  0.392389   \n",
       "\n",
       "       gaze_1  \n",
       "0    0.330910  \n",
       "2    0.450629  \n",
       "4    0.477151  \n",
       "6    0.317966  \n",
       "8    0.491981  \n",
       "10   0.417911  \n",
       "12   0.333647  \n",
       "14   0.491965  \n",
       "16   0.526488  \n",
       "18   0.446758  \n",
       "20   0.424694  \n",
       "22   0.564477  \n",
       "24   0.471665  \n",
       "26   0.514965  \n",
       "28   0.301621  \n",
       "30   0.488708  \n",
       "32   0.477607  \n",
       "34   0.477739  \n",
       "36   0.432939  \n",
       "38   0.441160  \n",
       "40   0.342397  \n",
       "42   0.297767  \n",
       "44   0.517253  \n",
       "46   0.301135  \n",
       "48   0.547368  \n",
       "50   0.440499  \n",
       "52   0.418090  \n",
       "54   0.469547  \n",
       "56   0.581441  \n",
       "58   0.423936  \n",
       "..        ...  \n",
       "60   0.496372  \n",
       "62   0.522985  \n",
       "64   0.583173  \n",
       "66   0.548863  \n",
       "68   0.624277  \n",
       "70   0.575283  \n",
       "72   0.530965  \n",
       "74   0.539924  \n",
       "76   0.467713  \n",
       "78   0.574768  \n",
       "80   0.431078  \n",
       "82   0.550262  \n",
       "84   0.520045  \n",
       "86   0.522826  \n",
       "88   0.502076  \n",
       "90   0.522541  \n",
       "92   0.515401  \n",
       "94   0.470030  \n",
       "96   0.460847  \n",
       "98   0.486670  \n",
       "100  0.442161  \n",
       "102  0.417825  \n",
       "104  0.600539  \n",
       "106  0.507514  \n",
       "108  0.406371  \n",
       "110  0.523614  \n",
       "112  0.415356  \n",
       "114  0.552859  \n",
       "116  0.319042  \n",
       "118  0.607611  \n",
       "\n",
       "[1920 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n",
    "#test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we renumber subject data for proper sequence\n",
    "train_data2 = train_data.replace(train_data.subject.unique(), list(range(len(train_data.subject.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM hierarchically...\n",
      "Generating hierarchical model for 32 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 model(s) using NUTS...\n",
      "  Fitting model 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, tau_sd, tau_mu, SNR, SNR_sd, SNR_mu, gamma, gamma_sd, gamma_mu, v, v_sd, v_mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 1:44:00<00:00 Sampling 4 chains, 4 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 6242 seconds.\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM hierarchically...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data2)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_full.make_model('hierarchical', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>p_error</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>gamma_mu</th>\n",
       "      <th>gamma_sd</th>\n",
       "      <th>gamma</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>SNR</th>\n",
       "      <th>s</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>tau</th>\n",
       "      <th>t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>179.69</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>267.98</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>236.55</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>273.45</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>139.03</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>147.38</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>251.45</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>118.87</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>75.60</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>157.11</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>256.77</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>177.10</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>63.25</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>170.59</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>229.42</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>179.37</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>277.31</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>188.85</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>137.19</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>246.11</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>168.64</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>201.02</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>210.21</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>294.39</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>232.09</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>135.58</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>188.27</td>\n",
       "      <td>0.007913</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>80.23</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>80.24</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>194.22</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>141.63</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>200.52</td>\n",
       "      <td>86.95</td>\n",
       "      <td>198.97</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b  p_error      v_mu      v_sd         v  gamma_mu  gamma_sd  gamma  \\\n",
       "0   1.0     0.05  0.000046  0.000017  0.000056     -0.81      0.03  -0.82   \n",
       "1   1.0     0.05  0.000046  0.000017  0.000017     -0.81      0.03  -0.81   \n",
       "2   1.0     0.05  0.000046  0.000017  0.000041     -0.81      0.03  -0.80   \n",
       "3   1.0     0.05  0.000046  0.000017  0.000033     -0.81      0.03  -0.81   \n",
       "4   1.0     0.05  0.000046  0.000017  0.000038     -0.81      0.03  -0.81   \n",
       "5   1.0     0.05  0.000046  0.000017  0.000054     -0.81      0.03  -0.80   \n",
       "6   1.0     0.05  0.000046  0.000017  0.000039     -0.81      0.03  -0.80   \n",
       "7   1.0     0.05  0.000046  0.000017  0.000059     -0.81      0.03  -0.82   \n",
       "8   1.0     0.05  0.000046  0.000017  0.000092     -0.81      0.03  -0.81   \n",
       "9   1.0     0.05  0.000046  0.000017  0.000053     -0.81      0.03  -0.81   \n",
       "10  1.0     0.05  0.000046  0.000017  0.000025     -0.81      0.03  -0.81   \n",
       "11  1.0     0.05  0.000046  0.000017  0.000063     -0.81      0.03  -0.82   \n",
       "12  1.0     0.05  0.000046  0.000017  0.000035     -0.81      0.03  -0.81   \n",
       "13  1.0     0.05  0.000046  0.000017  0.000040     -0.81      0.03  -0.83   \n",
       "14  1.0     0.05  0.000046  0.000017  0.000035     -0.81      0.03  -0.80   \n",
       "15  1.0     0.05  0.000046  0.000017  0.000064     -0.81      0.03  -0.81   \n",
       "16  1.0     0.05  0.000046  0.000017  0.000024     -0.81      0.03  -0.80   \n",
       "17  1.0     0.05  0.000046  0.000017  0.000032     -0.81      0.03  -0.80   \n",
       "18  1.0     0.05  0.000046  0.000017  0.000056     -0.81      0.03  -0.80   \n",
       "19  1.0     0.05  0.000046  0.000017  0.000040     -0.81      0.03  -0.81   \n",
       "20  1.0     0.05  0.000046  0.000017  0.000047     -0.81      0.03  -0.48   \n",
       "21  1.0     0.05  0.000046  0.000017  0.000054     -0.81      0.03  -0.80   \n",
       "22  1.0     0.05  0.000046  0.000017  0.000033     -0.81      0.03  -0.80   \n",
       "23  1.0     0.05  0.000046  0.000017  0.000030     -0.81      0.03  -0.81   \n",
       "24  1.0     0.05  0.000046  0.000017  0.000027     -0.81      0.03  -0.80   \n",
       "25  1.0     0.05  0.000046  0.000017  0.000044     -0.81      0.03  -0.82   \n",
       "26  1.0     0.05  0.000046  0.000017  0.000041     -0.81      0.03  -0.80   \n",
       "27  1.0     0.05  0.000046  0.000017  0.000078     -0.81      0.03  -0.80   \n",
       "28  1.0     0.05  0.000046  0.000017  0.000086     -0.81      0.03  -0.80   \n",
       "29  1.0     0.05  0.000046  0.000017  0.000054     -0.81      0.03  -0.98   \n",
       "30  1.0     0.05  0.000046  0.000017  0.000047     -0.81      0.03  -0.80   \n",
       "31  1.0     0.05  0.000046  0.000017  0.000036     -0.81      0.03  -0.80   \n",
       "\n",
       "    SNR_mu  SNR_sd     SNR         s  tau_mu  tau_sd   tau   t0  \n",
       "0   200.52   86.95  179.69  0.009453    0.23    0.17  0.32  0.0  \n",
       "1   200.52   86.95  267.98  0.004527    0.23    0.17  0.49  0.0  \n",
       "2   200.52   86.95  236.55  0.007810    0.23    0.17  0.00  0.0  \n",
       "3   200.52   86.95  273.45  0.010459    0.23    0.17  0.20  0.0  \n",
       "4   200.52   86.95  139.03  0.005512    0.23    0.17  0.43  0.0  \n",
       "5   200.52   86.95  147.38  0.008666    0.23    0.17  0.33  0.0  \n",
       "6   200.52   86.95  251.45  0.009701    0.23    0.17  0.33  0.0  \n",
       "7   200.52   86.95  118.87  0.008230    0.23    0.17  0.06  0.0  \n",
       "8   200.52   86.95   75.60  0.006783    0.23    0.17  0.03  0.0  \n",
       "9   200.52   86.95  157.11  0.010241    0.23    0.17  0.11  0.0  \n",
       "10  200.52   86.95  256.77  0.008428    0.23    0.17  0.30  0.0  \n",
       "11  200.52   86.95  177.10  0.010161    0.23    0.17  0.01  0.0  \n",
       "12  200.52   86.95   63.25  0.002264    0.23    0.17  0.23  0.0  \n",
       "13  200.52   86.95  170.59  0.010014    0.23    0.17  0.29  0.0  \n",
       "14  200.52   86.95  229.42  0.007718    0.23    0.17  0.33  0.0  \n",
       "15  200.52   86.95  179.37  0.009906    0.23    0.17  0.01  0.0  \n",
       "16  200.52   86.95  277.31  0.006432    0.23    0.17  0.02  0.0  \n",
       "17  200.52   86.95  188.85  0.006698    0.23    0.17  0.02  0.0  \n",
       "18  200.52   86.95  137.19  0.007911    0.23    0.17  0.16  0.0  \n",
       "19  200.52   86.95  246.11  0.009779    0.23    0.17  0.01  0.0  \n",
       "20  200.52   86.95  168.64  0.008010    0.23    0.17  0.39  0.0  \n",
       "21  200.52   86.95  201.02  0.010967    0.23    0.17  0.04  0.0  \n",
       "22  200.52   86.95  210.21  0.007249    0.23    0.17  0.37  0.0  \n",
       "23  200.52   86.95  294.39  0.009024    0.23    0.17  0.00  0.0  \n",
       "24  200.52   86.95  232.09  0.007065    0.23    0.17  0.24  0.0  \n",
       "25  200.52   86.95  135.58  0.005842    0.23    0.17  0.04  0.0  \n",
       "26  200.52   86.95  188.27  0.007913    0.23    0.17  0.83  0.0  \n",
       "27  200.52   86.95   80.23  0.007155    0.23    0.17  0.20  0.0  \n",
       "28  200.52   86.95   80.24  0.006913    0.23    0.17  0.07  0.0  \n",
       "29  200.52   86.95  194.22  0.010038    0.23    0.17  0.17  0.0  \n",
       "30  200.52   86.95  141.63  0.005522    0.23    0.17  0.41  0.0  \n",
       "31  200.52   86.95  198.97  0.007127    0.23    0.17  0.20  0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate convergence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rhat parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.580543</td>\n",
       "      <td>1.008342</td>\n",
       "      <td>1.094452</td>\n",
       "      <td>1.168823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.485442</td>\n",
       "      <td>1.072481</td>\n",
       "      <td>1.086488</td>\n",
       "      <td>1.050681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.573895</td>\n",
       "      <td>1.036162</td>\n",
       "      <td>1.041294</td>\n",
       "      <td>1.029820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.385815</td>\n",
       "      <td>1.138275</td>\n",
       "      <td>1.088586</td>\n",
       "      <td>1.007212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.249048</td>\n",
       "      <td>1.058654</td>\n",
       "      <td>1.039042</td>\n",
       "      <td>1.057783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.250613</td>\n",
       "      <td>1.106026</td>\n",
       "      <td>1.040474</td>\n",
       "      <td>1.019018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.540787</td>\n",
       "      <td>1.107003</td>\n",
       "      <td>1.139187</td>\n",
       "      <td>1.030005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.474119</td>\n",
       "      <td>1.125956</td>\n",
       "      <td>1.092537</td>\n",
       "      <td>1.052604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.673244</td>\n",
       "      <td>1.063903</td>\n",
       "      <td>1.178116</td>\n",
       "      <td>1.021814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.598330</td>\n",
       "      <td>1.213007</td>\n",
       "      <td>1.128729</td>\n",
       "      <td>1.020204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.537780</td>\n",
       "      <td>1.284641</td>\n",
       "      <td>1.014836</td>\n",
       "      <td>1.037065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.845097</td>\n",
       "      <td>1.140218</td>\n",
       "      <td>1.083167</td>\n",
       "      <td>1.054408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.304812</td>\n",
       "      <td>1.060973</td>\n",
       "      <td>1.018366</td>\n",
       "      <td>1.286851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.433253</td>\n",
       "      <td>1.266325</td>\n",
       "      <td>1.136844</td>\n",
       "      <td>1.031052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.469838</td>\n",
       "      <td>1.097314</td>\n",
       "      <td>1.093229</td>\n",
       "      <td>1.015133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.460432</td>\n",
       "      <td>1.292096</td>\n",
       "      <td>1.077060</td>\n",
       "      <td>1.049240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.569182</td>\n",
       "      <td>1.072261</td>\n",
       "      <td>1.082139</td>\n",
       "      <td>1.010464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.627370</td>\n",
       "      <td>1.074062</td>\n",
       "      <td>1.138337</td>\n",
       "      <td>1.060487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.910480</td>\n",
       "      <td>1.139720</td>\n",
       "      <td>1.030701</td>\n",
       "      <td>1.051804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.251897</td>\n",
       "      <td>1.069377</td>\n",
       "      <td>1.169533</td>\n",
       "      <td>1.014556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.933243</td>\n",
       "      <td>1.264587</td>\n",
       "      <td>1.042323</td>\n",
       "      <td>1.061197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.835152</td>\n",
       "      <td>1.248552</td>\n",
       "      <td>1.023612</td>\n",
       "      <td>1.027263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.246409</td>\n",
       "      <td>1.092359</td>\n",
       "      <td>1.072153</td>\n",
       "      <td>1.034780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.357469</td>\n",
       "      <td>1.180596</td>\n",
       "      <td>1.010405</td>\n",
       "      <td>1.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.649512</td>\n",
       "      <td>1.132468</td>\n",
       "      <td>1.070327</td>\n",
       "      <td>1.018837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.374989</td>\n",
       "      <td>1.171511</td>\n",
       "      <td>1.092179</td>\n",
       "      <td>1.045810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.367506</td>\n",
       "      <td>1.149722</td>\n",
       "      <td>1.608353</td>\n",
       "      <td>1.032285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.377040</td>\n",
       "      <td>1.113888</td>\n",
       "      <td>1.015245</td>\n",
       "      <td>1.078978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.331715</td>\n",
       "      <td>1.106718</td>\n",
       "      <td>1.110343</td>\n",
       "      <td>1.027990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.601428</td>\n",
       "      <td>1.158979</td>\n",
       "      <td>1.062542</td>\n",
       "      <td>1.117339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.410368</td>\n",
       "      <td>1.158980</td>\n",
       "      <td>1.085614</td>\n",
       "      <td>1.079845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.429164</td>\n",
       "      <td>1.102206</td>\n",
       "      <td>1.027042</td>\n",
       "      <td>1.022995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         v       tau         s\n",
       "0   1.580543  1.008342  1.094452  1.168823\n",
       "1   1.485442  1.072481  1.086488  1.050681\n",
       "2   1.573895  1.036162  1.041294  1.029820\n",
       "3   1.385815  1.138275  1.088586  1.007212\n",
       "4   1.249048  1.058654  1.039042  1.057783\n",
       "5   1.250613  1.106026  1.040474  1.019018\n",
       "6   1.540787  1.107003  1.139187  1.030005\n",
       "7   1.474119  1.125956  1.092537  1.052604\n",
       "8   1.673244  1.063903  1.178116  1.021814\n",
       "9   1.598330  1.213007  1.128729  1.020204\n",
       "10  1.537780  1.284641  1.014836  1.037065\n",
       "11  1.845097  1.140218  1.083167  1.054408\n",
       "12  1.304812  1.060973  1.018366  1.286851\n",
       "13  1.433253  1.266325  1.136844  1.031052\n",
       "14  1.469838  1.097314  1.093229  1.015133\n",
       "15  1.460432  1.292096  1.077060  1.049240\n",
       "16  1.569182  1.072261  1.082139  1.010464\n",
       "17  1.627370  1.074062  1.138337  1.060487\n",
       "18  1.910480  1.139720  1.030701  1.051804\n",
       "19  1.251897  1.069377  1.169533  1.014556\n",
       "20  1.933243  1.264587  1.042323  1.061197\n",
       "21  1.835152  1.248552  1.023612  1.027263\n",
       "22  1.246409  1.092359  1.072153  1.034780\n",
       "23  1.357469  1.180596  1.010405  1.027900\n",
       "24  1.649512  1.132468  1.070327  1.018837\n",
       "25  1.374989  1.171511  1.092179  1.045810\n",
       "26  1.367506  1.149722  1.608353  1.032285\n",
       "27  1.377040  1.113888  1.015245  1.078978\n",
       "28  1.331715  1.106718  1.110343  1.027990\n",
       "29  1.601428  1.158979  1.062542  1.117339\n",
       "30  1.410368  1.158980  1.085614  1.079845\n",
       "31  1.429164  1.102206  1.027042  1.022995"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trace = glam_full.trace\n",
    "rhats_params = az.rhat(model_trace, method=\"folded\")\n",
    "\n",
    "rhats_params_df = pd.DataFrame()\n",
    "rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "rhats_params_df['v'] = rhats_params.v.values\n",
    "rhats_params_df['tau'] = rhats_params.tau.values\n",
    "rhats_params_df['s'] = rhats_params.s.values\n",
    "\n",
    "rhats_params_df  # if |rhat - 1 | < 0.05 (rhat: gelman-rubin statistic) the sampler converged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.181521</td>\n",
       "      <td>12.026680</td>\n",
       "      <td>37.286309</td>\n",
       "      <td>22.859510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.310258</td>\n",
       "      <td>31.072743</td>\n",
       "      <td>18.731263</td>\n",
       "      <td>13.550428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.110439</td>\n",
       "      <td>11.852889</td>\n",
       "      <td>11.270867</td>\n",
       "      <td>35.480608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.213136</td>\n",
       "      <td>11.045820</td>\n",
       "      <td>38.102572</td>\n",
       "      <td>64.290529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.570845</td>\n",
       "      <td>33.410128</td>\n",
       "      <td>16.755138</td>\n",
       "      <td>40.626534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62.780367</td>\n",
       "      <td>20.518813</td>\n",
       "      <td>26.174689</td>\n",
       "      <td>65.553489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.939634</td>\n",
       "      <td>13.224574</td>\n",
       "      <td>11.463675</td>\n",
       "      <td>86.292749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.828323</td>\n",
       "      <td>7.762845</td>\n",
       "      <td>17.809040</td>\n",
       "      <td>10.323321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.431956</td>\n",
       "      <td>25.421697</td>\n",
       "      <td>11.437265</td>\n",
       "      <td>43.276290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.202344</td>\n",
       "      <td>7.956900</td>\n",
       "      <td>9.879972</td>\n",
       "      <td>18.068737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.003549</td>\n",
       "      <td>5.620906</td>\n",
       "      <td>58.033985</td>\n",
       "      <td>12.096980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.857119</td>\n",
       "      <td>11.815208</td>\n",
       "      <td>21.600095</td>\n",
       "      <td>51.482353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21.557491</td>\n",
       "      <td>12.337803</td>\n",
       "      <td>27.060292</td>\n",
       "      <td>5.810039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.663996</td>\n",
       "      <td>6.811396</td>\n",
       "      <td>14.888618</td>\n",
       "      <td>23.867433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26.206244</td>\n",
       "      <td>30.108327</td>\n",
       "      <td>9.712210</td>\n",
       "      <td>122.021655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.934063</td>\n",
       "      <td>7.050009</td>\n",
       "      <td>12.208074</td>\n",
       "      <td>18.113391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.321236</td>\n",
       "      <td>16.506580</td>\n",
       "      <td>49.363088</td>\n",
       "      <td>81.286581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.222773</td>\n",
       "      <td>21.027507</td>\n",
       "      <td>14.344394</td>\n",
       "      <td>23.906181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.296819</td>\n",
       "      <td>30.767875</td>\n",
       "      <td>24.951718</td>\n",
       "      <td>52.606741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.256248</td>\n",
       "      <td>20.491739</td>\n",
       "      <td>6.683892</td>\n",
       "      <td>38.591755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.593155</td>\n",
       "      <td>30.975423</td>\n",
       "      <td>20.403419</td>\n",
       "      <td>20.663762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.785793</td>\n",
       "      <td>7.984397</td>\n",
       "      <td>46.788345</td>\n",
       "      <td>24.524764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.929214</td>\n",
       "      <td>7.506661</td>\n",
       "      <td>20.061897</td>\n",
       "      <td>18.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.609424</td>\n",
       "      <td>7.712265</td>\n",
       "      <td>7.714065</td>\n",
       "      <td>20.982626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.232625</td>\n",
       "      <td>12.907150</td>\n",
       "      <td>31.628441</td>\n",
       "      <td>81.540115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.875487</td>\n",
       "      <td>15.390719</td>\n",
       "      <td>9.471557</td>\n",
       "      <td>19.862638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.393136</td>\n",
       "      <td>8.616981</td>\n",
       "      <td>5.855200</td>\n",
       "      <td>84.991771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.375483</td>\n",
       "      <td>11.127621</td>\n",
       "      <td>28.479771</td>\n",
       "      <td>15.114119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.286436</td>\n",
       "      <td>10.168139</td>\n",
       "      <td>9.330824</td>\n",
       "      <td>27.101246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.202748</td>\n",
       "      <td>7.786556</td>\n",
       "      <td>10.796725</td>\n",
       "      <td>20.019220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.723087</td>\n",
       "      <td>14.508746</td>\n",
       "      <td>19.542558</td>\n",
       "      <td>13.107334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.048946</td>\n",
       "      <td>17.025293</td>\n",
       "      <td>12.135618</td>\n",
       "      <td>65.512209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gamma          v        tau           s\n",
       "0    8.181521  12.026680  37.286309   22.859510\n",
       "1    7.310258  31.072743  18.731263   13.550428\n",
       "2    6.110439  11.852889  11.270867   35.480608\n",
       "3   12.213136  11.045820  38.102572   64.290529\n",
       "4    6.570845  33.410128  16.755138   40.626534\n",
       "5   62.780367  20.518813  26.174689   65.553489\n",
       "6    5.939634  13.224574  11.463675   86.292749\n",
       "7    6.828323   7.762845  17.809040   10.323321\n",
       "8    7.431956  25.421697  11.437265   43.276290\n",
       "9    6.202344   7.956900   9.879972   18.068737\n",
       "10  17.003549   5.620906  58.033985   12.096980\n",
       "11   5.857119  11.815208  21.600095   51.482353\n",
       "12  21.557491  12.337803  27.060292    5.810039\n",
       "13  10.663996   6.811396  14.888618   23.867433\n",
       "14  26.206244  30.108327   9.712210  122.021655\n",
       "15  13.934063   7.050009  12.208074   18.113391\n",
       "16   8.321236  16.506580  49.363088   81.286581\n",
       "17   7.222773  21.027507  14.344394   23.906181\n",
       "18   5.296819  30.767875  24.951718   52.606741\n",
       "19   9.256248  20.491739   6.683892   38.591755\n",
       "20   5.593155  30.975423  20.403419   20.663762\n",
       "21   5.785793   7.984397  46.788345   24.524764\n",
       "22  12.929214   7.506661  20.061897   18.001095\n",
       "23  11.609424   7.712265   7.714065   20.982626\n",
       "24   6.232625  12.907150  31.628441   81.540115\n",
       "25   9.875487  15.390719   9.471557   19.862638\n",
       "26   6.393136   8.616981   5.855200   84.991771\n",
       "27  28.375483  11.127621  28.479771   15.114119\n",
       "28  12.286436  10.168139   9.330824   27.101246\n",
       "29   6.202748   7.786556  10.796725   20.019220\n",
       "30   7.723087  14.508746  19.542558   13.107334\n",
       "31   7.048946  17.025293  12.135618   65.512209"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_model = az.ess(model_trace, relative=False)\n",
    "\n",
    "ess_params_df = pd.DataFrame()\n",
    "ess_params_df['gamma'] = ess_model.gamma.values\n",
    "ess_params_df['v'] = ess_model.v.values\n",
    "ess_params_df['tau'] = ess_model.tau.values\n",
    "ess_params_df['s'] = ess_model.s.values\n",
    "\n",
    "ess_params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Percentage of divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Divergent 4\n",
      "Percentage of Divergent 0.2\n"
     ]
    }
   ],
   "source": [
    "# display the total number and percentage of divergent\n",
    "divergent = model_trace['diverging']\n",
    "print('Number of Divergent %d' % divergent.nonzero()[0].size)\n",
    "divperc = divergent.nonzero()[0].size / len(model_trace) * 100\n",
    "print('Percentage of Divergent %.1f' % divperc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_rhatsParams'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_essParams'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waic Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "           Estimate       SE\n",
       "-elpd_waic 17888.81     0.00\n",
       "p_waic        56.22        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.waic(model_trace,scale = 'negative_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WAIC 17888.814414354874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    }
   ],
   "source": [
    "model_waic = pm.waic(model_trace,scale = 'negative_log')\n",
    "print ('Model WAIC',model_waic.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:683: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "          Estimate       SE\n",
       "-elpd_loo 17868.90     0.00\n",
       "p_loo        36.30        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.loo(model_trace,scale = 'negative_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), model_waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_trace.s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            self.waic = np.array([pm.waic(trace=trace, model=model)\n",
    "                                 for (trace, model) in zip(self.trace, self.model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "waic() got an unexpected keyword argument 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-94b46965eb7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mcompute_waic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             self.waic = np.array([pm.waic(trace=trace, model=model)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymc3/stats/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 )\n\u001b[1;32m     37\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: waic() got an unexpected keyword argument 'trace'"
     ]
    }
   ],
   "source": [
    "glam_full.compute_waic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing WAIC scores for full model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "waic() got an unexpected keyword argument 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bc337b458ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Note: DIC computation does not work for ADVI fitted models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# But we are using WAIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Found old DIC scores in \"results/waic\". Skipping WAIC computation...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mcompute_waic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             self.waic = np.array([pm.waic(trace=trace, model=model)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymc3/stats/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 )\n\u001b[1;32m     37\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: waic() got an unexpected keyword argument 'trace'"
     ]
    }
   ],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GLAM' object has no attribute 'waic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5dded6f41c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLAM' object has no attribute 'waic'"
     ]
    }
   ],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loo() got an unexpected keyword argument 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f3d14e55e290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute LOO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/loo/glam_PF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msufix\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymc3/stats/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 )\n\u001b[1;32m     37\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: loo() got an unexpected keyword argument 'trace'"
     ]
    }
   ],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM hierarchically...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
