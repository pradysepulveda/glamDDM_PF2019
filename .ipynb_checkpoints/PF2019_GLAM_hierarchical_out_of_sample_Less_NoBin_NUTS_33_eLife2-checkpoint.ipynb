{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import arviz as az\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical GLAM estimation and out of sample prediction\n",
    "## eLife reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.735</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3559.258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490772</td>\n",
       "      <td>0.509228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3754.464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490893</td>\n",
       "      <td>0.509107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2431.751</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639125</td>\n",
       "      <td>0.360875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2199.342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702232</td>\n",
       "      <td>0.297768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice        rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        1      0       0  4261.735             6             7  0.603448   \n",
       "1        1      1       1  3559.258             0             0  0.490772   \n",
       "2        1      2       1  3754.464             0             0  0.490893   \n",
       "3        1      3       0  2431.751             2             0  0.639125   \n",
       "4        1      4       0  2199.342             0             0  0.702232   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.396552  \n",
       "1  0.509228  \n",
       "2  0.509107  \n",
       "3  0.360875  \n",
       "4  0.297768  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_hierarchical_Less_Bin_Gamma-11_NUTS_33_eLife'\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataPF2019_Less_Bin_33.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1920 trials) and test (1920 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we renumber subject data for proper sequence\n",
    "train_data2 = train_data.replace(train_data.subject.unique(), list(range(len(train_data.subject.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2.subject.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM hierarchically...\n",
      "Generating hierarchical model for 32 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 model(s) using NUTS...\n",
      "  Fitting model 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, tau_sd, tau_mu, SNR, SNR_sd, SNR_mu, gamma, gamma_sd, gamma_mu, v, v_sd, v_mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 1:59:21<00:00 Sampling 4 chains, 4 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 7164 seconds.\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7154512169286372, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6860421887311469, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM hierarchically...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data2)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_full.make_model('hierarchical', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>p_error</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>gamma_mu</th>\n",
       "      <th>gamma_sd</th>\n",
       "      <th>gamma</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>SNR</th>\n",
       "      <th>s</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>tau</th>\n",
       "      <th>t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>172.99</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>281.24</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>202.53</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>364.38</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>227.65</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>111.33</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>271.66</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>119.14</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>45.70</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>176.17</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>240.02</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>52.44</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>83.20</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>217.28</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>150.31</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>142.31</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>264.24</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>207.06</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>191.92</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>219.95</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>187.39</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>245.86</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>224.39</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>140.21</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>326.84</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>220.04</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>246.26</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>141.51</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>80.45</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>115.57</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>133.85</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>191.63</td>\n",
       "      <td>67.8</td>\n",
       "      <td>157.38</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b  p_error      v_mu      v_sd         v  gamma_mu  gamma_sd  gamma  \\\n",
       "0   1.0     0.05  0.000044  0.000023  0.000047     -0.64       0.1  -0.83   \n",
       "1   1.0     0.05  0.000044  0.000023  0.000019     -0.64       0.1  -0.95   \n",
       "2   1.0     0.05  0.000044  0.000023  0.000045     -0.64       0.1  -0.64   \n",
       "3   1.0     0.05  0.000044  0.000023  0.000027     -0.64       0.1  -0.58   \n",
       "4   1.0     0.05  0.000044  0.000023  0.000027     -0.64       0.1  -0.56   \n",
       "5   1.0     0.05  0.000044  0.000023  0.000066     -0.64       0.1  -0.62   \n",
       "6   1.0     0.05  0.000044  0.000023  0.000035     -0.64       0.1  -0.57   \n",
       "7   1.0     0.05  0.000044  0.000023  0.000047     -0.64       0.1  -0.59   \n",
       "8   1.0     0.05  0.000044  0.000023  0.000112     -0.64       0.1  -0.53   \n",
       "9   1.0     0.05  0.000044  0.000023  0.000059     -0.64       0.1  -0.52   \n",
       "10  1.0     0.05  0.000044  0.000023  0.000030     -0.64       0.1  -0.81   \n",
       "11  1.0     0.05  0.000044  0.000023  0.000082     -0.64       0.1  -0.70   \n",
       "12  1.0     0.05  0.000044  0.000023  0.000034     -0.64       0.1  -0.71   \n",
       "13  1.0     0.05  0.000044  0.000023  0.000034     -0.64       0.1  -0.58   \n",
       "14  1.0     0.05  0.000044  0.000023  0.000046     -0.64       0.1  -0.57   \n",
       "15  1.0     0.05  0.000044  0.000023  0.000049     -0.64       0.1  -0.53   \n",
       "16  1.0     0.05  0.000044  0.000023  0.000023     -0.64       0.1  -0.63   \n",
       "17  1.0     0.05  0.000044  0.000023  0.000030     -0.64       0.1  -0.63   \n",
       "18  1.0     0.05  0.000044  0.000023  0.000043     -0.64       0.1  -0.83   \n",
       "19  1.0     0.05  0.000044  0.000023  0.000047     -0.64       0.1  -0.58   \n",
       "20  1.0     0.05  0.000044  0.000023  0.000034     -0.64       0.1  -0.60   \n",
       "21  1.0     0.05  0.000044  0.000023  0.000041     -0.64       0.1  -0.54   \n",
       "22  1.0     0.05  0.000044  0.000023  0.000033     -0.64       0.1  -0.65   \n",
       "23  1.0     0.05  0.000044  0.000023  0.000041     -0.64       0.1  -0.63   \n",
       "24  1.0     0.05  0.000044  0.000023  0.000019     -0.64       0.1  -0.69   \n",
       "25  1.0     0.05  0.000044  0.000023  0.000040     -0.64       0.1  -0.62   \n",
       "26  1.0     0.05  0.000044  0.000023  0.000031     -0.64       0.1  -0.53   \n",
       "27  1.0     0.05  0.000044  0.000023  0.000065     -0.64       0.1  -0.16   \n",
       "28  1.0     0.05  0.000044  0.000023  0.000085     -0.64       0.1  -0.55   \n",
       "29  1.0     0.05  0.000044  0.000023  0.000068     -0.64       0.1  -0.63   \n",
       "30  1.0     0.05  0.000044  0.000023  0.000043     -0.64       0.1  -0.60   \n",
       "31  1.0     0.05  0.000044  0.000023  0.000045     -0.64       0.1  -0.67   \n",
       "\n",
       "    SNR_mu  SNR_sd     SNR         s  tau_mu  tau_sd   tau   t0  \n",
       "0   191.63    67.8  172.99  0.007310    0.76     0.5  0.65  0.0  \n",
       "1   191.63    67.8  281.24  0.005324    0.76     0.5  1.06  0.0  \n",
       "2   191.63    67.8  202.53  0.008786    0.76     0.5  0.10  0.0  \n",
       "3   191.63    67.8  364.38  0.009589    0.76     0.5  1.32  0.0  \n",
       "4   191.63    67.8  227.65  0.006119    0.76     0.5  0.84  0.0  \n",
       "5   191.63    67.8  111.33  0.007750    0.76     0.5  0.53  0.0  \n",
       "6   191.63    67.8  271.66  0.008658    0.76     0.5  1.44  0.0  \n",
       "7   191.63    67.8  119.14  0.010842    0.76     0.5  0.21  0.0  \n",
       "8   191.63    67.8   45.70  0.005171    0.76     0.5  0.00  0.0  \n",
       "9   191.63    67.8  176.17  0.009949    0.76     0.5  0.12  0.0  \n",
       "10  191.63    67.8  240.02  0.008403    0.76     0.5  0.52  0.0  \n",
       "11  191.63    67.8   52.44  0.007368    0.76     0.5  0.08  0.0  \n",
       "12  191.63    67.8   83.20  0.002651    0.76     0.5  0.23  0.0  \n",
       "13  191.63    67.8  217.28  0.011575    0.76     0.5  0.84  0.0  \n",
       "14  191.63    67.8  150.31  0.006893    0.76     0.5  0.32  0.0  \n",
       "15  191.63    67.8  142.31  0.008539    0.76     0.5  0.87  0.0  \n",
       "16  191.63    67.8  264.24  0.007938    0.76     0.5  0.04  0.0  \n",
       "17  191.63    67.8  207.06  0.005622    0.76     0.5  0.01  0.0  \n",
       "18  191.63    67.8  191.92  0.008050    0.76     0.5  0.57  0.0  \n",
       "19  191.63    67.8  219.95  0.009465    0.76     0.5  0.06  0.0  \n",
       "20  191.63    67.8  187.39  0.006713    0.76     0.5  0.97  0.0  \n",
       "21  191.63    67.8  245.86  0.011192    0.76     0.5  0.13  0.0  \n",
       "22  191.63    67.8  224.39  0.007340    0.76     0.5  0.82  0.0  \n",
       "23  191.63    67.8  140.21  0.005874    0.76     0.5  0.41  0.0  \n",
       "24  191.63    67.8  326.84  0.006055    0.76     0.5  0.51  0.0  \n",
       "25  191.63    67.8  220.04  0.006948    0.76     0.5  0.75  0.0  \n",
       "26  191.63    67.8  246.26  0.004827    0.76     0.5  0.39  0.0  \n",
       "27  191.63    67.8  141.51  0.009136    0.76     0.5  0.36  0.0  \n",
       "28  191.63    67.8   80.45  0.006837    0.76     0.5  0.39  0.0  \n",
       "29  191.63    67.8  115.57  0.008013    0.76     0.5  1.13  0.0  \n",
       "30  191.63    67.8  133.85  0.006702    0.76     0.5  0.61  0.0  \n",
       "31  191.63    67.8  157.38  0.007080    0.76     0.5  0.18  0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate convergence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rhat parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.738165</td>\n",
       "      <td>1.186639</td>\n",
       "      <td>1.258079</td>\n",
       "      <td>1.053812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.173723</td>\n",
       "      <td>1.073386</td>\n",
       "      <td>1.322334</td>\n",
       "      <td>1.025258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.334411</td>\n",
       "      <td>1.695364</td>\n",
       "      <td>1.255432</td>\n",
       "      <td>1.560893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.327429</td>\n",
       "      <td>1.123609</td>\n",
       "      <td>1.120194</td>\n",
       "      <td>1.100191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.286346</td>\n",
       "      <td>1.295520</td>\n",
       "      <td>1.082180</td>\n",
       "      <td>1.091589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.164065</td>\n",
       "      <td>1.206953</td>\n",
       "      <td>1.111541</td>\n",
       "      <td>1.118246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.384741</td>\n",
       "      <td>1.422557</td>\n",
       "      <td>1.158603</td>\n",
       "      <td>1.070011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.299173</td>\n",
       "      <td>1.137552</td>\n",
       "      <td>1.296579</td>\n",
       "      <td>1.144321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.244390</td>\n",
       "      <td>1.130278</td>\n",
       "      <td>1.091183</td>\n",
       "      <td>1.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.708875</td>\n",
       "      <td>1.490136</td>\n",
       "      <td>1.732245</td>\n",
       "      <td>1.055452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.506514</td>\n",
       "      <td>1.494403</td>\n",
       "      <td>1.232121</td>\n",
       "      <td>1.103332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.435639</td>\n",
       "      <td>1.390509</td>\n",
       "      <td>1.071399</td>\n",
       "      <td>1.491851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.131030</td>\n",
       "      <td>1.333850</td>\n",
       "      <td>1.310828</td>\n",
       "      <td>1.971607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.441978</td>\n",
       "      <td>1.198289</td>\n",
       "      <td>1.122589</td>\n",
       "      <td>1.026614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.260737</td>\n",
       "      <td>1.335530</td>\n",
       "      <td>1.748998</td>\n",
       "      <td>1.138868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.547820</td>\n",
       "      <td>1.101905</td>\n",
       "      <td>1.249992</td>\n",
       "      <td>1.095604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.474744</td>\n",
       "      <td>1.072979</td>\n",
       "      <td>1.103621</td>\n",
       "      <td>1.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.288350</td>\n",
       "      <td>1.202606</td>\n",
       "      <td>1.058500</td>\n",
       "      <td>1.109380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.406265</td>\n",
       "      <td>1.120684</td>\n",
       "      <td>1.480552</td>\n",
       "      <td>1.057057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.422416</td>\n",
       "      <td>1.103106</td>\n",
       "      <td>1.144513</td>\n",
       "      <td>1.028361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.392582</td>\n",
       "      <td>1.190109</td>\n",
       "      <td>1.120458</td>\n",
       "      <td>1.061949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.448734</td>\n",
       "      <td>1.223682</td>\n",
       "      <td>1.067834</td>\n",
       "      <td>1.024425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.372783</td>\n",
       "      <td>1.465415</td>\n",
       "      <td>1.059800</td>\n",
       "      <td>1.166080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.732325</td>\n",
       "      <td>1.150143</td>\n",
       "      <td>1.344181</td>\n",
       "      <td>1.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.245253</td>\n",
       "      <td>1.139087</td>\n",
       "      <td>1.187028</td>\n",
       "      <td>1.108931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.518559</td>\n",
       "      <td>1.092148</td>\n",
       "      <td>1.213002</td>\n",
       "      <td>1.056522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.264293</td>\n",
       "      <td>1.623856</td>\n",
       "      <td>1.176622</td>\n",
       "      <td>1.683894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.832332</td>\n",
       "      <td>1.384955</td>\n",
       "      <td>1.131628</td>\n",
       "      <td>1.160704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.195309</td>\n",
       "      <td>1.151634</td>\n",
       "      <td>1.107632</td>\n",
       "      <td>1.175125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.292214</td>\n",
       "      <td>1.054004</td>\n",
       "      <td>1.148345</td>\n",
       "      <td>1.091753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.362608</td>\n",
       "      <td>1.199653</td>\n",
       "      <td>1.230533</td>\n",
       "      <td>1.158029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.547720</td>\n",
       "      <td>1.057336</td>\n",
       "      <td>1.144088</td>\n",
       "      <td>1.026659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         v       tau         s\n",
       "0   1.738165  1.186639  1.258079  1.053812\n",
       "1   2.173723  1.073386  1.322334  1.025258\n",
       "2   1.334411  1.695364  1.255432  1.560893\n",
       "3   1.327429  1.123609  1.120194  1.100191\n",
       "4   1.286346  1.295520  1.082180  1.091589\n",
       "5   1.164065  1.206953  1.111541  1.118246\n",
       "6   1.384741  1.422557  1.158603  1.070011\n",
       "7   1.299173  1.137552  1.296579  1.144321\n",
       "8   1.244390  1.130278  1.091183  1.031746\n",
       "9   1.708875  1.490136  1.732245  1.055452\n",
       "10  1.506514  1.494403  1.232121  1.103332\n",
       "11  1.435639  1.390509  1.071399  1.491851\n",
       "12  1.131030  1.333850  1.310828  1.971607\n",
       "13  1.441978  1.198289  1.122589  1.026614\n",
       "14  1.260737  1.335530  1.748998  1.138868\n",
       "15  1.547820  1.101905  1.249992  1.095604\n",
       "16  1.474744  1.072979  1.103621  1.034561\n",
       "17  1.288350  1.202606  1.058500  1.109380\n",
       "18  1.406265  1.120684  1.480552  1.057057\n",
       "19  1.422416  1.103106  1.144513  1.028361\n",
       "20  1.392582  1.190109  1.120458  1.061949\n",
       "21  1.448734  1.223682  1.067834  1.024425\n",
       "22  1.372783  1.465415  1.059800  1.166080\n",
       "23  1.732325  1.150143  1.344181  1.035900\n",
       "24  1.245253  1.139087  1.187028  1.108931\n",
       "25  1.518559  1.092148  1.213002  1.056522\n",
       "26  1.264293  1.623856  1.176622  1.683894\n",
       "27  1.832332  1.384955  1.131628  1.160704\n",
       "28  1.195309  1.151634  1.107632  1.175125\n",
       "29  1.292214  1.054004  1.148345  1.091753\n",
       "30  1.362608  1.199653  1.230533  1.158029\n",
       "31  1.547720  1.057336  1.144088  1.026659"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trace = glam_full.trace\n",
    "rhats_params = az.rhat(model_trace, method=\"folded\")\n",
    "\n",
    "rhats_params_df = pd.DataFrame()\n",
    "rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "rhats_params_df['v'] = rhats_params.v.values\n",
    "rhats_params_df['tau'] = rhats_params.tau.values\n",
    "rhats_params_df['s'] = rhats_params.s.values\n",
    "\n",
    "rhats_params_df  # if |rhat - 1 | < 0.05 (rhat: gelman-rubin statistic) the sampler converged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.979555</td>\n",
       "      <td>8.318538</td>\n",
       "      <td>7.785854</td>\n",
       "      <td>15.629311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.987034</td>\n",
       "      <td>17.156684</td>\n",
       "      <td>21.820910</td>\n",
       "      <td>26.114229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.595718</td>\n",
       "      <td>9.242555</td>\n",
       "      <td>6.272830</td>\n",
       "      <td>10.747110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.788681</td>\n",
       "      <td>7.992378</td>\n",
       "      <td>11.012336</td>\n",
       "      <td>26.315296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.153438</td>\n",
       "      <td>8.908525</td>\n",
       "      <td>19.774377</td>\n",
       "      <td>28.270776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.522435</td>\n",
       "      <td>7.471950</td>\n",
       "      <td>11.518790</td>\n",
       "      <td>11.500141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.437503</td>\n",
       "      <td>17.248116</td>\n",
       "      <td>19.285776</td>\n",
       "      <td>34.679353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.340958</td>\n",
       "      <td>7.527140</td>\n",
       "      <td>8.175543</td>\n",
       "      <td>9.079810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.207144</td>\n",
       "      <td>8.944016</td>\n",
       "      <td>8.718288</td>\n",
       "      <td>9.337314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.489565</td>\n",
       "      <td>6.430078</td>\n",
       "      <td>5.843272</td>\n",
       "      <td>30.575584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.457206</td>\n",
       "      <td>5.388315</td>\n",
       "      <td>10.793149</td>\n",
       "      <td>12.086617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.594239</td>\n",
       "      <td>7.499977</td>\n",
       "      <td>10.120281</td>\n",
       "      <td>7.011257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.494762</td>\n",
       "      <td>6.101901</td>\n",
       "      <td>6.998893</td>\n",
       "      <td>4.703941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.971056</td>\n",
       "      <td>7.208283</td>\n",
       "      <td>10.801007</td>\n",
       "      <td>25.711556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.549522</td>\n",
       "      <td>10.460738</td>\n",
       "      <td>9.532189</td>\n",
       "      <td>22.576226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.599106</td>\n",
       "      <td>16.223189</td>\n",
       "      <td>9.184682</td>\n",
       "      <td>16.951879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21.313904</td>\n",
       "      <td>18.796127</td>\n",
       "      <td>11.161740</td>\n",
       "      <td>63.318204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.552022</td>\n",
       "      <td>13.577386</td>\n",
       "      <td>11.267331</td>\n",
       "      <td>59.032488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.774890</td>\n",
       "      <td>12.679880</td>\n",
       "      <td>6.410284</td>\n",
       "      <td>33.498190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.674954</td>\n",
       "      <td>9.877512</td>\n",
       "      <td>12.742051</td>\n",
       "      <td>16.364514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.872079</td>\n",
       "      <td>7.710853</td>\n",
       "      <td>8.405185</td>\n",
       "      <td>11.197148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.663115</td>\n",
       "      <td>30.341482</td>\n",
       "      <td>16.222897</td>\n",
       "      <td>70.959716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.750890</td>\n",
       "      <td>6.243821</td>\n",
       "      <td>11.298229</td>\n",
       "      <td>11.908603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.652832</td>\n",
       "      <td>10.826820</td>\n",
       "      <td>11.092686</td>\n",
       "      <td>14.993391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.325661</td>\n",
       "      <td>14.491744</td>\n",
       "      <td>15.025963</td>\n",
       "      <td>16.835687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.245151</td>\n",
       "      <td>16.892363</td>\n",
       "      <td>8.355400</td>\n",
       "      <td>22.147073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.452764</td>\n",
       "      <td>5.656508</td>\n",
       "      <td>8.863667</td>\n",
       "      <td>6.660505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.462094</td>\n",
       "      <td>6.956698</td>\n",
       "      <td>37.888331</td>\n",
       "      <td>9.693606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.248341</td>\n",
       "      <td>10.469193</td>\n",
       "      <td>11.796359</td>\n",
       "      <td>8.706462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.723354</td>\n",
       "      <td>8.500086</td>\n",
       "      <td>13.734700</td>\n",
       "      <td>9.966345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.976736</td>\n",
       "      <td>12.207620</td>\n",
       "      <td>7.070986</td>\n",
       "      <td>8.889513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.891280</td>\n",
       "      <td>33.772707</td>\n",
       "      <td>34.499800</td>\n",
       "      <td>103.524278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gamma          v        tau           s\n",
       "0    4.979555   8.318538   7.785854   15.629311\n",
       "1    6.987034  17.156684  21.820910   26.114229\n",
       "2    7.595718   9.242555   6.272830   10.747110\n",
       "3   24.788681   7.992378  11.012336   26.315296\n",
       "4    8.153438   8.908525  19.774377   28.270776\n",
       "5   15.522435   7.471950  11.518790   11.500141\n",
       "6   16.437503  17.248116  19.285776   34.679353\n",
       "7   21.340958   7.527140   8.175543    9.079810\n",
       "8   19.207144   8.944016   8.718288    9.337314\n",
       "9   10.489565   6.430078   5.843272   30.575584\n",
       "10   7.457206   5.388315  10.793149   12.086617\n",
       "11  10.594239   7.499977  10.120281    7.011257\n",
       "12   8.494762   6.101901   6.998893    4.703941\n",
       "13   6.971056   7.208283  10.801007   25.711556\n",
       "14  17.549522  10.460738   9.532189   22.576226\n",
       "15   7.599106  16.223189   9.184682   16.951879\n",
       "16  21.313904  18.796127  11.161740   63.318204\n",
       "17  13.552022  13.577386  11.267331   59.032488\n",
       "18   9.774890  12.679880   6.410284   33.498190\n",
       "19   6.674954   9.877512  12.742051   16.364514\n",
       "20   7.872079   7.710853   8.405185   11.197148\n",
       "21  14.663115  30.341482  16.222897   70.959716\n",
       "22  10.750890   6.243821  11.298229   11.908603\n",
       "23   7.652832  10.826820  11.092686   14.993391\n",
       "24  11.325661  14.491744  15.025963   16.835687\n",
       "25  13.245151  16.892363   8.355400   22.147073\n",
       "26  16.452764   5.656508   8.863667    6.660505\n",
       "27   5.462094   6.956698  37.888331    9.693606\n",
       "28   6.248341  10.469193  11.796359    8.706462\n",
       "29  11.723354   8.500086  13.734700    9.966345\n",
       "30  11.976736  12.207620   7.070986    8.889513\n",
       "31   5.891280  33.772707  34.499800  103.524278"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_model = az.ess(model_trace, relative=False)\n",
    "\n",
    "ess_params_df = pd.DataFrame()\n",
    "ess_params_df['gamma'] = ess_model.gamma.values\n",
    "ess_params_df['v'] = ess_model.v.values\n",
    "ess_params_df['tau'] = ess_model.tau.values\n",
    "ess_params_df['s'] = ess_model.s.values\n",
    "\n",
    "ess_params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Percentage of divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Divergent 4\n",
      "Percentage of Divergent 0.2\n"
     ]
    }
   ],
   "source": [
    "# display the total number and percentage of divergent\n",
    "divergent = model_trace['diverging']\n",
    "print('Number of Divergent %d' % divergent.nonzero()[0].size)\n",
    "divperc = divergent.nonzero()[0].size / len(model_trace) * 100\n",
    "print('Percentage of Divergent %.1f' % divperc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_rhatsParams'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_essParams'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Waic scores (Less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "          Estimate       SE\n",
       "elpd_waic -17833.35     0.00\n",
       "p_waic      181.74        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.waic(model_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WAIC 17833.34625021151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    }
   ],
   "source": [
    "model_waic = pm.waic(model_trace,scale = 'negative_log')\n",
    "print ('Model WAIC',model_waic.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:683: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "          Estimate       SE\n",
       "-elpd_loo 17711.52     0.00\n",
       "p_loo        59.91        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.loo(model_trace,scale = 'negative_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), model_waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing WAIC scores for full model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "waic() got an unexpected keyword argument 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bc337b458ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Note: DIC computation does not work for ADVI fitted models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# But we are using WAIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Found old DIC scores in \"results/waic\". Skipping WAIC computation...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mcompute_waic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_waic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             self.waic = np.array([pm.waic(trace=trace, model=model)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pymc3/stats/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 )\n\u001b[1;32m     37\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: waic() got an unexpected keyword argument 'trace'"
     ]
    }
   ],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM hierarchically...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
