{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import arviz as az\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical GLAM estimation and out of sample prediction\n",
    "## eLife reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.735</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3559.258</td>\n",
       "      <td>126</td>\n",
       "      <td>123</td>\n",
       "      <td>0.490772</td>\n",
       "      <td>0.509228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3754.464</td>\n",
       "      <td>123</td>\n",
       "      <td>129</td>\n",
       "      <td>0.490893</td>\n",
       "      <td>0.509107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2431.751</td>\n",
       "      <td>116</td>\n",
       "      <td>123</td>\n",
       "      <td>0.639125</td>\n",
       "      <td>0.360875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2199.342</td>\n",
       "      <td>131</td>\n",
       "      <td>123</td>\n",
       "      <td>0.702232</td>\n",
       "      <td>0.297768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice        rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        1      0       0  4261.735            63            42  0.603448   \n",
       "1        1      1       1  3559.258           126           123  0.490772   \n",
       "2        1      2       1  3754.464           123           129  0.490893   \n",
       "3        1      3       0  2431.751           116           123  0.639125   \n",
       "4        1      4       0  2199.342           131           123  0.702232   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.396552  \n",
       "1  0.509228  \n",
       "2  0.509107  \n",
       "3  0.360875  \n",
       "4  0.297768  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_hierarchical_Less_NoBin_Inv_Gamma-11_NUTS_33_eLife2'\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataPF2019_Less_Inv_NoBin_33.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down the measures\n",
    "data['item_value_0'] = data['item_value_0']/10\n",
    "data['item_value_1'] = data['item_value_1']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove conflictive participants\n",
    "data = data[ (data['subject'] != 1) & (data['subject'] != 13) & (data['subject'] != 16) & (data['subject'] != 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1680 trials) and test (1680 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 17, 18, 19, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 17, 18, 19, 21,\n",
       "       22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we renumber subject data for proper sequence\n",
    "train_data2 = train_data.replace(train_data.subject.unique(), list(range(len(train_data.subject.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM hierarchically...\n",
      "Generating hierarchical model for 28 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 model(s) using NUTS...\n",
      "  Fitting model 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, tau_sd, tau_mu, SNR, SNR_sd, SNR_mu, gamma, gamma_sd, gamma_mu, v, v_sd, v_mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 13:20<00:00 Sampling 4 chains, 12 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 802 seconds.\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM hierarchically...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data2)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_full.make_model('hierarchical', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>p_error</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>gamma_mu</th>\n",
       "      <th>gamma_sd</th>\n",
       "      <th>gamma</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>SNR</th>\n",
       "      <th>s</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>tau</th>\n",
       "      <th>t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.44</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>355.22</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>179.48</td>\n",
       "      <td>0.006870</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>391.61</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.13</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>183.16</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>114.28</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>212.11</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>109.44</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>51.51</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>198.98</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>235.78</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>124.29</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>188.52</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>132.74</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>314.89</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.18</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>246.24</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>230.59</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.14</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>203.72</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>219.83</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>234.21</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>213.50</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>444.64</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>183.01</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>158.46</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.13</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>146.03</td>\n",
       "      <td>0.008054</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>60.02</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>140.44</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>195.21</td>\n",
       "      <td>99.69</td>\n",
       "      <td>165.30</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b  p_error     v_mu      v_sd         v  gamma_mu  gamma_sd  gamma  \\\n",
       "0   1.0     0.05  0.00004  0.000017  0.000017      0.17      0.25   0.44   \n",
       "1   1.0     0.05  0.00004  0.000017  0.000038      0.17      0.25  -0.04   \n",
       "2   1.0     0.05  0.00004  0.000017  0.000024      0.17      0.25   0.10   \n",
       "3   1.0     0.05  0.00004  0.000017  0.000030      0.17      0.25   0.13   \n",
       "4   1.0     0.05  0.00004  0.000017  0.000055      0.17      0.25   0.17   \n",
       "5   1.0     0.05  0.00004  0.000017  0.000032      0.17      0.25   0.29   \n",
       "6   1.0     0.05  0.00004  0.000017  0.000051      0.17      0.25  -0.14   \n",
       "7   1.0     0.05  0.00004  0.000017  0.000097      0.17      0.25   0.56   \n",
       "8   1.0     0.05  0.00004  0.000017  0.000051      0.17      0.25   0.23   \n",
       "9   1.0     0.05  0.00004  0.000017  0.000028      0.17      0.25   0.36   \n",
       "10  1.0     0.05  0.00004  0.000017  0.000060      0.17      0.25  -0.01   \n",
       "11  1.0     0.05  0.00004  0.000017  0.000044      0.17      0.25   0.11   \n",
       "12  1.0     0.05  0.00004  0.000017  0.000044      0.17      0.25   0.28   \n",
       "13  1.0     0.05  0.00004  0.000017  0.000022      0.17      0.25   0.21   \n",
       "14  1.0     0.05  0.00004  0.000017  0.000025      0.17      0.25   0.18   \n",
       "15  1.0     0.05  0.00004  0.000017  0.000037      0.17      0.25   0.16   \n",
       "16  1.0     0.05  0.00004  0.000017  0.000032      0.17      0.25   0.14   \n",
       "17  1.0     0.05  0.00004  0.000017  0.000039      0.17      0.25   0.21   \n",
       "18  1.0     0.05  0.00004  0.000017  0.000031      0.17      0.25   0.10   \n",
       "19  1.0     0.05  0.00004  0.000017  0.000033      0.17      0.25   0.31   \n",
       "20  1.0     0.05  0.00004  0.000017  0.000017      0.17      0.25   0.63   \n",
       "21  1.0     0.05  0.00004  0.000017  0.000037      0.17      0.25  -0.00   \n",
       "22  1.0     0.05  0.00004  0.000017  0.000026      0.17      0.25   0.04   \n",
       "23  1.0     0.05  0.00004  0.000017  0.000052      0.17      0.25   0.13   \n",
       "24  1.0     0.05  0.00004  0.000017  0.000067      0.17      0.25   0.00   \n",
       "25  1.0     0.05  0.00004  0.000017  0.000056      0.17      0.25   0.28   \n",
       "26  1.0     0.05  0.00004  0.000017  0.000039      0.17      0.25   0.33   \n",
       "27  1.0     0.05  0.00004  0.000017  0.000039      0.17      0.25   0.27   \n",
       "\n",
       "    SNR_mu  SNR_sd     SNR         s  tau_mu  tau_sd   tau   t0  \n",
       "0   195.21   99.69  355.22  0.006010    0.92    0.28  0.92  0.0  \n",
       "1   195.21   99.69  179.48  0.006870    0.92    0.28  0.86  0.0  \n",
       "2   195.21   99.69  391.61  0.009539    0.92    0.28  0.87  0.0  \n",
       "3   195.21   99.69  183.16  0.005348    0.92    0.28  0.82  0.0  \n",
       "4   195.21   99.69  114.28  0.006607    0.92    0.28  0.99  0.0  \n",
       "5   195.21   99.69  212.11  0.007128    0.92    0.28  0.94  0.0  \n",
       "6   195.21   99.69  109.44  0.005660    0.92    0.28  0.88  0.0  \n",
       "7   195.21   99.69   51.51  0.005423    0.92    0.28  0.21  0.0  \n",
       "8   195.21   99.69  198.98  0.010273    0.92    0.28  0.99  0.0  \n",
       "9   195.21   99.69  235.78  0.006721    0.92    0.28  0.98  0.0  \n",
       "10  195.21   99.69  124.29  0.007607    0.92    0.28  0.98  0.0  \n",
       "11  195.21   99.69  188.52  0.008581    0.92    0.28  1.10  0.0  \n",
       "12  195.21   99.69  132.74  0.006235    0.92    0.28  0.76  0.0  \n",
       "13  195.21   99.69  314.89  0.006848    0.92    0.28  1.05  0.0  \n",
       "14  195.21   99.69  246.24  0.006115    0.92    0.28  0.89  0.0  \n",
       "15  195.21   99.69  230.59  0.007588    0.92    0.28  0.87  0.0  \n",
       "16  195.21   99.69  203.72  0.006265    0.92    0.28  0.93  0.0  \n",
       "17  195.21   99.69  219.83  0.010098    0.92    0.28  0.99  0.0  \n",
       "18  195.21   99.69  234.21  0.006788    0.92    0.28  1.02  0.0  \n",
       "19  195.21   99.69  213.50  0.006643    0.92    0.28  0.99  0.0  \n",
       "20  195.21   99.69  444.64  0.006621    0.92    0.28  1.02  0.0  \n",
       "21  195.21   99.69  183.01  0.006287    0.92    0.28  0.84  0.0  \n",
       "22  195.21   99.69  158.46  0.004453    0.92    0.28  0.52  0.0  \n",
       "23  195.21   99.69  146.03  0.008054    0.92    0.28  1.04  0.0  \n",
       "24  195.21   99.69   60.02  0.004160    0.92    0.28  0.88  0.0  \n",
       "25  195.21   99.69  150.00  0.008480    0.92    0.28  0.95  0.0  \n",
       "26  195.21   99.69  140.44  0.005346    0.92    0.28  0.81  0.0  \n",
       "27  195.21   99.69  165.30  0.006038    0.92    0.28  1.09  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate convergence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rhat parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000389</td>\n",
       "      <td>1.003135</td>\n",
       "      <td>1.002220</td>\n",
       "      <td>1.002702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.001295</td>\n",
       "      <td>1.001487</td>\n",
       "      <td>1.001795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002586</td>\n",
       "      <td>1.000121</td>\n",
       "      <td>1.002056</td>\n",
       "      <td>1.001367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.002167</td>\n",
       "      <td>1.002841</td>\n",
       "      <td>1.002268</td>\n",
       "      <td>1.000662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.002557</td>\n",
       "      <td>1.001707</td>\n",
       "      <td>1.004232</td>\n",
       "      <td>1.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.002611</td>\n",
       "      <td>1.005011</td>\n",
       "      <td>1.003965</td>\n",
       "      <td>0.999783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.004264</td>\n",
       "      <td>1.003308</td>\n",
       "      <td>1.003402</td>\n",
       "      <td>1.004766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000748</td>\n",
       "      <td>1.003308</td>\n",
       "      <td>1.004426</td>\n",
       "      <td>1.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000408</td>\n",
       "      <td>1.001130</td>\n",
       "      <td>1.004545</td>\n",
       "      <td>1.000456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.001654</td>\n",
       "      <td>1.001046</td>\n",
       "      <td>1.004247</td>\n",
       "      <td>1.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.001431</td>\n",
       "      <td>1.006915</td>\n",
       "      <td>1.005407</td>\n",
       "      <td>1.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000776</td>\n",
       "      <td>1.002144</td>\n",
       "      <td>1.000485</td>\n",
       "      <td>1.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.001634</td>\n",
       "      <td>1.004706</td>\n",
       "      <td>1.003073</td>\n",
       "      <td>1.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.001207</td>\n",
       "      <td>1.001280</td>\n",
       "      <td>1.000913</td>\n",
       "      <td>1.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.002797</td>\n",
       "      <td>1.001312</td>\n",
       "      <td>1.002433</td>\n",
       "      <td>1.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.002154</td>\n",
       "      <td>1.000816</td>\n",
       "      <td>1.001624</td>\n",
       "      <td>1.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000921</td>\n",
       "      <td>1.000370</td>\n",
       "      <td>1.000523</td>\n",
       "      <td>1.002469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.004341</td>\n",
       "      <td>1.002505</td>\n",
       "      <td>1.004090</td>\n",
       "      <td>1.002522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.003949</td>\n",
       "      <td>1.001535</td>\n",
       "      <td>1.003273</td>\n",
       "      <td>1.002064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.001382</td>\n",
       "      <td>1.003596</td>\n",
       "      <td>1.003607</td>\n",
       "      <td>1.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.005274</td>\n",
       "      <td>1.007432</td>\n",
       "      <td>1.006692</td>\n",
       "      <td>1.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.001752</td>\n",
       "      <td>1.003414</td>\n",
       "      <td>1.003131</td>\n",
       "      <td>1.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.004720</td>\n",
       "      <td>1.003057</td>\n",
       "      <td>1.005638</td>\n",
       "      <td>1.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.003557</td>\n",
       "      <td>1.004313</td>\n",
       "      <td>1.002428</td>\n",
       "      <td>1.002176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.002055</td>\n",
       "      <td>1.011147</td>\n",
       "      <td>1.002435</td>\n",
       "      <td>1.003132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.004213</td>\n",
       "      <td>1.000136</td>\n",
       "      <td>1.001271</td>\n",
       "      <td>1.001992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.001606</td>\n",
       "      <td>1.004083</td>\n",
       "      <td>1.003637</td>\n",
       "      <td>1.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.003255</td>\n",
       "      <td>1.000948</td>\n",
       "      <td>1.000511</td>\n",
       "      <td>1.001836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         v       tau         s\n",
       "0   1.000389  1.003135  1.002220  1.002702\n",
       "1   0.999988  1.001295  1.001487  1.001795\n",
       "2   1.002586  1.000121  1.002056  1.001367\n",
       "3   1.002167  1.002841  1.002268  1.000662\n",
       "4   1.002557  1.001707  1.004232  1.001394\n",
       "5   1.002611  1.005011  1.003965  0.999783\n",
       "6   1.004264  1.003308  1.003402  1.004766\n",
       "7   1.000748  1.003308  1.004426  1.001896\n",
       "8   1.000408  1.001130  1.004545  1.000456\n",
       "9   1.001654  1.001046  1.004247  1.002297\n",
       "10  1.001431  1.006915  1.005407  1.000252\n",
       "11  1.000776  1.002144  1.000485  1.001721\n",
       "12  1.001634  1.004706  1.003073  1.000666\n",
       "13  1.001207  1.001280  1.000913  1.000441\n",
       "14  1.002797  1.001312  1.002433  1.003518\n",
       "15  1.002154  1.000816  1.001624  1.000520\n",
       "16  1.000921  1.000370  1.000523  1.002469\n",
       "17  1.004341  1.002505  1.004090  1.002522\n",
       "18  1.003949  1.001535  1.003273  1.002064\n",
       "19  1.001382  1.003596  1.003607  1.001756\n",
       "20  1.005274  1.007432  1.006692  1.001336\n",
       "21  1.001752  1.003414  1.003131  1.001203\n",
       "22  1.004720  1.003057  1.005638  1.001755\n",
       "23  1.003557  1.004313  1.002428  1.002176\n",
       "24  1.002055  1.011147  1.002435  1.003132\n",
       "25  1.004213  1.000136  1.001271  1.001992\n",
       "26  1.001606  1.004083  1.003637  1.001221\n",
       "27  1.003255  1.000948  1.000511  1.001836"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trace = glam_full.trace\n",
    "rhats_params = az.rhat(model_trace, method=\"folded\")\n",
    "\n",
    "rhats_params_df = pd.DataFrame()\n",
    "rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "rhats_params_df['v'] = rhats_params.v.values\n",
    "rhats_params_df['tau'] = rhats_params.tau.values\n",
    "rhats_params_df['s'] = rhats_params.s.values\n",
    "\n",
    "rhats_params_df  # if |rhat - 1 | < 0.05 (rhat: gelman-rubin statistic) the sampler converged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623.649009</td>\n",
       "      <td>737.553633</td>\n",
       "      <td>898.072647</td>\n",
       "      <td>2288.358114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537.533772</td>\n",
       "      <td>1204.289575</td>\n",
       "      <td>1130.755536</td>\n",
       "      <td>1691.976206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>795.650382</td>\n",
       "      <td>872.163178</td>\n",
       "      <td>1370.347018</td>\n",
       "      <td>3014.392362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1126.771160</td>\n",
       "      <td>1020.938902</td>\n",
       "      <td>1219.547362</td>\n",
       "      <td>1950.793852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1617.668052</td>\n",
       "      <td>1352.344052</td>\n",
       "      <td>942.221304</td>\n",
       "      <td>1598.089873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1306.461944</td>\n",
       "      <td>969.692504</td>\n",
       "      <td>867.516508</td>\n",
       "      <td>1642.256136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>854.763671</td>\n",
       "      <td>947.209583</td>\n",
       "      <td>1209.418096</td>\n",
       "      <td>1153.650459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1184.376237</td>\n",
       "      <td>366.312619</td>\n",
       "      <td>410.180602</td>\n",
       "      <td>338.011735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>772.821689</td>\n",
       "      <td>1187.214468</td>\n",
       "      <td>878.694598</td>\n",
       "      <td>2165.708150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1556.595624</td>\n",
       "      <td>825.480628</td>\n",
       "      <td>827.960396</td>\n",
       "      <td>1949.279517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>890.722874</td>\n",
       "      <td>902.130597</td>\n",
       "      <td>898.557994</td>\n",
       "      <td>1128.475070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1223.569190</td>\n",
       "      <td>711.937424</td>\n",
       "      <td>698.394119</td>\n",
       "      <td>1819.229050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1623.821880</td>\n",
       "      <td>886.883493</td>\n",
       "      <td>1041.819413</td>\n",
       "      <td>1513.967960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1408.141993</td>\n",
       "      <td>583.544302</td>\n",
       "      <td>971.933503</td>\n",
       "      <td>2118.687085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1428.739713</td>\n",
       "      <td>1199.995564</td>\n",
       "      <td>1244.906509</td>\n",
       "      <td>1666.715270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1643.638044</td>\n",
       "      <td>895.520455</td>\n",
       "      <td>852.765179</td>\n",
       "      <td>2168.559224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1160.077150</td>\n",
       "      <td>1279.834079</td>\n",
       "      <td>1173.210002</td>\n",
       "      <td>1541.654079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1244.867359</td>\n",
       "      <td>1057.002471</td>\n",
       "      <td>1037.895179</td>\n",
       "      <td>2687.175973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1695.491773</td>\n",
       "      <td>1352.640686</td>\n",
       "      <td>823.645779</td>\n",
       "      <td>1979.687728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1469.087080</td>\n",
       "      <td>672.801931</td>\n",
       "      <td>1014.196635</td>\n",
       "      <td>1763.167284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000.044544</td>\n",
       "      <td>732.577653</td>\n",
       "      <td>600.342041</td>\n",
       "      <td>2576.758570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1395.179107</td>\n",
       "      <td>700.251764</td>\n",
       "      <td>1116.827752</td>\n",
       "      <td>1423.458587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1638.645928</td>\n",
       "      <td>805.464678</td>\n",
       "      <td>690.625739</td>\n",
       "      <td>1524.667748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1396.272531</td>\n",
       "      <td>1248.929330</td>\n",
       "      <td>1171.919701</td>\n",
       "      <td>1746.019868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1259.166224</td>\n",
       "      <td>540.775958</td>\n",
       "      <td>873.843465</td>\n",
       "      <td>772.039294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1943.937062</td>\n",
       "      <td>1241.833952</td>\n",
       "      <td>1230.982719</td>\n",
       "      <td>2355.500273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1221.155754</td>\n",
       "      <td>1097.072381</td>\n",
       "      <td>1065.114098</td>\n",
       "      <td>1607.146683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1472.044775</td>\n",
       "      <td>921.521898</td>\n",
       "      <td>639.938128</td>\n",
       "      <td>1895.544048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gamma            v          tau            s\n",
       "0   1623.649009   737.553633   898.072647  2288.358114\n",
       "1   1537.533772  1204.289575  1130.755536  1691.976206\n",
       "2    795.650382   872.163178  1370.347018  3014.392362\n",
       "3   1126.771160  1020.938902  1219.547362  1950.793852\n",
       "4   1617.668052  1352.344052   942.221304  1598.089873\n",
       "5   1306.461944   969.692504   867.516508  1642.256136\n",
       "6    854.763671   947.209583  1209.418096  1153.650459\n",
       "7   1184.376237   366.312619   410.180602   338.011735\n",
       "8    772.821689  1187.214468   878.694598  2165.708150\n",
       "9   1556.595624   825.480628   827.960396  1949.279517\n",
       "10   890.722874   902.130597   898.557994  1128.475070\n",
       "11  1223.569190   711.937424   698.394119  1819.229050\n",
       "12  1623.821880   886.883493  1041.819413  1513.967960\n",
       "13  1408.141993   583.544302   971.933503  2118.687085\n",
       "14  1428.739713  1199.995564  1244.906509  1666.715270\n",
       "15  1643.638044   895.520455   852.765179  2168.559224\n",
       "16  1160.077150  1279.834079  1173.210002  1541.654079\n",
       "17  1244.867359  1057.002471  1037.895179  2687.175973\n",
       "18  1695.491773  1352.640686   823.645779  1979.687728\n",
       "19  1469.087080   672.801931  1014.196635  1763.167284\n",
       "20  1000.044544   732.577653   600.342041  2576.758570\n",
       "21  1395.179107   700.251764  1116.827752  1423.458587\n",
       "22  1638.645928   805.464678   690.625739  1524.667748\n",
       "23  1396.272531  1248.929330  1171.919701  1746.019868\n",
       "24  1259.166224   540.775958   873.843465   772.039294\n",
       "25  1943.937062  1241.833952  1230.982719  2355.500273\n",
       "26  1221.155754  1097.072381  1065.114098  1607.146683\n",
       "27  1472.044775   921.521898   639.938128  1895.544048"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_model = az.ess(model_trace, relative=False)\n",
    "\n",
    "ess_params_df = pd.DataFrame()\n",
    "ess_params_df['gamma'] = ess_model.gamma.values\n",
    "ess_params_df['v'] = ess_model.v.values\n",
    "ess_params_df['tau'] = ess_model.tau.values\n",
    "ess_params_df['s'] = ess_model.s.values\n",
    "\n",
    "ess_params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Percentage of divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Divergent 12\n",
      "Percentage of Divergent 0.6\n"
     ]
    }
   ],
   "source": [
    "# display the total number and percentage of divergent\n",
    "divergent = model_trace['diverging']\n",
    "print('Number of Divergent %d' % divergent.nonzero()[0].size)\n",
    "divperc = divergent.nonzero()[0].size / len(model_trace) * 100\n",
    "print('Percentage of Divergent %.1f' % divperc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_rhatsParams'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_essParams'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waic scores (Less Inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "          Estimate       SE\n",
       "elpd_waic -15063.89     0.00\n",
       "p_waic       77.77        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.waic(model_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WAIC 15063.891935358417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    }
   ],
   "source": [
    "model_waic = pm.waic(model_trace,scale = 'negative_log')\n",
    "print ('Model WAIC',model_waic.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:683: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "         Estimate       SE\n",
       "elpd_loo -15036.08     0.00\n",
       "p_loo       49.96        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.loo(model_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), model_waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM hierarchically...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
