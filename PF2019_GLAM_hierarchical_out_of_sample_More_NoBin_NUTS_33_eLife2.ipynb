{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import arviz as az\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Hierarchical GLAM estimation and out of sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1734.284</td>\n",
       "      <td>110</td>\n",
       "      <td>131</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6555.370</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.240370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3174.566</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2877.579</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>0.608409</td>\n",
       "      <td>0.391591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1806.310</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.522849</td>\n",
       "      <td>0.477151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice        rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        1      0       1  1734.284           110           131  0.669090   \n",
       "1        1      1       0  6555.370            47            50  0.759630   \n",
       "2        1      2       0  3174.566            50            44  0.549371   \n",
       "3        1      3       1  2877.579            57            50  0.608409   \n",
       "4        1      4       1  1806.310            42            50  0.522849   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.330910  \n",
       "1  0.240370  \n",
       "2  0.450629  \n",
       "3  0.391591  \n",
       "4  0.477151  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_hierarchical_More_NoBin_Gamma-11_NUTS_33_eLife2'\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataPF2019_More_NoBin_33.csv')\n",
    "#data = pd.read_csv('data/PF2019_data/GlamDataFF2018_Like_NoBin_TEST.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.loc[data[\"subject\"] < 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale down the measures\n",
    "data['item_value_0'] = data['item_value_0']/10\n",
    "data['item_value_1'] = data['item_value_1']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[ (data['subject'] != 1) & (data['subject'] != 13) & (data['subject'] != 16) & (data['subject'] != 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1680 trials) and test (1680 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6228.547</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.575607</td>\n",
       "      <td>0.424393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4766.744</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.794866</td>\n",
       "      <td>0.205134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5673.265</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.830204</td>\n",
       "      <td>0.169796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7750.691</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.718690</td>\n",
       "      <td>0.281310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7758.235</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.419489</td>\n",
       "      <td>0.580511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10806.455</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.599278</td>\n",
       "      <td>0.400722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>22118.048</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.159116</td>\n",
       "      <td>0.840884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>24336.379</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.797748</td>\n",
       "      <td>0.202252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>7216.421</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.488293</td>\n",
       "      <td>0.511707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>20652.520</td>\n",
       "      <td>10.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.873862</td>\n",
       "      <td>0.126138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>15264.738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.564608</td>\n",
       "      <td>0.435392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>10502.538</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.686641</td>\n",
       "      <td>0.313359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>8371.705</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.575343</td>\n",
       "      <td>0.424657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>9256.349</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.773568</td>\n",
       "      <td>0.226432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>71123.695</td>\n",
       "      <td>13.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.832843</td>\n",
       "      <td>0.167157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>11246.800</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.763044</td>\n",
       "      <td>0.236956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>15507.063</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.409877</td>\n",
       "      <td>0.590123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>15060.043</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.522569</td>\n",
       "      <td>0.477431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>4962.179</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.625553</td>\n",
       "      <td>0.374447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>6745.102</td>\n",
       "      <td>12.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.536511</td>\n",
       "      <td>0.463489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>6980.156</td>\n",
       "      <td>12.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.540335</td>\n",
       "      <td>0.459665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>12685.652</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.521921</td>\n",
       "      <td>0.478079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>7470.982</td>\n",
       "      <td>10.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.501339</td>\n",
       "      <td>0.498661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>4605.276</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.486432</td>\n",
       "      <td>0.513568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>4717.351</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.678824</td>\n",
       "      <td>0.321176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4786.207</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.505419</td>\n",
       "      <td>0.494581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7383.357</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.504990</td>\n",
       "      <td>0.495010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>11765.399</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.569103</td>\n",
       "      <td>0.430897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3989.236</td>\n",
       "      <td>6.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.668575</td>\n",
       "      <td>0.331425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>10580.194</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.574560</td>\n",
       "      <td>0.425440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4251.426</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.503628</td>\n",
       "      <td>0.496372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4601.336</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.477015</td>\n",
       "      <td>0.522985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3649.435</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.416827</td>\n",
       "      <td>0.583173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3708.628</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.451137</td>\n",
       "      <td>0.548863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>5089.783</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.624277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>6969.709</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.424717</td>\n",
       "      <td>0.575283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>33</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1858.269</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.469035</td>\n",
       "      <td>0.530965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>3910.930</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.460076</td>\n",
       "      <td>0.539924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2087.100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.532287</td>\n",
       "      <td>0.467713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>33</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>4085.180</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.425232</td>\n",
       "      <td>0.574768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6549.821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.568922</td>\n",
       "      <td>0.431078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>4550.765</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.449738</td>\n",
       "      <td>0.550262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>33</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>5756.064</td>\n",
       "      <td>10.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.479955</td>\n",
       "      <td>0.520045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>33</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4035.357</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.477174</td>\n",
       "      <td>0.522826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1844.621</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.497924</td>\n",
       "      <td>0.502076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>33</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3936.449</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.477459</td>\n",
       "      <td>0.522541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>33</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>11964.377</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.484599</td>\n",
       "      <td>0.515401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>33</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2743.440</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.529970</td>\n",
       "      <td>0.470030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>2532.466</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.539153</td>\n",
       "      <td>0.460847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>6412.806</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.513330</td>\n",
       "      <td>0.486670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4007.788</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.442161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>33</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>3685.316</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.582175</td>\n",
       "      <td>0.417825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>33</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.182</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.399461</td>\n",
       "      <td>0.600539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>33</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>4300.777</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.492486</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>7640.657</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.593629</td>\n",
       "      <td>0.406371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>33</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>3341.929</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.476386</td>\n",
       "      <td>0.523614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>33</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2674.219</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.584644</td>\n",
       "      <td>0.415356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2848.448</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>0.552859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>33</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>2835.649</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.680958</td>\n",
       "      <td>0.319042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>33</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>3903.836</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.392389</td>\n",
       "      <td>0.607611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  trial  choice         rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0          2      0       1   6228.547          11.0          13.1  0.575607   \n",
       "2          2      2       0   4766.744           5.0           4.4  0.794866   \n",
       "4          2      4       1   5673.265           4.2           5.0  0.830204   \n",
       "6          2      6       0   7750.691           7.8           8.0  0.718690   \n",
       "8          2      8       1   7758.235           5.0           4.8  0.419489   \n",
       "10         2     10       1  10806.455           4.6           5.0  0.599278   \n",
       "12         2     12       0  22118.048           5.0           5.6  0.159116   \n",
       "14         2     14       1  24336.379          11.0          12.4  0.797748   \n",
       "16         2     16       1   7216.421           6.4           8.0  0.488293   \n",
       "18         2     18       1  20652.520          10.1          11.0  0.873862   \n",
       "20         2     20       0  15264.738           5.0           4.2  0.564608   \n",
       "22         2     22       0  10502.538           7.7           8.0  0.686641   \n",
       "24         2     24       1   8371.705           4.4           5.0  0.575343   \n",
       "26         2     26       0   9256.349           5.0           4.6  0.773568   \n",
       "28         2     28       0  71123.695          13.3          11.0  0.832843   \n",
       "30         2     30       1  11246.800          12.6          11.0  0.763044   \n",
       "32         2     32       1  15507.063          11.0          12.6  0.409877   \n",
       "34         2     34       1  15060.043           8.0           7.7  0.522569   \n",
       "36         2     36       0   4962.179           8.0           6.4  0.625553   \n",
       "38         2     38       1   6745.102          12.4          11.0  0.536511   \n",
       "40         2     40       0   6980.156          12.8          11.0  0.540335   \n",
       "42         2     42       1  12685.652           5.4           5.0  0.521921   \n",
       "44         2     44       1   7470.982          10.5          11.0  0.501339   \n",
       "46         2     46       0   4605.276           9.6           8.0  0.486432   \n",
       "48         2     48       1   4717.351          11.0          12.8  0.678824   \n",
       "50         2     50       1   4786.207          11.0          11.9  0.505419   \n",
       "52         2     52       0   7383.357           5.8           5.0  0.504990   \n",
       "54         2     54       1  11765.399           7.4           8.0  0.569103   \n",
       "56         2     56       1   3989.236           6.6           8.0  0.668575   \n",
       "58         2     58       1  10580.194           9.4          11.0  0.574560   \n",
       "..       ...    ...     ...        ...           ...           ...       ...   \n",
       "60        33     60       1   4251.426           7.5           8.0  0.503628   \n",
       "62        33     62       0   4601.336           8.9          11.0  0.477015   \n",
       "64        33     64       0   3649.435          11.0           9.8  0.416827   \n",
       "66        33     66       0   3708.628          11.0           9.4  0.451137   \n",
       "68        33     68       1   5089.783           5.0           5.4  0.375723   \n",
       "70        33     70       1   6969.709           5.0           5.2  0.424717   \n",
       "72        33     72       1   1858.269           8.7          11.0  0.469035   \n",
       "74        33     74       1   3910.930           8.0           9.6  0.460076   \n",
       "76        33     76       1   2087.100           5.0           5.5  0.532287   \n",
       "78        33     78       1   4085.180           4.5           5.0  0.425232   \n",
       "80        33     80       1   6549.821           5.0           5.3  0.568922   \n",
       "82        33     82       1   4550.765           8.0           8.8  0.449738   \n",
       "84        33     84       0   5756.064          10.3          11.0  0.479955   \n",
       "86        33     86       0   4035.357           8.0           7.2  0.477174   \n",
       "88        33     88       1   1844.621           8.0           9.0  0.497924   \n",
       "90        33     90       0   3936.449           8.0           7.0  0.477459   \n",
       "92        33     92       0  11964.377           8.2           8.0  0.484599   \n",
       "94        33     94       1   2743.440           9.6          11.0  0.529970   \n",
       "96        33     96       0   2532.466           6.0           5.0  0.539153   \n",
       "98        33     98       1   6412.806          11.0           9.6  0.513330   \n",
       "100       33    100       0   4007.788           4.9           5.0  0.557839   \n",
       "102       33    102       0   3685.316           5.1           5.0  0.582175   \n",
       "104       33    104       1   1988.182           4.0           5.0  0.399461   \n",
       "106       33    106       0   4300.777           8.5           8.0  0.492486   \n",
       "108       33    108       0   7640.657           5.0           4.3  0.593629   \n",
       "110       33    110       1   3341.929           5.0           6.0  0.476386   \n",
       "112       33    112       0   2674.219          12.2          11.0  0.584644   \n",
       "114       33    114       1   2848.448           8.0           6.7  0.447141   \n",
       "116       33    116       1   2835.649          11.0          12.2  0.680958   \n",
       "118       33    118       1   3903.836          11.0          11.2  0.392389   \n",
       "\n",
       "       gaze_1  \n",
       "0    0.424393  \n",
       "2    0.205134  \n",
       "4    0.169796  \n",
       "6    0.281310  \n",
       "8    0.580511  \n",
       "10   0.400722  \n",
       "12   0.840884  \n",
       "14   0.202252  \n",
       "16   0.511707  \n",
       "18   0.126138  \n",
       "20   0.435392  \n",
       "22   0.313359  \n",
       "24   0.424657  \n",
       "26   0.226432  \n",
       "28   0.167157  \n",
       "30   0.236956  \n",
       "32   0.590123  \n",
       "34   0.477431  \n",
       "36   0.374447  \n",
       "38   0.463489  \n",
       "40   0.459665  \n",
       "42   0.478079  \n",
       "44   0.498661  \n",
       "46   0.513568  \n",
       "48   0.321176  \n",
       "50   0.494581  \n",
       "52   0.495010  \n",
       "54   0.430897  \n",
       "56   0.331425  \n",
       "58   0.425440  \n",
       "..        ...  \n",
       "60   0.496372  \n",
       "62   0.522985  \n",
       "64   0.583173  \n",
       "66   0.548863  \n",
       "68   0.624277  \n",
       "70   0.575283  \n",
       "72   0.530965  \n",
       "74   0.539924  \n",
       "76   0.467713  \n",
       "78   0.574768  \n",
       "80   0.431078  \n",
       "82   0.550262  \n",
       "84   0.520045  \n",
       "86   0.522826  \n",
       "88   0.502076  \n",
       "90   0.522541  \n",
       "92   0.515401  \n",
       "94   0.470030  \n",
       "96   0.460847  \n",
       "98   0.486670  \n",
       "100  0.442161  \n",
       "102  0.417825  \n",
       "104  0.600539  \n",
       "106  0.507514  \n",
       "108  0.406371  \n",
       "110  0.523614  \n",
       "112  0.415356  \n",
       "114  0.552859  \n",
       "116  0.319042  \n",
       "118  0.607611  \n",
       "\n",
       "[1680 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n",
    "#test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we renumber subject data for proper sequence\n",
    "train_data2 = train_data.replace(train_data.subject.unique(), list(range(len(train_data.subject.unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM hierarchically...\n",
      "Generating hierarchical model for 28 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 model(s) using NUTS...\n",
      "  Fitting model 1 of 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau, tau_sd, tau_mu, SNR, SNR_sd, SNR_mu, gamma, gamma_sd, gamma_mu, v, v_sd, v_mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 19:16<00:00 Sampling 4 chains, 11 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 1157 seconds.\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6636409691977572, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 5 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.46660554724996517, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/!\\ Automatically setting parameter precision...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM hierarchically...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data2)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_full.make_model('hierarchical', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full_hierarchical_cv'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>p_error</th>\n",
       "      <th>v_mu</th>\n",
       "      <th>v_sd</th>\n",
       "      <th>v</th>\n",
       "      <th>gamma_mu</th>\n",
       "      <th>gamma_sd</th>\n",
       "      <th>gamma</th>\n",
       "      <th>SNR_mu</th>\n",
       "      <th>SNR_sd</th>\n",
       "      <th>SNR</th>\n",
       "      <th>s</th>\n",
       "      <th>tau_mu</th>\n",
       "      <th>tau_sd</th>\n",
       "      <th>tau</th>\n",
       "      <th>t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.16</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>271.24</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>301.57</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>342.61</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.30</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>206.63</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>154.42</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.29</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>245.12</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>155.85</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>49.72</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>133.28</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.37</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>255.26</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>107.57</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>203.70</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>239.78</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>372.63</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>189.02</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>138.37</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>160.77</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>195.60</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>178.18</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>334.94</td>\n",
       "      <td>0.009285</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>307.90</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>136.61</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>151.15</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>102.80</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.11</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>197.77</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>140.83</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>211.31</td>\n",
       "      <td>106.1</td>\n",
       "      <td>222.75</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      b  p_error      v_mu      v_sd         v  gamma_mu  gamma_sd  gamma  \\\n",
       "0   1.0     0.05  0.000042  0.000017  0.000017     -0.11      0.46   0.16   \n",
       "1   1.0     0.05  0.000042  0.000017  0.000034     -0.11      0.46  -0.51   \n",
       "2   1.0     0.05  0.000042  0.000017  0.000031     -0.11      0.46   0.21   \n",
       "3   1.0     0.05  0.000042  0.000017  0.000035     -0.11      0.46   0.30   \n",
       "4   1.0     0.05  0.000042  0.000017  0.000050     -0.11      0.46  -0.48   \n",
       "5   1.0     0.05  0.000042  0.000017  0.000037     -0.11      0.46   0.29   \n",
       "6   1.0     0.05  0.000042  0.000017  0.000051     -0.11      0.46  -0.59   \n",
       "7   1.0     0.05  0.000042  0.000017  0.000088     -0.11      0.46  -0.26   \n",
       "8   1.0     0.05  0.000042  0.000017  0.000050     -0.11      0.46  -0.49   \n",
       "9   1.0     0.05  0.000042  0.000017  0.000024     -0.11      0.46   0.37   \n",
       "10  1.0     0.05  0.000042  0.000017  0.000061     -0.11      0.46  -0.99   \n",
       "11  1.0     0.05  0.000042  0.000017  0.000040     -0.11      0.46  -0.42   \n",
       "12  1.0     0.05  0.000042  0.000017  0.000031     -0.11      0.46  -1.00   \n",
       "13  1.0     0.05  0.000042  0.000017  0.000023     -0.11      0.46   0.22   \n",
       "14  1.0     0.05  0.000042  0.000017  0.000028     -0.11      0.46  -0.75   \n",
       "15  1.0     0.05  0.000042  0.000017  0.000047     -0.11      0.46  -0.08   \n",
       "16  1.0     0.05  0.000042  0.000017  0.000043     -0.11      0.46  -0.06   \n",
       "17  1.0     0.05  0.000042  0.000017  0.000048     -0.11      0.46  -0.32   \n",
       "18  1.0     0.05  0.000042  0.000017  0.000034     -0.11      0.46  -0.63   \n",
       "19  1.0     0.05  0.000042  0.000017  0.000028     -0.11      0.46   0.00   \n",
       "20  1.0     0.05  0.000042  0.000017  0.000025     -0.11      0.46   0.33   \n",
       "21  1.0     0.05  0.000042  0.000017  0.000040     -0.11      0.46  -0.55   \n",
       "22  1.0     0.05  0.000042  0.000017  0.000037     -0.11      0.46   0.13   \n",
       "23  1.0     0.05  0.000042  0.000017  0.000082     -0.11      0.46  -0.91   \n",
       "24  1.0     0.05  0.000042  0.000017  0.000066     -0.11      0.46  -0.65   \n",
       "25  1.0     0.05  0.000042  0.000017  0.000051     -0.11      0.46   0.11   \n",
       "26  1.0     0.05  0.000042  0.000017  0.000045     -0.11      0.46  -0.20   \n",
       "27  1.0     0.05  0.000042  0.000017  0.000034     -0.11      0.46  -0.07   \n",
       "\n",
       "    SNR_mu  SNR_sd     SNR         s  tau_mu  tau_sd   tau   t0  \n",
       "0   211.31   106.1  271.24  0.004723     0.6     0.4  0.03  0.0  \n",
       "1   211.31   106.1  301.57  0.008951     0.6     0.4  1.02  0.0  \n",
       "2   211.31   106.1  342.61  0.010646     0.6     0.4  0.01  0.0  \n",
       "3   211.31   106.1  206.63  0.007283     0.6     0.4  0.32  0.0  \n",
       "4   211.31   106.1  154.42  0.007700     0.6     0.4  0.15  0.0  \n",
       "5   211.31   106.1  245.12  0.009987     0.6     0.4  0.03  0.0  \n",
       "6   211.31   106.1  155.85  0.007983     0.6     0.4  0.55  0.0  \n",
       "7   211.31   106.1   49.72  0.005133     0.6     0.4  0.05  0.0  \n",
       "8   211.31   106.1  133.28  0.007579     0.6     0.4  1.09  0.0  \n",
       "9   211.31   106.1  255.26  0.007056     0.6     0.4  0.69  0.0  \n",
       "10  211.31   106.1  107.57  0.006245     0.6     0.4  1.09  0.0  \n",
       "11  211.31   106.1  203.70  0.008385     0.6     0.4  0.78  0.0  \n",
       "12  211.31   106.1  239.78  0.007619     0.6     0.4  0.02  0.0  \n",
       "13  211.31   106.1  372.63  0.007469     0.6     0.4  0.35  0.0  \n",
       "14  211.31   106.1  189.02  0.005228     0.6     0.4  0.97  0.0  \n",
       "15  211.31   106.1  138.37  0.007522     0.6     0.4  0.65  0.0  \n",
       "16  211.31   106.1  160.77  0.007542     0.6     0.4  0.49  0.0  \n",
       "17  211.31   106.1  195.60  0.009807     0.6     0.4  1.34  0.0  \n",
       "18  211.31   106.1  178.18  0.006713     0.6     0.4  0.23  0.0  \n",
       "19  211.31   106.1  334.94  0.009285     0.6     0.4  0.55  0.0  \n",
       "20  211.31   106.1  307.90  0.006575     0.6     0.4  0.22  0.0  \n",
       "21  211.31   106.1  136.61  0.005491     0.6     0.4  0.38  0.0  \n",
       "22  211.31   106.1  151.15  0.006231     0.6     0.4  0.48  0.0  \n",
       "23  211.31   106.1   58.62  0.004790     0.6     0.4  0.30  0.0  \n",
       "24  211.31   106.1  102.80  0.006726     0.6     0.4  0.71  0.0  \n",
       "25  211.31   106.1  197.77  0.010033     0.6     0.4  0.32  0.0  \n",
       "26  211.31   106.1  140.83  0.006344     0.6     0.4  0.03  0.0  \n",
       "27  211.31   106.1  222.75  0.006691     0.6     0.4  0.56  0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_full.estimates)\n",
    "pd.DataFrame(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate convergence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rhat parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.041482</td>\n",
       "      <td>1.010669</td>\n",
       "      <td>1.056703</td>\n",
       "      <td>1.006579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.037471</td>\n",
       "      <td>1.092425</td>\n",
       "      <td>1.070733</td>\n",
       "      <td>1.056711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.079211</td>\n",
       "      <td>1.045275</td>\n",
       "      <td>1.047258</td>\n",
       "      <td>1.011098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.062372</td>\n",
       "      <td>1.026971</td>\n",
       "      <td>1.043778</td>\n",
       "      <td>1.046346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.026530</td>\n",
       "      <td>1.034618</td>\n",
       "      <td>1.027784</td>\n",
       "      <td>1.011045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.062316</td>\n",
       "      <td>1.017087</td>\n",
       "      <td>1.019890</td>\n",
       "      <td>1.004798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.012911</td>\n",
       "      <td>1.059059</td>\n",
       "      <td>1.039201</td>\n",
       "      <td>1.030079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.017544</td>\n",
       "      <td>1.105576</td>\n",
       "      <td>1.006274</td>\n",
       "      <td>1.109060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.008626</td>\n",
       "      <td>1.081852</td>\n",
       "      <td>1.077887</td>\n",
       "      <td>1.011102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.038091</td>\n",
       "      <td>1.041181</td>\n",
       "      <td>1.036396</td>\n",
       "      <td>1.011470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.016480</td>\n",
       "      <td>1.037194</td>\n",
       "      <td>1.046409</td>\n",
       "      <td>1.015252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.005403</td>\n",
       "      <td>1.071943</td>\n",
       "      <td>1.048311</td>\n",
       "      <td>1.027845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.026085</td>\n",
       "      <td>1.055248</td>\n",
       "      <td>1.024629</td>\n",
       "      <td>1.006545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.012193</td>\n",
       "      <td>1.007535</td>\n",
       "      <td>1.005631</td>\n",
       "      <td>1.055289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.026881</td>\n",
       "      <td>1.077103</td>\n",
       "      <td>1.053063</td>\n",
       "      <td>1.011152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.026627</td>\n",
       "      <td>1.045647</td>\n",
       "      <td>1.019683</td>\n",
       "      <td>1.010948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.013413</td>\n",
       "      <td>1.033669</td>\n",
       "      <td>1.026961</td>\n",
       "      <td>1.006505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.038865</td>\n",
       "      <td>1.058417</td>\n",
       "      <td>1.015053</td>\n",
       "      <td>1.010488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.074026</td>\n",
       "      <td>1.054437</td>\n",
       "      <td>1.039731</td>\n",
       "      <td>1.020782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.053366</td>\n",
       "      <td>1.071195</td>\n",
       "      <td>1.049675</td>\n",
       "      <td>1.043444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.016357</td>\n",
       "      <td>1.013615</td>\n",
       "      <td>1.067229</td>\n",
       "      <td>1.027036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.021983</td>\n",
       "      <td>1.020162</td>\n",
       "      <td>1.034084</td>\n",
       "      <td>1.013449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.043192</td>\n",
       "      <td>1.017163</td>\n",
       "      <td>1.065675</td>\n",
       "      <td>1.056116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.037968</td>\n",
       "      <td>1.022095</td>\n",
       "      <td>1.034766</td>\n",
       "      <td>1.011409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.015817</td>\n",
       "      <td>1.008941</td>\n",
       "      <td>1.081264</td>\n",
       "      <td>1.037584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.037425</td>\n",
       "      <td>1.094231</td>\n",
       "      <td>1.025453</td>\n",
       "      <td>1.040749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.036223</td>\n",
       "      <td>1.061277</td>\n",
       "      <td>1.046311</td>\n",
       "      <td>1.025265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.039977</td>\n",
       "      <td>1.067197</td>\n",
       "      <td>1.011280</td>\n",
       "      <td>1.015603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         v       tau         s\n",
       "0   1.041482  1.010669  1.056703  1.006579\n",
       "1   1.037471  1.092425  1.070733  1.056711\n",
       "2   1.079211  1.045275  1.047258  1.011098\n",
       "3   1.062372  1.026971  1.043778  1.046346\n",
       "4   1.026530  1.034618  1.027784  1.011045\n",
       "5   1.062316  1.017087  1.019890  1.004798\n",
       "6   1.012911  1.059059  1.039201  1.030079\n",
       "7   1.017544  1.105576  1.006274  1.109060\n",
       "8   1.008626  1.081852  1.077887  1.011102\n",
       "9   1.038091  1.041181  1.036396  1.011470\n",
       "10  1.016480  1.037194  1.046409  1.015252\n",
       "11  1.005403  1.071943  1.048311  1.027845\n",
       "12  1.026085  1.055248  1.024629  1.006545\n",
       "13  1.012193  1.007535  1.005631  1.055289\n",
       "14  1.026881  1.077103  1.053063  1.011152\n",
       "15  1.026627  1.045647  1.019683  1.010948\n",
       "16  1.013413  1.033669  1.026961  1.006505\n",
       "17  1.038865  1.058417  1.015053  1.010488\n",
       "18  1.074026  1.054437  1.039731  1.020782\n",
       "19  1.053366  1.071195  1.049675  1.043444\n",
       "20  1.016357  1.013615  1.067229  1.027036\n",
       "21  1.021983  1.020162  1.034084  1.013449\n",
       "22  1.043192  1.017163  1.065675  1.056116\n",
       "23  1.037968  1.022095  1.034766  1.011409\n",
       "24  1.015817  1.008941  1.081264  1.037584\n",
       "25  1.037425  1.094231  1.025453  1.040749\n",
       "26  1.036223  1.061277  1.046311  1.025265\n",
       "27  1.039977  1.067197  1.011280  1.015603"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trace = glam_full.trace\n",
    "rhats_params = az.rhat(model_trace, method=\"folded\")\n",
    "\n",
    "rhats_params_df = pd.DataFrame()\n",
    "rhats_params_df['gamma'] = rhats_params.gamma.values\n",
    "rhats_params_df['v'] = rhats_params.v.values\n",
    "rhats_params_df['tau'] = rhats_params.tau.values\n",
    "rhats_params_df['s'] = rhats_params.s.values\n",
    "\n",
    "rhats_params_df  # if |rhat - 1 | < 0.05 (rhat: gelman-rubin statistic) the sampler converged "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 2. effective sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>v</th>\n",
       "      <th>tau</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129.826063</td>\n",
       "      <td>122.410773</td>\n",
       "      <td>105.415105</td>\n",
       "      <td>102.606384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137.256908</td>\n",
       "      <td>19.862110</td>\n",
       "      <td>113.756351</td>\n",
       "      <td>29.455708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.427506</td>\n",
       "      <td>36.203434</td>\n",
       "      <td>37.236704</td>\n",
       "      <td>112.826427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.659321</td>\n",
       "      <td>80.567103</td>\n",
       "      <td>119.210769</td>\n",
       "      <td>35.903660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186.264402</td>\n",
       "      <td>180.816222</td>\n",
       "      <td>96.442001</td>\n",
       "      <td>359.066219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>139.980383</td>\n",
       "      <td>191.981317</td>\n",
       "      <td>95.731413</td>\n",
       "      <td>125.499401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73.549038</td>\n",
       "      <td>40.872295</td>\n",
       "      <td>40.344715</td>\n",
       "      <td>133.267579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84.298308</td>\n",
       "      <td>22.861119</td>\n",
       "      <td>66.187745</td>\n",
       "      <td>25.470931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97.321311</td>\n",
       "      <td>31.512538</td>\n",
       "      <td>143.324969</td>\n",
       "      <td>71.548984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37.949042</td>\n",
       "      <td>66.126126</td>\n",
       "      <td>69.923910</td>\n",
       "      <td>56.753961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60.103056</td>\n",
       "      <td>38.884147</td>\n",
       "      <td>118.014577</td>\n",
       "      <td>80.515969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>243.576527</td>\n",
       "      <td>178.036336</td>\n",
       "      <td>193.074586</td>\n",
       "      <td>96.321986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55.568938</td>\n",
       "      <td>86.063808</td>\n",
       "      <td>101.985346</td>\n",
       "      <td>62.257232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>139.523992</td>\n",
       "      <td>82.321129</td>\n",
       "      <td>74.336434</td>\n",
       "      <td>39.288902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23.478139</td>\n",
       "      <td>110.347604</td>\n",
       "      <td>34.642228</td>\n",
       "      <td>151.632138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42.548568</td>\n",
       "      <td>91.882972</td>\n",
       "      <td>72.947126</td>\n",
       "      <td>92.422877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>87.094486</td>\n",
       "      <td>84.607778</td>\n",
       "      <td>191.105437</td>\n",
       "      <td>107.750339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>122.889449</td>\n",
       "      <td>113.549031</td>\n",
       "      <td>99.634729</td>\n",
       "      <td>107.686790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.005617</td>\n",
       "      <td>36.013035</td>\n",
       "      <td>36.514984</td>\n",
       "      <td>56.345043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>127.798086</td>\n",
       "      <td>63.148272</td>\n",
       "      <td>33.274955</td>\n",
       "      <td>24.784540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>66.345884</td>\n",
       "      <td>123.726112</td>\n",
       "      <td>125.214844</td>\n",
       "      <td>170.072875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>69.448058</td>\n",
       "      <td>46.580244</td>\n",
       "      <td>115.270314</td>\n",
       "      <td>30.097449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>78.618578</td>\n",
       "      <td>32.868429</td>\n",
       "      <td>81.051999</td>\n",
       "      <td>21.067506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>267.790115</td>\n",
       "      <td>84.569062</td>\n",
       "      <td>99.745126</td>\n",
       "      <td>32.372157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>160.100269</td>\n",
       "      <td>88.005253</td>\n",
       "      <td>72.580640</td>\n",
       "      <td>70.158479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>228.593870</td>\n",
       "      <td>133.031496</td>\n",
       "      <td>135.303194</td>\n",
       "      <td>130.226983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29.994769</td>\n",
       "      <td>118.506861</td>\n",
       "      <td>28.857488</td>\n",
       "      <td>176.734315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33.184173</td>\n",
       "      <td>32.330854</td>\n",
       "      <td>25.995478</td>\n",
       "      <td>134.748754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gamma           v         tau           s\n",
       "0   129.826063  122.410773  105.415105  102.606384\n",
       "1   137.256908   19.862110  113.756351   29.455708\n",
       "2    41.427506   36.203434   37.236704  112.826427\n",
       "3    28.659321   80.567103  119.210769   35.903660\n",
       "4   186.264402  180.816222   96.442001  359.066219\n",
       "5   139.980383  191.981317   95.731413  125.499401\n",
       "6    73.549038   40.872295   40.344715  133.267579\n",
       "7    84.298308   22.861119   66.187745   25.470931\n",
       "8    97.321311   31.512538  143.324969   71.548984\n",
       "9    37.949042   66.126126   69.923910   56.753961\n",
       "10   60.103056   38.884147  118.014577   80.515969\n",
       "11  243.576527  178.036336  193.074586   96.321986\n",
       "12   55.568938   86.063808  101.985346   62.257232\n",
       "13  139.523992   82.321129   74.336434   39.288902\n",
       "14   23.478139  110.347604   34.642228  151.632138\n",
       "15   42.548568   91.882972   72.947126   92.422877\n",
       "16   87.094486   84.607778  191.105437  107.750339\n",
       "17  122.889449  113.549031   99.634729  107.686790\n",
       "18   50.005617   36.013035   36.514984   56.345043\n",
       "19  127.798086   63.148272   33.274955   24.784540\n",
       "20   66.345884  123.726112  125.214844  170.072875\n",
       "21   69.448058   46.580244  115.270314   30.097449\n",
       "22   78.618578   32.868429   81.051999   21.067506\n",
       "23  267.790115   84.569062   99.745126   32.372157\n",
       "24  160.100269   88.005253   72.580640   70.158479\n",
       "25  228.593870  133.031496  135.303194  130.226983\n",
       "26   29.994769  118.506861   28.857488  176.734315\n",
       "27   33.184173   32.330854   25.995478  134.748754"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_model = az.ess(model_trace, relative=False)\n",
    "\n",
    "ess_params_df = pd.DataFrame()\n",
    "ess_params_df['gamma'] = ess_model.gamma.values\n",
    "ess_params_df['v'] = ess_model.v.values\n",
    "ess_params_df['tau'] = ess_model.tau.values\n",
    "ess_params_df['s'] = ess_model.s.values\n",
    "\n",
    "ess_params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Percentage of divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Divergent 11\n",
      "Percentage of Divergent 0.5\n"
     ]
    }
   ],
   "source": [
    "# display the total number and percentage of divergent\n",
    "divergent = model_trace['diverging']\n",
    "print('Number of Divergent %d' % divergent.nonzero()[0].size)\n",
    "divperc = divergent.nonzero()[0].size / len(model_trace) * 100\n",
    "print('Percentage of Divergent %.1f' % divperc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_rhatsParams'+sufix+'.csv'))\n",
    "ess_params_df.to_csv(str('results/convergence/GlamDataPF2019_hierarch_essParams'+sufix+'.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waic Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/data/io_pymc3.py:89: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  FutureWarning,\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "           Estimate       SE\n",
       "-elpd_waic 15481.91     0.00\n",
       "p_waic        67.26        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.waic(model_trace,scale = 'negative_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WAIC 15481.905746223238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:1415: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  \"For one or more samples the posterior variance of the log predictive \"\n"
     ]
    }
   ],
   "source": [
    "model_waic = pm.waic(model_trace,scale = 'negative_log')\n",
    "print ('Model WAIC',model_waic.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda3/lib/python3.7/site-packages/arviz/stats/stats.py:683: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 8000 by 1 log-likelihood matrix\n",
       "\n",
       "          Estimate       SE\n",
       "-elpd_loo 15460.29     0.00\n",
       "p_loo        45.65        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "\n",
       "The scale is now log by default. Use 'scale' argument or 'stats.ic_scale' rcParam if\n",
       "you rely on a specific value.\n",
       "A higher log-score (or a lower deviance) indicates a model with better predictive\n",
       "accuracy."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.loo(model_trace,scale = 'negative_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), model_waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_trace.s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            self.waic = np.array([pm.waic(trace=trace, model=model)\n",
    "                                 for (trace, model) in zip(self.trace, self.model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.compute_waic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM hierarchically...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "np.save(str('results/estimates/glam_PF2019_nobias_hierarchical_cv'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias_hierarchical_cv'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
