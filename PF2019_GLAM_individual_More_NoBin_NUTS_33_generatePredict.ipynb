{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradyumna/anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(23) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Individual GLAM estimation and out of sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1734.284</td>\n",
       "      <td>110</td>\n",
       "      <td>131</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6555.370</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.240370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3174.566</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2877.579</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>0.608409</td>\n",
       "      <td>0.391591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1806.310</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.522849</td>\n",
       "      <td>0.477151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial  choice        rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0        1      0       1  1734.284           110           131  0.669090   \n",
       "1        1      1       0  6555.370            47            50  0.759630   \n",
       "2        1      2       0  3174.566            50            44  0.549371   \n",
       "3        1      3       1  2877.579            57            50  0.608409   \n",
       "4        1      4       1  1806.310            42            50  0.522849   \n",
       "\n",
       "     gaze_1  \n",
       "0  0.330910  \n",
       "1  0.240370  \n",
       "2  0.450629  \n",
       "3  0.391591  \n",
       "4  0.477151  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "sufix = '_individual_More_NoBin_Gamma-11_NUTS_33'\n",
    "data = pd.read_csv('data/PF2019_data/GlamDataPF2019_More_NoBin_33.csv')\n",
    "\n",
    "# Subset only necessary columns\n",
    "data = data[['subject', 'trial', 'choice', 'rt',\n",
    "         'item_value_0', 'item_value_1',\n",
    "         'gaze_0', 'gaze_1']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training (1920 trials) and test (1920 trials) sets...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "for subject in data.subject.unique():\n",
    "    subject_data = data[data['subject'] == subject].copy().reset_index(drop=True)\n",
    "    n_trials = len(subject_data)\n",
    "    \n",
    "    subject_train = subject_data.iloc[np.arange(0, n_trials, 2)].copy()\n",
    "    subject_test = subject_data.iloc[np.arange(1, n_trials, 2)].copy()\n",
    "\n",
    "    test_data = pd.concat([test_data, subject_test])\n",
    "    train_data = pd.concat([train_data, subject_train])\n",
    "\n",
    "#test_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_test'+sufix+'.csv'))\n",
    "#train_data.to_csv(str('data/PF2019_data/GlamDataPF2019_preprocessed_train'+sufix+'.csv'))\n",
    "\n",
    "print('Split data into training ({} trials) and test ({} trials) sets...'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>choice</th>\n",
       "      <th>rt</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1734.284</td>\n",
       "      <td>110</td>\n",
       "      <td>131</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3174.566</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.450629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1806.310</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.522849</td>\n",
       "      <td>0.477151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3650.266</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>0.317966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1259.268</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>0.508019</td>\n",
       "      <td>0.491981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5698.027</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>0.582089</td>\n",
       "      <td>0.417911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2626.168</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>0.666353</td>\n",
       "      <td>0.333647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1671.149</td>\n",
       "      <td>110</td>\n",
       "      <td>124</td>\n",
       "      <td>0.508035</td>\n",
       "      <td>0.491965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1527.826</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0.473512</td>\n",
       "      <td>0.526488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2267.665</td>\n",
       "      <td>101</td>\n",
       "      <td>110</td>\n",
       "      <td>0.553242</td>\n",
       "      <td>0.446758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5571.061</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>0.575306</td>\n",
       "      <td>0.424694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1402.112</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>0.435523</td>\n",
       "      <td>0.564477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2065.604</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>0.528335</td>\n",
       "      <td>0.471665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1613.454</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>0.485035</td>\n",
       "      <td>0.514965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4895.517</td>\n",
       "      <td>133</td>\n",
       "      <td>110</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.301621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.688</td>\n",
       "      <td>126</td>\n",
       "      <td>110</td>\n",
       "      <td>0.511292</td>\n",
       "      <td>0.488708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2050.497</td>\n",
       "      <td>110</td>\n",
       "      <td>126</td>\n",
       "      <td>0.522393</td>\n",
       "      <td>0.477607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1635.473</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>0.522261</td>\n",
       "      <td>0.477739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>4443.018</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>0.567061</td>\n",
       "      <td>0.432939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.903</td>\n",
       "      <td>124</td>\n",
       "      <td>110</td>\n",
       "      <td>0.558840</td>\n",
       "      <td>0.441160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1686.530</td>\n",
       "      <td>128</td>\n",
       "      <td>110</td>\n",
       "      <td>0.657603</td>\n",
       "      <td>0.342397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2244.929</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>0.702233</td>\n",
       "      <td>0.297767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1361.319</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "      <td>0.482747</td>\n",
       "      <td>0.517253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2850.121</td>\n",
       "      <td>96</td>\n",
       "      <td>80</td>\n",
       "      <td>0.698865</td>\n",
       "      <td>0.301135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1391.672</td>\n",
       "      <td>110</td>\n",
       "      <td>128</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.547368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1582.340</td>\n",
       "      <td>110</td>\n",
       "      <td>119</td>\n",
       "      <td>0.559501</td>\n",
       "      <td>0.440499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2184.782</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>0.581910</td>\n",
       "      <td>0.418090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2890.742</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "      <td>0.530453</td>\n",
       "      <td>0.469547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1901.984</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>0.418559</td>\n",
       "      <td>0.581441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2545.418</td>\n",
       "      <td>94</td>\n",
       "      <td>110</td>\n",
       "      <td>0.576064</td>\n",
       "      <td>0.423936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4251.426</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0.503628</td>\n",
       "      <td>0.496372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4601.336</td>\n",
       "      <td>89</td>\n",
       "      <td>110</td>\n",
       "      <td>0.477015</td>\n",
       "      <td>0.522985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3649.435</td>\n",
       "      <td>110</td>\n",
       "      <td>98</td>\n",
       "      <td>0.416827</td>\n",
       "      <td>0.583173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3708.628</td>\n",
       "      <td>110</td>\n",
       "      <td>94</td>\n",
       "      <td>0.451137</td>\n",
       "      <td>0.548863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>5089.783</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.624277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>6969.709</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>0.424717</td>\n",
       "      <td>0.575283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>33</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1858.269</td>\n",
       "      <td>87</td>\n",
       "      <td>110</td>\n",
       "      <td>0.469035</td>\n",
       "      <td>0.530965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>3910.930</td>\n",
       "      <td>80</td>\n",
       "      <td>96</td>\n",
       "      <td>0.460076</td>\n",
       "      <td>0.539924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2087.100</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>0.532287</td>\n",
       "      <td>0.467713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>33</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>4085.180</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>0.425232</td>\n",
       "      <td>0.574768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6549.821</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>0.568922</td>\n",
       "      <td>0.431078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>33</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>4550.765</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>0.449738</td>\n",
       "      <td>0.550262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>33</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>5756.064</td>\n",
       "      <td>103</td>\n",
       "      <td>110</td>\n",
       "      <td>0.479955</td>\n",
       "      <td>0.520045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>33</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4035.357</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>0.477174</td>\n",
       "      <td>0.522826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1844.621</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>0.497924</td>\n",
       "      <td>0.502076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>33</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3936.449</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>0.477459</td>\n",
       "      <td>0.522541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>33</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>11964.377</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>0.484599</td>\n",
       "      <td>0.515401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>33</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2743.440</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>0.529970</td>\n",
       "      <td>0.470030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>2532.466</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>0.539153</td>\n",
       "      <td>0.460847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>6412.806</td>\n",
       "      <td>110</td>\n",
       "      <td>96</td>\n",
       "      <td>0.513330</td>\n",
       "      <td>0.486670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4007.788</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.442161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>33</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>3685.316</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>0.582175</td>\n",
       "      <td>0.417825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>33</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>1988.182</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>0.399461</td>\n",
       "      <td>0.600539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>33</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>4300.777</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>0.492486</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>7640.657</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>0.593629</td>\n",
       "      <td>0.406371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>33</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>3341.929</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>0.476386</td>\n",
       "      <td>0.523614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>33</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2674.219</td>\n",
       "      <td>122</td>\n",
       "      <td>110</td>\n",
       "      <td>0.584644</td>\n",
       "      <td>0.415356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>33</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2848.448</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>0.552859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>33</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>2835.649</td>\n",
       "      <td>110</td>\n",
       "      <td>122</td>\n",
       "      <td>0.680958</td>\n",
       "      <td>0.319042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>33</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>3903.836</td>\n",
       "      <td>110</td>\n",
       "      <td>112</td>\n",
       "      <td>0.392389</td>\n",
       "      <td>0.607611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  trial  choice         rt  item_value_0  item_value_1    gaze_0  \\\n",
       "0          1      0       1   1734.284           110           131  0.669090   \n",
       "2          1      2       0   3174.566            50            44  0.549371   \n",
       "4          1      4       1   1806.310            42            50  0.522849   \n",
       "6          1      6       1   3650.266            78            80  0.682034   \n",
       "8          1      8       1   1259.268            50            48  0.508019   \n",
       "10         1     10       1   5698.027            46            50  0.582089   \n",
       "12         1     12       1   2626.168            50            56  0.666353   \n",
       "14         1     14       1   1671.149           110           124  0.508035   \n",
       "16         1     16       1   1527.826            64            80  0.473512   \n",
       "18         1     18       1   2267.665           101           110  0.553242   \n",
       "20         1     20       0   5571.061            50            42  0.575306   \n",
       "22         1     22       1   1402.112            77            80  0.435523   \n",
       "24         1     24       1   2065.604            44            50  0.528335   \n",
       "26         1     26       1   1613.454            50            46  0.485035   \n",
       "28         1     28       0   4895.517           133           110  0.698379   \n",
       "30         1     30       1   2000.688           126           110  0.511292   \n",
       "32         1     32       1   2050.497           110           126  0.522393   \n",
       "34         1     34       1   1635.473            80            77  0.522261   \n",
       "36         1     36       0   4443.018            80            64  0.567061   \n",
       "38         1     38       1   1725.903           124           110  0.558840   \n",
       "40         1     40       0   1686.530           128           110  0.657603   \n",
       "42         1     42       0   2244.929            54            50  0.702233   \n",
       "44         1     44       1   1361.319           105           110  0.482747   \n",
       "46         1     46       0   2850.121            96            80  0.698865   \n",
       "48         1     48       1   1391.672           110           128  0.452632   \n",
       "50         1     50       1   1582.340           110           119  0.559501   \n",
       "52         1     52       0   2184.782            58            50  0.581910   \n",
       "54         1     54       1   2890.742            74            80  0.530453   \n",
       "56         1     56       1   1901.984            66            80  0.418559   \n",
       "58         1     58       1   2545.418            94           110  0.576064   \n",
       "..       ...    ...     ...        ...           ...           ...       ...   \n",
       "60        33     60       1   4251.426            75            80  0.503628   \n",
       "62        33     62       0   4601.336            89           110  0.477015   \n",
       "64        33     64       0   3649.435           110            98  0.416827   \n",
       "66        33     66       0   3708.628           110            94  0.451137   \n",
       "68        33     68       1   5089.783            50            54  0.375723   \n",
       "70        33     70       1   6969.709            50            52  0.424717   \n",
       "72        33     72       1   1858.269            87           110  0.469035   \n",
       "74        33     74       1   3910.930            80            96  0.460076   \n",
       "76        33     76       1   2087.100            50            55  0.532287   \n",
       "78        33     78       1   4085.180            45            50  0.425232   \n",
       "80        33     80       1   6549.821            50            53  0.568922   \n",
       "82        33     82       1   4550.765            80            88  0.449738   \n",
       "84        33     84       0   5756.064           103           110  0.479955   \n",
       "86        33     86       0   4035.357            80            72  0.477174   \n",
       "88        33     88       1   1844.621            80            90  0.497924   \n",
       "90        33     90       0   3936.449            80            70  0.477459   \n",
       "92        33     92       0  11964.377            82            80  0.484599   \n",
       "94        33     94       1   2743.440            96           110  0.529970   \n",
       "96        33     96       0   2532.466            60            50  0.539153   \n",
       "98        33     98       1   6412.806           110            96  0.513330   \n",
       "100       33    100       0   4007.788            49            50  0.557839   \n",
       "102       33    102       0   3685.316            51            50  0.582175   \n",
       "104       33    104       1   1988.182            40            50  0.399461   \n",
       "106       33    106       0   4300.777            85            80  0.492486   \n",
       "108       33    108       0   7640.657            50            43  0.593629   \n",
       "110       33    110       1   3341.929            50            60  0.476386   \n",
       "112       33    112       0   2674.219           122           110  0.584644   \n",
       "114       33    114       1   2848.448            80            67  0.447141   \n",
       "116       33    116       1   2835.649           110           122  0.680958   \n",
       "118       33    118       1   3903.836           110           112  0.392389   \n",
       "\n",
       "       gaze_1  \n",
       "0    0.330910  \n",
       "2    0.450629  \n",
       "4    0.477151  \n",
       "6    0.317966  \n",
       "8    0.491981  \n",
       "10   0.417911  \n",
       "12   0.333647  \n",
       "14   0.491965  \n",
       "16   0.526488  \n",
       "18   0.446758  \n",
       "20   0.424694  \n",
       "22   0.564477  \n",
       "24   0.471665  \n",
       "26   0.514965  \n",
       "28   0.301621  \n",
       "30   0.488708  \n",
       "32   0.477607  \n",
       "34   0.477739  \n",
       "36   0.432939  \n",
       "38   0.441160  \n",
       "40   0.342397  \n",
       "42   0.297767  \n",
       "44   0.517253  \n",
       "46   0.301135  \n",
       "48   0.547368  \n",
       "50   0.440499  \n",
       "52   0.418090  \n",
       "54   0.469547  \n",
       "56   0.581441  \n",
       "58   0.423936  \n",
       "..        ...  \n",
       "60   0.496372  \n",
       "62   0.522985  \n",
       "64   0.583173  \n",
       "66   0.548863  \n",
       "68   0.624277  \n",
       "70   0.575283  \n",
       "72   0.530965  \n",
       "74   0.539924  \n",
       "76   0.467713  \n",
       "78   0.574768  \n",
       "80   0.431078  \n",
       "82   0.550262  \n",
       "84   0.520045  \n",
       "86   0.522826  \n",
       "88   0.502076  \n",
       "90   0.522541  \n",
       "92   0.515401  \n",
       "94   0.470030  \n",
       "96   0.460847  \n",
       "98   0.486670  \n",
       "100  0.442161  \n",
       "102  0.417825  \n",
       "104  0.600539  \n",
       "106  0.507514  \n",
       "108  0.406371  \n",
       "110  0.523614  \n",
       "112  0.415356  \n",
       "114  0.552859  \n",
       "116  0.319042  \n",
       "118  0.607611  \n",
       "\n",
       "[1920 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical GLAM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. full GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting full GLAM individually...\n",
      "  Found old parameter estimates in \"results/estimates\". Skipping estimation...\n"
     ]
    }
   ],
   "source": [
    "# Fitting full GLAM\n",
    "print('Fitting full GLAM individually...')\n",
    "\n",
    "glam_full = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_full'+sufix+'.npy')):\n",
    "    glam_full.make_model('individual', gamma_bounds=(-1, 1), t0_val=0)\n",
    "    glam_full.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_full.estimates = np.load(str('results/estimates/glam_PF2019_full'+sufix+'.npy'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameter estimates\n",
    "#np.save(str('results/estimates/glam_PF2019_full'+sufix+'.npy'), glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tau': 0.28, 'gamma': 0.85, 's': 0.009766, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tau': 0.29, 'gamma': 0.89, 's': 0.005238, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tau': 0.13, 'gamma': -0.09, 's': 0.007449, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tau': 0.17, 'gamma': 0.98, 's': 0.010301, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tau': 0.13, 'gamma': 0.68, 's': 0.005436, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'tau': 0.08, 'gamma': 0.63, 's': 0.007799, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'tau': 0.1, 'gamma': 0.82, 's': 0.011048, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'tau': 0.06, 'gamma': -0.27, 's': 0.007531, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'tau': 0.02, 'gamma': 0.99, 's': 0.005685, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'tau': 0.32, 'gamma': 0.08, 's': 0.009549, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'tau': 0.11, 'gamma': 0.7, 's': 0.008549, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'tau': 0.1, 'gamma': -0.44, 's': 0.00659, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'tau': 0.03, 'gamma': 0.96, 's': 0.001909, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'tau': 0.27, 'gamma': 0.44, 's': 0.008386, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'tau': 0.13, 'gamma': 0.78, 's': 0.008272, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'tau': 4.4, 'gamma': 0.59, 's': 0.008647, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'tau': 0.32, 'gamma': 0.99, 's': 0.006765, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'tau': 0.13, 'gamma': 0.51, 's': 0.004763, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'tau': 0.72, 'gamma': 0.59, 's': 0.007874, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'tau': 4.1, 'gamma': 0.58, 's': 0.010811, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'tau': 0.11, 'gamma': 0.6, 's': 0.007451, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'tau': 1.38, 'gamma': 0.12, 's': 0.012091, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'tau': 0.21, 'gamma': 0.65, 's': 0.00677, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'tau': 0.2, 'gamma': 0.71, 's': 0.008297, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'tau': 4.09, 'gamma': 0.94, 's': 0.006249, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'tau': 0.08, 'gamma': 0.42, 's': 0.006002, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'tau': 0.07, 'gamma': 0.56, 's': 0.006639, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'tau': 0.03, 'gamma': 0.4, 's': 0.004388, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'tau': 0.13, 'gamma': 0.17, 's': 0.005154, 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'tau': 0.2, 'gamma': 0.58, 's': 0.008771, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'tau': 0.07, 'gamma': 0.85, 's': 0.00749, 'SN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'tau': 0.1, 'gamma': 0.71, 's': 0.006352, 'SN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   {'tau': 0.28, 'gamma': 0.85, 's': 0.009766, 'S...\n",
       "1   {'tau': 0.29, 'gamma': 0.89, 's': 0.005238, 'S...\n",
       "2   {'tau': 0.13, 'gamma': -0.09, 's': 0.007449, '...\n",
       "3   {'tau': 0.17, 'gamma': 0.98, 's': 0.010301, 'S...\n",
       "4   {'tau': 0.13, 'gamma': 0.68, 's': 0.005436, 'S...\n",
       "5   {'tau': 0.08, 'gamma': 0.63, 's': 0.007799, 'S...\n",
       "6   {'tau': 0.1, 'gamma': 0.82, 's': 0.011048, 'SN...\n",
       "7   {'tau': 0.06, 'gamma': -0.27, 's': 0.007531, '...\n",
       "8   {'tau': 0.02, 'gamma': 0.99, 's': 0.005685, 'S...\n",
       "9   {'tau': 0.32, 'gamma': 0.08, 's': 0.009549, 'S...\n",
       "10  {'tau': 0.11, 'gamma': 0.7, 's': 0.008549, 'SN...\n",
       "11  {'tau': 0.1, 'gamma': -0.44, 's': 0.00659, 'SN...\n",
       "12  {'tau': 0.03, 'gamma': 0.96, 's': 0.001909, 'S...\n",
       "13  {'tau': 0.27, 'gamma': 0.44, 's': 0.008386, 'S...\n",
       "14  {'tau': 0.13, 'gamma': 0.78, 's': 0.008272, 'S...\n",
       "15  {'tau': 4.4, 'gamma': 0.59, 's': 0.008647, 'SN...\n",
       "16  {'tau': 0.32, 'gamma': 0.99, 's': 0.006765, 'S...\n",
       "17  {'tau': 0.13, 'gamma': 0.51, 's': 0.004763, 'S...\n",
       "18  {'tau': 0.72, 'gamma': 0.59, 's': 0.007874, 'S...\n",
       "19  {'tau': 4.1, 'gamma': 0.58, 's': 0.010811, 'SN...\n",
       "20  {'tau': 0.11, 'gamma': 0.6, 's': 0.007451, 'SN...\n",
       "21  {'tau': 1.38, 'gamma': 0.12, 's': 0.012091, 'S...\n",
       "22  {'tau': 0.21, 'gamma': 0.65, 's': 0.00677, 'SN...\n",
       "23  {'tau': 0.2, 'gamma': 0.71, 's': 0.008297, 'SN...\n",
       "24  {'tau': 4.09, 'gamma': 0.94, 's': 0.006249, 'S...\n",
       "25  {'tau': 0.08, 'gamma': 0.42, 's': 0.006002, 'S...\n",
       "26  {'tau': 0.07, 'gamma': 0.56, 's': 0.006639, 'S...\n",
       "27  {'tau': 0.03, 'gamma': 0.4, 's': 0.004388, 'SN...\n",
       "28  {'tau': 0.13, 'gamma': 0.17, 's': 0.005154, 'S...\n",
       "29  {'tau': 0.2, 'gamma': 0.58, 's': 0.008771, 'SN...\n",
       "30  {'tau': 0.07, 'gamma': 0.85, 's': 0.00749, 'SN...\n",
       "31  {'tau': 0.1, 'gamma': 0.71, 's': 0.006352, 'SN..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(glam_full.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing WAIC scores for full model...\n",
      "  Found old DIC scores in \"results/waic\". Skipping WAIC computation...\n"
     ]
    }
   ],
   "source": [
    "# Compute WAICs\n",
    "print('Computing WAIC scores for full model...')\n",
    "if not os.path.exists(str('results/waic/glam_PF2019_full'+ sufix +'.npy')):\n",
    "    # Note: DIC computation does not work for ADVI fitted models\n",
    "    # But we are using WAIC\n",
    "    glam_full.compute_waic()\n",
    "else:\n",
    "    print('  Found old DIC scores in \"results/waic\". Skipping WAIC computation...')\n",
    "    glam_full.waic = np.load(str('results/waic/glam_PF2019_full'+ sufix +'.npy'))\n",
    "\n",
    "# Compute WAICs\n",
    "#np.save(str('results/waic/glam_PF2019_full'+ sufix +'.npy'), glam_full.waic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04604884e+03, 0.00000000e+00, 1.72250244e+00, 1.00000000e+00],\n",
       "       [1.22067883e+03, 0.00000000e+00, 1.77895232e+00, 1.00000000e+00],\n",
       "       [1.08131950e+03, 0.00000000e+00, 4.57825376e+00, 1.00000000e+00],\n",
       "       [1.19129127e+03, 0.00000000e+00, 1.81216772e+00, 1.00000000e+00],\n",
       "       [1.09360688e+03, 0.00000000e+00, 2.09341500e+00, 1.00000000e+00],\n",
       "       [1.07141022e+03, 0.00000000e+00, 3.96698860e+00, 1.00000000e+00],\n",
       "       [1.16532728e+03, 0.00000000e+00, 1.59540281e+00, 1.00000000e+00],\n",
       "       [1.04997833e+03, 0.00000000e+00, 2.34431071e+00, 1.00000000e+00],\n",
       "       [9.92213429e+02, 0.00000000e+00, 2.57769666e+00, 1.00000000e+00],\n",
       "       [1.03406225e+03, 0.00000000e+00, 2.59437231e+00, 1.00000000e+00],\n",
       "       [1.20205192e+03, 0.00000000e+00, 3.10274965e+00, 1.00000000e+00],\n",
       "       [1.00093682e+03, 0.00000000e+00, 2.61991370e+00, 1.00000000e+00],\n",
       "       [1.05702793e+03, 0.00000000e+00, 1.21914822e+01, 1.00000000e+00],\n",
       "       [1.07529609e+03, 0.00000000e+00, 3.57531961e+00, 1.00000000e+00],\n",
       "       [1.14818307e+03, 0.00000000e+00, 2.59812852e+00, 1.00000000e+00],\n",
       "       [1.01134051e+03, 0.00000000e+00, 4.59129769e+00, 1.00000000e+00],\n",
       "       [1.17904935e+03, 0.00000000e+00, 2.61328657e+00, 1.00000000e+00],\n",
       "       [1.08212759e+03, 0.00000000e+00, 2.91359478e+00, 1.00000000e+00],\n",
       "       [1.03912684e+03, 0.00000000e+00, 2.98513902e+00, 1.00000000e+00],\n",
       "       [1.12281397e+03, 0.00000000e+00, 1.58847943e+00, 1.00000000e+00],\n",
       "       [1.08328029e+03, 0.00000000e+00, 5.13211283e+00, 1.00000000e+00],\n",
       "       [1.04048361e+03, 0.00000000e+00, 2.37669404e+00, 1.00000000e+00],\n",
       "       [1.10951177e+03, 0.00000000e+00, 3.77999267e+00, 1.00000000e+00],\n",
       "       [1.17166441e+03, 0.00000000e+00, 3.14235474e+00, 1.00000000e+00],\n",
       "       [1.14466468e+03, 0.00000000e+00, 1.24185550e+00, 1.00000000e+00],\n",
       "       [1.10702344e+03, 0.00000000e+00, 4.35968602e+00, 1.00000000e+00],\n",
       "       [1.11839910e+03, 0.00000000e+00, 3.38129679e+00, 1.00000000e+00],\n",
       "       [9.84718636e+02, 0.00000000e+00, 1.72399392e+00, 1.00000000e+00],\n",
       "       [9.37096894e+02, 0.00000000e+00, 3.91369881e+00, 1.00000000e+00],\n",
       "       [1.07135325e+03, 0.00000000e+00, 3.29260029e+00, 1.00000000e+00],\n",
       "       [1.07397668e+03, 0.00000000e+00, 6.75135179e+00, 1.00000000e+00],\n",
       "       [1.11923509e+03, 0.00000000e+00, 5.32397127e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glam_full.waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GLAM' object has no attribute 'trace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a1004a65292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute LOO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLAM' object has no attribute 'trace'"
     ]
    }
   ],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_full.loo = pm.loo(trace=glam_full.trace, model=glam_full.model)\n",
    "glam_full.loo\n",
    "#np.save(str('results/loo/glam_PF2019_full'+ sufix +'.npy'), glam_full.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GLAM' object has no attribute 'loo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-93edf815a60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLAM' object has no attribute 'loo'"
     ]
    }
   ],
   "source": [
    "glam_full.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glam_full.type = \"individual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GLAM' object has no attribute 'error_range'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-045dc5f9ebdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLAM' object has no attribute 'error_range'"
     ]
    }
   ],
   "source": [
    "glam_full.error_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test set data using full GLAM...\n",
      "Replaced attached data (1920 trials) with new data (1920 trials)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Domain error in arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2434503e487c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/predictions/glam_PF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msufix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/predictions/glam_PF2019_full'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msufix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, n_repeats, boundary, error_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                                                   \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboundary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                                                   \u001b[0merror_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                                                                   error_range=error_range)\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/simulation.py\u001b[0m in \u001b[0;36msimulate_subject\u001b[0;34m(parameters, values, gaze, n_repeats, subject, boundary, error_weight, error_range)\u001b[0m\n\u001b[1;32m     22\u001b[0m                                         \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboundary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                         \u001b[0merror_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                         error_range=error_range)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mrts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrunning_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GiTs/glamDDM_PF2019/glam/simulation.py\u001b[0m in \u001b[0;36msimulate_trial\u001b[0;34m(parameters, values, gaze, boundary, error_weight, error_range)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboundary\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdrifts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboundary\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mFPTs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvgauss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFPTs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_argcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Domain error in arguments.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Domain error in arguments."
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using full GLAM...')\n",
    "glam_full.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_full'+sufix+'.csv')):\n",
    "    glam_full.predict(n_repeats=50)\n",
    "    glam_full.prediction.to_csv(str('results/predictions/glam_PF2019_full'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical full GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_full.prediction = pd.read_csv(str('results/predictions/glam_PF2019_full'+sufix+'.csv'))\n",
    "\n",
    "glam_full.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. no-bias GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting no-bias GLAM\n",
    "print('Fitting no-bias GLAM individually...')\n",
    "\n",
    "glam_nobias = glam.GLAM(train_data)\n",
    "\n",
    "if not os.path.exists(str('results/estimates/glam_PF2019_nobias'+sufix+'.npy')):\n",
    "    glam_nobias.make_model('hierarchical', gamma_val=1.0, t0_val=0)\n",
    "    glam_nobias.fit(method='NUTS', tune=1000)\n",
    "else:\n",
    "    print('  Found old parameter estimates in \"results/estimates\". Skipping estimation...')\n",
    "    glam_nobias.estimates = np.load(str('results/estimates/glam_PF2019_nobias'+sufix+'.npy'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Save parameter estimates\n",
    "#np.save(str('results/estimates/glam_PF2019_nobias'+sufix+'.npy'), glam_nobias.estimates)\n",
    "pd.DataFrame(glam_nobias.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it is already fitted\n",
    "params_part_like = pd.DataFrame.from_dict(glam_nobias.estimates.item(0))\n",
    "params_part_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute LOO\n",
    "\n",
    "glam_nobias.loo = pm.loo(trace=glam_nobias.trace, model=glam_nobias.model)\n",
    "glam_nobias.loo\n",
    "\n",
    "#np.save(str('results/loo/glam_PF2019_nobias'+ sufix +'.npy'), glam_nobias.loo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "print('Predicting test set data using no-bias GLAM...')\n",
    "glam_nobias.exchange_data(test_data)\n",
    "\n",
    "if not os.path.exists(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv')):\n",
    "    glam_nobias.predict(n_repeats=50)\n",
    "#    glam_nobias.prediction.to_csv(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv'), index=False)\n",
    "else:\n",
    "    print('  Found old hierarchical no-bias GLAM predictions in \"results/predictions\". Skipping prediction...')\n",
    "    glam_nobias.prediction = pd.read_csv(str('results/predictions/glam_PF2019_nobias'+sufix+'.csv'))\n",
    "\n",
    "glam_nobias.prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close Figure to continue...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GLAM' object has no attribute 'prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45350e456e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Close Figure to continue...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mglam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLAM' object has no attribute 'prediction'"
     ]
    }
   ],
   "source": [
    "print('Close Figure to continue...')\n",
    "glam.plot_fit(test_data, [glam_full.prediction]);\n",
    "#glam.plot_fit(test_data, [glam_full.prediction,glam_nobias.prediction]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for full hierarchical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.1e-05,\n",
       "  'gamma': -0.77,\n",
       "  'SNR': 125.41,\n",
       "  's': 0.0081,\n",
       "  'tau': 0.01,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 1.6e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 290.78,\n",
       "  's': 0.006238,\n",
       "  'tau': 0.05,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.5e-05,\n",
       "  'gamma': -0.11,\n",
       "  'SNR': 230.96,\n",
       "  's': 0.008048,\n",
       "  'tau': 0.11,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.1e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 434.59,\n",
       "  's': 0.009583,\n",
       "  'tau': 0.1,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.2e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 165.04,\n",
       "  's': 0.005638,\n",
       "  'tau': 0.06,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.7e-05,\n",
       "  'gamma': -0.71,\n",
       "  'SNR': 83.7,\n",
       "  's': 0.005543,\n",
       "  'tau': 0.09,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 232.79,\n",
       "  's': 0.008216,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.1e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 99.14,\n",
       "  's': 0.005566,\n",
       "  'tau': 0.09,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 0.00011,\n",
       "  'gamma': -0.86,\n",
       "  'SNR': 49.13,\n",
       "  's': 0.005373,\n",
       "  'tau': 0.0,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 165.72,\n",
       "  's': 0.008702,\n",
       "  'tau': 0.06,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.8e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 326.55,\n",
       "  's': 0.008587,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 9e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 54.42,\n",
       "  's': 0.004899,\n",
       "  'tau': 0.02,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.4e-05,\n",
       "  'gamma': -0.56,\n",
       "  'SNR': 86.39,\n",
       "  's': 0.002529,\n",
       "  'tau': 0.0,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4e-05,\n",
       "  'gamma': -0.87,\n",
       "  'SNR': 232.26,\n",
       "  's': 0.00942,\n",
       "  'tau': 0.25,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 154.16,\n",
       "  's': 0.006544,\n",
       "  'tau': 0.04,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.6e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 127.67,\n",
       "  's': 0.007116,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 1.9e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 476.5,\n",
       "  's': 0.008507,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.8e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 177.22,\n",
       "  's': 0.005505,\n",
       "  'tau': 0.05,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.2e-05,\n",
       "  'gamma': -0.87,\n",
       "  'SNR': 340.23,\n",
       "  's': 0.008569,\n",
       "  'tau': 0.04,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.5e-05,\n",
       "  'gamma': -0.98,\n",
       "  'SNR': 228.98,\n",
       "  's': 0.008275,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.2e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 213.49,\n",
       "  's': 0.006526,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.6e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 288.26,\n",
       "  's': 0.009493,\n",
       "  'tau': 0.08,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 232.13,\n",
       "  's': 0.007639,\n",
       "  'tau': 0.07,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 133.67,\n",
       "  's': 0.006737,\n",
       "  'tau': 0.04,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 1.7e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 336.19,\n",
       "  's': 0.007432,\n",
       "  'tau': 0.02,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 3.9e-05,\n",
       "  'gamma': -0.71,\n",
       "  'SNR': 145.41,\n",
       "  's': 0.006367,\n",
       "  'tau': 0.06,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 2.9e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 141.85,\n",
       "  's': 0.004457,\n",
       "  'tau': 0.03,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.6e-05,\n",
       "  'gamma': -0.98,\n",
       "  'SNR': 259.96,\n",
       "  's': 0.010083,\n",
       "  'tau': 0.18,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 6.8e-05,\n",
       "  'gamma': -0.99,\n",
       "  'SNR': 62.69,\n",
       "  's': 0.004352,\n",
       "  'tau': 0.11,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 5.7e-05,\n",
       "  'gamma': -0.98,\n",
       "  'SNR': 115.24,\n",
       "  's': 0.008492,\n",
       "  'tau': 0.05,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 7.2e-05,\n",
       "  'gamma': 0.27,\n",
       "  'SNR': 106.53,\n",
       "  's': 0.008452,\n",
       "  'tau': 0.01,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.6e-05,\n",
       "  'gamma': -0.94,\n",
       "  'SNR': 145.61,\n",
       "  's': 0.006249,\n",
       "  'tau': 0.01,\n",
       "  't0': array([0.])},\n",
       " {'b': 1.0,\n",
       "  'p_error': 0.05,\n",
       "  'v': 4.4e-05,\n",
       "  'gamma': -0.94,\n",
       "  'SNR': 156.31,\n",
       "  's': 0.007018,\n",
       "  'tau': 0.0,\n",
       "  't0': array([0.])}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_participant = glam_full.estimates\n",
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-24a3f3602e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams_participant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparams_participant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglam_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "params_participant = pd.DataFrame.from_dict(glam_full.estimates.item(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mean gamma \" +  str(params_participant['gamma'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = params_participant[['SNR','gamma','tau','v']].hist(figsize = [20,3] , layout=[1,4],bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [END] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
